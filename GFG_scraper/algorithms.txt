Fundamentals-Of-Algorithms ArchiveIndex1.		Analysis of Algorithms | Set 1 (Asymptotic Analysis) - GeeksforGeeks 2.		Analysis of Algorithms | Set 2 (Worst, Average and Best Cases) - GeeksforGeeks 3.		Analysis of Algorithms | Set 3 (Asymptotic Notations) - GeeksforGeeks 4.		Analysis of algorithms | little o and little omega notations - GeeksforGeeks 5.		Lower and Upper Bound Theory - GeeksforGeeks 6.		Analysis of Algorithms | Set 4 (Analysis of Loops) - GeeksforGeeks 7.		Analysis of Algorithm | Set 4 (Solving Recurrences) - GeeksforGeeks 8.		Analysis of Algorithm | Set 5 (Amortized Analysis Introduction) - GeeksforGeeks 9.		What does 'Space Complexity' mean? - GeeksforGeeks 10.		Pseudo-polynomial Algorithms - GeeksforGeeks 11.		NP-Completeness | Set 1 (Introduction) - GeeksforGeeks 12.		Polynomial Time Approximation Scheme - GeeksforGeeks 13.		A Time Complexity Question - GeeksforGeeks 14.		Time Complexity of building a heap - GeeksforGeeks 15.		Time Complexity where loop variable is incremented by 1, 2, 3, 4 .. - GeeksforGeeks 16.		Time Complexity of Loop with Powers - GeeksforGeeks 17.		Performance of loops (A caching question) - GeeksforGeeks 18.		Linear Search - GeeksforGeeks 19.		Binary Search - GeeksforGeeks 20.		Jump Search - GeeksforGeeks 21.		Interpolation Search - GeeksforGeeks 22.		Exponential Search - GeeksforGeeks 23.		Why is Binary Search preferred over Ternary Search? - GeeksforGeeks 24.		Selection Sort - GeeksforGeeks 25.		Bubble Sort - GeeksforGeeks 26.		Insertion Sort - GeeksforGeeks 27.		Merge Sort - GeeksforGeeks 28.		HeapSort - GeeksforGeeks 29.		QuickSort - GeeksforGeeks 30.		Radix Sort - GeeksforGeeks 31.		Counting Sort - GeeksforGeeks 32.		Bucket Sort - GeeksforGeeks 33.		ShellSort - GeeksforGeeks 34.		Comb Sort - GeeksforGeeks 35.		Pigeonhole Sort - GeeksforGeeks 36.		Cycle Sort - GeeksforGeeks 37.		Interpolation search vs Binary search - GeeksforGeeks 38.		Stability in sorting algorithms - GeeksforGeeks 39.		When does the worst case of Quicksort occur? - GeeksforGeeks 40.		Lower bound for comparison based sorting algorithms - GeeksforGeeks 41.		Which sorting algorithm makes minimum number of memory writes? - GeeksforGeeks 42.		Find the Minimum length Unsorted Subarray, sorting which makes the complete array sorted - GeeksforGeeks 43.		Merge Sort for Linked Lists - GeeksforGeeks 44.		Sort a nearly sorted (or K sorted) array - GeeksforGeeks 45.		Iterative Quick Sort - GeeksforGeeks 46.		QuickSort on Singly Linked List - GeeksforGeeks 47.		QuickSort on Doubly Linked List - GeeksforGeeks 48.		Find k closest elements to a given value - GeeksforGeeks 49.		Sort n numbers in range from 0 to n^2 - 1 in linear time - GeeksforGeeks 50.		A Problem in Many Binary Search Implementations - GeeksforGeeks 51.		Search in an almost sorted array - GeeksforGeeks 52.		Sort an array in wave form - GeeksforGeeks 53.		Why is Binary Search preferred over Ternary Search? - GeeksforGeeks 54.		K'th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time) - GeeksforGeeks 55.		K'th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time) - GeeksforGeeks 56.		K'th Smallest/Largest Element in Unsorted Array | Set 3 (Worst Case Linear Time) - GeeksforGeeks 57.		Find the closest pair from two sorted arrays - GeeksforGeeks 58.		Find common elements in three sorted arrays - GeeksforGeeks 59.		Given a sorted array and a number x, find the pair in array whose sum is closest to x - GeeksforGeeks 60.		Count 1's in a sorted binary array - GeeksforGeeks 61.		Binary Insertion Sort - GeeksforGeeks 62.		Insertion Sort for Singly Linked List - GeeksforGeeks 63.		Why Quick Sort preferred for Arrays and Merge Sort for Linked Lists? - GeeksforGeeks 64.		Merge Sort for Doubly Linked List - GeeksforGeeks 65.		Minimum adjacent swaps to move maximum and minimum to corners - GeeksforGeeks 66.		Activity Selection Problem | Greedy Algo-1 - GeeksforGeeks 67.		Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2 - GeeksforGeeks 68.		Huffman Coding | Greedy Algo-3 - GeeksforGeeks 69.		Efficient Huffman Coding for Sorted Input | Greedy Algo-4 - GeeksforGeeks 70.		Prim’s Minimum Spanning Tree (MST) | Greedy Algo-5 - GeeksforGeeks 71.		Prim’s MST for Adjacency List Representation | Greedy Algo-6 - GeeksforGeeks 72.		Dijsktra's algorithm 73.		Dijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8 - GeeksforGeeks 74.		Job Sequencing Problem - GeeksforGeeks 75.		Greedy Algorithms - GeeksforGeeks 76.		Greedy Algorithm to find Minimum number of Coins - GeeksforGeeks 77.		K Centers Problem | Set 1 (Greedy Approximate Algorithm) - GeeksforGeeks 78.		Minimum Number of Platforms Required for a Railway/Bus Station - GeeksforGeeks 79.		Overlapping Subproblems Property in Dynamic Programming | DP-1 - GeeksforGeeks 80.		Optimal Substructure Property in Dynamic Programming | DP-2 - GeeksforGeeks 81.		Longest Increasing Subsequence | DP-3 - GeeksforGeeks 82.		Longest Common Subsequence | DP-4 - GeeksforGeeks 83.		Edit Distance | DP-5 - GeeksforGeeks 84.		Min Cost Path | DP-6 - GeeksforGeeks 85.		Coin Change | DP-7 - GeeksforGeeks 86.		Matrix Chain Multiplication | DP-8 - GeeksforGeeks 87.		Binomial Coefficient | DP-9 - GeeksforGeeks 88.		0-1 Knapsack Problem | DP-10 - GeeksforGeeks 89.		Egg Dropping Puzzle | DP-11 - GeeksforGeeks 90.		Longest Palindromic Subsequence | DP-12 - GeeksforGeeks 91.		Cutting a Rod | DP-13 - GeeksforGeeks 92.		Maximum Sum Increasing Subsequence | DP-14 - GeeksforGeeks 93.		Longest Bitonic Subsequence | DP-15 - GeeksforGeeks 94.		Floyd Warshall Algorithm | DP-16 - GeeksforGeeks 95.		Palindrome Partitioning | DP-17 - GeeksforGeeks 96.		Partition problem | DP-18 - GeeksforGeeks 97.		Word Wrap Problem | DP-19 - GeeksforGeeks 98.		Maximum Length Chain of Pairs | DP-20 - GeeksforGeeks 99.		Variations of LIS | DP-21 - GeeksforGeeks 100.		Box Stacking Problem | DP-22 - GeeksforGeeks 101.		Program for Fibonacci numbers - GeeksforGeeks 102.		Minimum number of jumps to reach end - GeeksforGeeks 103.		Maximum size square sub-matrix with all 1s - GeeksforGeeks 104.		Ugly Numbers - GeeksforGeeks 105.		Largest Sum Contiguous Subarray - GeeksforGeeks 106.		Longest Palindromic Substring | Set 1 - GeeksforGeeks 107.		Bellman–Ford Algorithm | DP-23 - GeeksforGeeks 108.		Optimal Binary Search Tree | DP-24 - GeeksforGeeks 109.		Largest Independent Set Problem | DP-26 - GeeksforGeeks 110.		Dynamic Programming - Subset Sum Problem 111.		Maximum sum rectangle in a 2D matrix | DP-27 - GeeksforGeeks 112.		Count number of binary strings without consecutive 1's - GeeksforGeeks 113.		Boolean Parenthesization Problem | DP-37 - GeeksforGeeks 114.		Count ways to reach the n'th stair - GeeksforGeeks 115.		Minimum Cost Polygon Triangulation - GeeksforGeeks 116.		Mobile Numeric Keypad Problem - GeeksforGeeks 117.		Count of n digit numbers whose sum of digits equals to given sum - GeeksforGeeks 118.		Minimum Initial Points to Reach Destination - GeeksforGeeks 119.		Total number of non-decreasing numbers with n digits - GeeksforGeeks 120.		Find length of the longest consecutive path from a given starting character - GeeksforGeeks 121.		Tiling Problem - GeeksforGeeks 122.		Minimum number of squares whose sum equals to given number n - GeeksforGeeks 123.		Find minimum number of coins that make a given value - GeeksforGeeks 124.		Collect maximum points in a grid using two traversals - GeeksforGeeks 125.		Shortest Common Supersequence - GeeksforGeeks 126.		Compute sum of digits in all numbers from 1 to n - GeeksforGeeks 127.		Count possible ways to construct buildings - GeeksforGeeks 128.		Maximum profit by buying and selling a share at most twice - GeeksforGeeks 129.		How to print maximum number of A's using given four keys - GeeksforGeeks 130.		Find the minimum cost to reach destination using a train - GeeksforGeeks 131.		Vertex Cover Problem | Set 2 (Dynamic Programming Solution for Tree) - GeeksforGeeks 132.		Count number of ways to reach a given score in a game - GeeksforGeeks 133.		Weighted Job Scheduling - GeeksforGeeks 134.		Longest Even Length Substring such that Sum of First and Second Half is same - GeeksforGeeks 135.		Naive algorithm for Pattern Searching - GeeksforGeeks 136.		KMP Algorithm for Pattern Searching - GeeksforGeeks 137.		Rabin-Karp Algorithm for Pattern Searching - GeeksforGeeks 138.		Optimized Naive Algorithm for Pattern Searching - GeeksforGeeks 139.		Finite Automata algorithm for Pattern Searching - GeeksforGeeks 140.		Pattern Searching | Set 6 (Efficient Construction of Finite Automata) - GeeksforGeeks 141.		Boyer Moore Algorithm for Pattern Searching - GeeksforGeeks 142.		Suffix Array | Set 1 (Introduction) - GeeksforGeeks 143.		Anagram Substring Search (Or Search for all permutations) - GeeksforGeeks 144.		Pattern Searching using a Trie of all Suffixes - GeeksforGeeks 145.		Aho-Corasick Algorithm for Pattern Searching - GeeksforGeeks 146.		­­kasai’s Algorithm for Construction of LCP array from Suffix Array - GeeksforGeeks 147.		Z algorithm (Linear time pattern searching Algorithm) - GeeksforGeeks 148.		Program to wish Women's Day - GeeksforGeeks 149.		Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 1 - GeeksforGeeks 150.		Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 2 - GeeksforGeeks 151.		Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 3 - GeeksforGeeks 152.		Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 4 - GeeksforGeeks 153.		Longest Even Length Substring such that Sum of First and Second Half is same - GeeksforGeeks 154.		Print all possible strings that can be made by placing spaces - GeeksforGeeks 155.		Write a program to print all permutations of a given string - GeeksforGeeks 156.		The Knight's tour problem | Backtracking-1 - GeeksforGeeks 157.		Rat in a Maze | Backtracking-2 - GeeksforGeeks 158.		N Queen Problem | Backtracking-3 - GeeksforGeeks 159.		Subset Sum | Backtracking-4 - GeeksforGeeks 160.		m Coloring Problem | Backtracking-5 - GeeksforGeeks 161.		Hamiltonian Cycle | Backtracking-6 - GeeksforGeeks 162.		Sudoku | Backtracking-7 - GeeksforGeeks 163.		Tug of War - GeeksforGeeks 164.		Solving Cryptarithmetic Puzzles | Backtracking-8 - GeeksforGeeks 165.		Divide and Conquer Algorithm | Introduction - GeeksforGeeks 166.		Write a program to calculate pow(x,n) - GeeksforGeeks 167.		Median of two sorted arrays of same size - GeeksforGeeks 168.		Count Inversions in an array | Set 1 (Using Merge Sort) - GeeksforGeeks 169.		Closest Pair of Points using Divide and Conquer algorithm - GeeksforGeeks 170.		Divide and Conquer | Set 5 (Strassen's Matrix Multiplication) - GeeksforGeeks 171.		Quick Sort vs Merge Sort - GeeksforGeeks 172.		Closest Pair of Points | O(nlogn) Implementation - GeeksforGeeks 173.		How to check if two given line segments intersect? - GeeksforGeeks 174.		How to check if a given point lies inside or outside a polygon? - GeeksforGeeks 175.		Convex Hull | Set 1 (Jarvis's Algorithm or Wrapping) - GeeksforGeeks 176.		Convex Hull | Set 2 (Graham Scan) - GeeksforGeeks 177.		Given n line segments, find if any two segments intersect - GeeksforGeeks 178.		Check whether a given point lies inside a triangle or not - GeeksforGeeks 179.		How to check if given four points form a square - GeeksforGeeks 180.		Write an Efficient Method to Check if a Number is Multiple of 3 - GeeksforGeeks 181.		Efficient way to multiply with 7 - GeeksforGeeks 182.		Write a program to print all permutations of a given string - GeeksforGeeks 183.		Lucky Numbers - GeeksforGeeks 184.		Write a program to add two numbers in base 14 - GeeksforGeeks 185.		Babylonian method for square root - GeeksforGeeks 186.		Multiply two integers without using multiplication, division and bitwise operators, and no loops - GeeksforGeeks 187.		Print all combinations of points that can compose a given number - GeeksforGeeks 188.		Write you own Power without using multiplication(*) and division(/) operators - GeeksforGeeks 189.		Program for Fibonacci numbers - GeeksforGeeks 190.		Average of a stream of numbers - GeeksforGeeks 191.		Count numbers that don't contain 3 - GeeksforGeeks 192.		Magic Square - GeeksforGeeks 193.		Sieve of Eratosthenes - GeeksforGeeks 194.		Number which has the maximum number of distinct prime factors in the range M to N - GeeksforGeeks 195.		Find day of the week for a given date - GeeksforGeeks 196.		DFA based division - GeeksforGeeks 197.		Generate integer from 1 to 7 with equal probability - GeeksforGeeks 198.		Given a number, find the next smallest palindrome - GeeksforGeeks 199.		Make a fair coin from a biased coin - GeeksforGeeks 200.		Check divisibility by 7 - GeeksforGeeks 201.		Find the largest multiple of 3 | Set 1 (Using Queue) - GeeksforGeeks 202.		Lexicographic rank of a string - GeeksforGeeks 203.		Print all permutations in sorted (lexicographic) order - GeeksforGeeks 204.		Shuffle a given array using Fisher–Yates shuffle Algorithm - GeeksforGeeks 205.		Space and time efficient Binomial Coefficient - GeeksforGeeks 206.		Reservoir Sampling - GeeksforGeeks 207.		Pascal's Triangle - GeeksforGeeks 208.		Select a random number from stream, with O(1) space - GeeksforGeeks 209.		Find the largest multiple of 2, 3 and 5 - GeeksforGeeks 210.		Efficient program to calculate e^x - GeeksforGeeks 211.		Measure one litre using two vessels and infinite water supply 212.		Efficient program to print all prime factors of a given number 213.		Print all possible combinations of r elements in a given array of size n - GeeksforGeeks 214.		Random number generator in arbitrary probability distribution fashion - GeeksforGeeks 215.		How to check if a given number is Fibonacci number? - GeeksforGeeks 216.		Russian Peasant (Multiply two numbers using bitwise operators) - GeeksforGeeks 217.		Count all possible groups of size 2 or 3 that have sum as multiple of 3 - GeeksforGeeks 218.		Program for Tower of Hanoi - GeeksforGeeks 219.		Horner's Method for Polynomial Evaluation - GeeksforGeeks 220.		Count trailing zeroes in factorial of a number - GeeksforGeeks 221.		Program for nth Catalan Number - GeeksforGeeks 222.		Write a function that generates one of 3 numbers according to given probabilities - GeeksforGeeks 223.		Find Excel column name from a given column number - GeeksforGeeks 224.		Find next greater number with same set of digits - GeeksforGeeks 225.		Count Possible Decodings of a given Digit Sequence - GeeksforGeeks 226.		Calculate the angle between hour hand and minute hand - GeeksforGeeks 227.		Count number of binary strings without consecutive 1's - GeeksforGeeks 228.		Find the smallest number whose digits multiply to a given number n - GeeksforGeeks 229.		Draw a circle without floating point arithmetic - GeeksforGeeks 230.		How to check if an instance of 8 puzzle is solvable? - GeeksforGeeks 231.		Birthday Paradox - GeeksforGeeks 232.		Multiply two polynomials - GeeksforGeeks 233.		Count Distinct Non-Negative Integer Pairs (x, y) that Satisfy the Inequality x*x + y*y < n - GeeksforGeeks 234.		Count ways to reach the n'th stair - GeeksforGeeks 235.		Replace all ‘0’ with ‘5’ in an input Integer - GeeksforGeeks 236.		Program to add two polynomials - GeeksforGeeks 237.		Print first k digits of 1/n where n is a positive integer - GeeksforGeeks 238.		Given a number as a string, find the number of contiguous subsequences which recursively add up to 9 - GeeksforGeeks 239.		Program for Bisection Method - GeeksforGeeks 240.		Program for Method Of False Position - GeeksforGeeks 241.		Program for Newton Raphson Method - GeeksforGeeks 242.		Find the element that appears once - GeeksforGeeks 243.		Detect if two integers have opposite signs - GeeksforGeeks 244.		Count total set bits in all numbers from 1 to n - GeeksforGeeks 245.		Swap bits in a given number - GeeksforGeeks 246.		Add two numbers without using arithmetic operators - GeeksforGeeks 247.		Smallest of three integers without comparison operators - GeeksforGeeks 248.		A Boolean Array Puzzle - GeeksforGeeks 249.		Program to count number of set bits in an (big) array - GeeksforGeeks 250.		Next higher number with same number of set bits - GeeksforGeeks 251.		Optimization Techniques | Set 1 (Modulus) - GeeksforGeeks 252.		Add 1 to a given number - GeeksforGeeks 253.		Multiply a given Integer with 3.5 - GeeksforGeeks 254.		Turn off the rightmost set bit - GeeksforGeeks 255.		Find whether a given number is a power of 4 or not - GeeksforGeeks 256.		Compute the integer absolute value (abs) without branching - GeeksforGeeks 257.		Compute modulus division by a power-of-2-number - GeeksforGeeks 258.		Compute the minimum or maximum of two integers without branching - GeeksforGeeks 259.		Rotate bits of a number - GeeksforGeeks 260.		Find the two non-repeating elements in an array of repeating elements - GeeksforGeeks 261.		Find the Number Occurring Odd Number of Times - GeeksforGeeks 262.		Check for Integer Overflow - GeeksforGeeks 263.		Little and Big Endian Mystery - GeeksforGeeks 264.		Write an Efficient C Program to Reverse Bits of a Number - GeeksforGeeks 265.		Count set bits in an integer - GeeksforGeeks 266.		Count number of bits to be flipped to convert A to B - GeeksforGeeks 267.		Smallest power of 2 greater than or equal to n - GeeksforGeeks 268.		Write an Efficient Method to Check if a Number is Multiple of 3 - GeeksforGeeks 269.		Program to find parity - GeeksforGeeks 270.		Efficient way to multiply with 7 - GeeksforGeeks 271.		Program to find whether a no is power of two - GeeksforGeeks 272.		Position of rightmost set bit - GeeksforGeeks 273.		Binary representation of a given number - GeeksforGeeks 274.		Swap all odd and even bits - GeeksforGeeks 275.		Find position of the only set bit - GeeksforGeeks 276.		Karatsuba algorithm for fast multiplication using Divide and Conquer algorithm - GeeksforGeeks 277.		How to swap two numbers without using a temporary variable? - GeeksforGeeks 278.		Check if a number is multiple of 9 using bitwise operators - GeeksforGeeks 279.		Swap two nibbles in a byte - GeeksforGeeks 280.		How to turn off a particular bit in a number? - GeeksforGeeks 281.		Check if binary representation of a number is palindrome - GeeksforGeeks 282.		Graph and its representations - GeeksforGeeks 283.		Breadth First Search or BFS for a Graph - GeeksforGeeks 284.		Depth First Search or DFS for a Graph - GeeksforGeeks 285.		Applications of Depth First Search - GeeksforGeeks 286.		Detect Cycle in a Directed Graph - GeeksforGeeks 287.		Disjoint Set (Or Union-Find) | Set 1 (Detect Cycle in an Undirected Graph) - GeeksforGeeks 288.		Detect cycle in an undirected graph - GeeksforGeeks 289.		Longest Path in a Directed Acyclic Graph - GeeksforGeeks 290.		Topological Sorting - GeeksforGeeks 291.		Check whether a given graph is Bipartite or not - GeeksforGeeks 292.		Snake and Ladder Problem - GeeksforGeeks 293.		Biconnected Components - GeeksforGeeks 294.		Check if a given graph is tree or not - GeeksforGeeks 295.		Prim’s Minimum Spanning Tree (MST) | Greedy Algo-5 - GeeksforGeeks 296.		Applications of Minimum Spanning Tree Problem - GeeksforGeeks 297.		Prim’s MST for Adjacency List Representation | Greedy Algo-6 - GeeksforGeeks 298.		Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2 - GeeksforGeeks 299.		Boruvka's algorithm | Greedy Algo-9 - GeeksforGeeks 300.		Dijsktra's algorithm 301.		Dijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8 - GeeksforGeeks 302.		Bellman–Ford Algorithm | DP-23 - GeeksforGeeks 303.		Floyd Warshall Algorithm | DP-16 - GeeksforGeeks 304.		Johnson's algorithm for All-pairs shortest paths - GeeksforGeeks 305.		Shortest Path in Directed Acyclic Graph - GeeksforGeeks 306.		Some interesting shortest path questions | Set 1 - GeeksforGeeks 307.		Shortest path with exactly k edges in a directed and weighted graph - GeeksforGeeks 308.		Find if there is a path between two vertices in a directed graph - GeeksforGeeks 309.		Check if a graph is strongly connected | Set 1 (Kosaraju using DFS) - GeeksforGeeks 310.		Articulation Points (or Cut Vertices) in a Graph - GeeksforGeeks 311.		Biconnected graph - GeeksforGeeks 312.		Bridges in a graph - GeeksforGeeks 313.		Eulerian path and circuit for undirected graph - GeeksforGeeks 314.		Fleury's Algorithm for printing Eulerian Path or Circuit - GeeksforGeeks 315.		Strongly Connected Components - GeeksforGeeks 316.		Transitive closure of a graph - GeeksforGeeks 317.		Find the number of islands | Set 1 (Using DFS) - GeeksforGeeks 318.		Count all possible walks from a source to a destination with exactly k edges - GeeksforGeeks 319.		Euler Circuit in a Directed Graph - GeeksforGeeks 320.		Biconnected Components - GeeksforGeeks 321.		Tarjan's Algorithm to find Strongly Connected Components - GeeksforGeeks 322.		Graph Coloring | Set 1 (Introduction and Applications) - GeeksforGeeks 323.		Graph Coloring | Set 2 (Greedy Algorithm) - GeeksforGeeks 324.		Travelling Salesman Problem | Set 1 (Naive and Dynamic Programming) - GeeksforGeeks 325.		Travelling Salesman Problem | Set 2 (Approximate using MST) - GeeksforGeeks 326.		Hamiltonian Cycle | Backtracking-6 - GeeksforGeeks 327.		Vertex Cover Problem | Set 1 (Introduction and Approximate Algorithm) - GeeksforGeeks 328.		K Centers Problem | Set 1 (Greedy Approximate Algorithm) - GeeksforGeeks 329.		Ford-Fulkerson Algorithm for Maximum Flow Problem - GeeksforGeeks 330.		Find maximum number of edge disjoint paths between two vertices - GeeksforGeeks 331.		Find minimum s-t cut in a flow network - GeeksforGeeks 332.		Maximum Bipartite Matching - GeeksforGeeks 333.		Channel Assignment Problem - GeeksforGeeks 334.		Find if an array of strings can be chained to form a circle | Set 1 - GeeksforGeeks 335.		Given a sorted dictionary of an alien language, find order of characters - GeeksforGeeks 336.		Karger's algorithm for Minimum Cut | Set 1 (Introduction and Implementation) - GeeksforGeeks 337.		Karger’s algorithm for Minimum Cut | Set 2 (Analysis and Applications) - GeeksforGeeks 338.		Hopcroft–Karp Algorithm for Maximum Matching | Set 1 (Introduction) - GeeksforGeeks 339.		Hopcroft–Karp Algorithm for Maximum Matching | Set 1 (Introduction) - GeeksforGeeks 340.		Word Ladder (Length of shortest chain to reach a target word) - GeeksforGeeks 341.		Find same contacts in a list of contacts - GeeksforGeeks 342.		Linearity of Expectation - GeeksforGeeks 343.		Expected Number of Trials until Success - GeeksforGeeks 344.		Randomized Algorithms | Set 0 (Mathematical Background) - GeeksforGeeks 345.		Randomized Algorithms | Set 1 (Introduction and Analysis) - GeeksforGeeks 346.		Randomized Algorithms | Set 2 (Classification and Applications) - GeeksforGeeks 347.		Randomized Algorithms | Set 3 (1/2 Approximate Median) - GeeksforGeeks 348.		Karger's algorithm for Minimum Cut | Set 1 (Introduction and Implementation) - GeeksforGeeks 349.		K'th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time) - GeeksforGeeks 350.		Reservoir Sampling - GeeksforGeeks 351.		Shuffle a given array using Fisher–Yates shuffle Algorithm - GeeksforGeeks 352.		Select a Random Node from a Singly Linked List - GeeksforGeeks 353.		0/1 Knapsack using Branch and Bound - GeeksforGeeks 354.		Implementation of 0/1 Knapsack using Branch and Bound - GeeksforGeeks 355.		8 puzzle Problem using Branch And Bound - GeeksforGeeks 356.		Job Assignment Problem using Branch And Bound - GeeksforGeeks 357.		N Queen Problem using Branch And Bound - GeeksforGeeks 358.		Traveling Salesman Problem using Branch And Bound - GeeksforGeeks 

Analysis of Algorithms | Set 1 (Asymptotic Analysis)


Why performance analysis?
There are many important things that should be taken care of, like user friendliness, modularity, security, maintainability, etc. Why to worry about performance? 
The answer to this is simple, we can have all the above things only if we have performance. So performance is like currency through which we can buy all the above things. Another reason for studying performance is – speed is fun!
To summarize, performance == scale. Imagine a text editor that can load 1000 pages, but can spell check 1 page per minute OR an image editor that takes 1 hour to rotate your image 90 degrees left OR … you get it. If a software feature can not cope with the scale of tasks users need to perform – it is as good as dead. 

Given two algorithms for a task, how do we find out which one is better?
One naive way of doing this is – implement both the algorithms and run the two programs on your computer for different inputs and see which one takes less time. There are many problems with this approach for analysis of algorithms.
1) It might be possible that for some inputs, first algorithm performs better than the second. And for some inputs second performs better.
2) It might also be possible that for some inputs, first algorithm perform better on one machine and the second works better on other machine for some other inputs.
Asymptotic Analysis is the big idea that handles above issues in analyzing algorithms. In Asymptotic Analysis, we evaluate the performance of an algorithm in terms of input size (we don’t measure the actual running time). We calculate, how does the time (or space) taken by an algorithm increases with the input size.
For example, let us consider the search problem (searching a given item) in a sorted array. One way to search is Linear Search (order of growth is linear) and other way is Binary Search (order of growth is logarithmic). To understand how Asymptotic Analysis solves the above mentioned problems in analyzing algorithms, let us say we run the Linear Search on a fast computer and Binary Search on a slow computer. For small values of input array size n, the fast computer may take less time. But, after certain value of input array size, the Binary Search will definitely start taking less time compared to the Linear Search even though the Binary Search is being run on a slow machine. The reason is the order of growth of Binary Search with respect to input size logarithmic while the order of growth of Linear Search is linear. So the machine dependent constants can always be ignored after certain values of input size.





Does Asymptotic Analysis always work?
Asymptotic Analysis is not perfect, but that’s the best way available for analyzing algorithms. For example, say there are two sorting algorithms that take 1000nLogn and 2nLogn time respectively on a machine. Both of these algorithms are asymptotically same (order of growth is nLogn). So, With Asymptotic Analysis, we can’t judge which one is better as we ignore constants in Asymptotic Analysis.
Also, in Asymptotic analysis, we always talk about input sizes larger than a constant value. It might be possible that those large inputs are never given to your software and an algorithm which is asymptotically slower, always performs better for your particular situation. So, you may end up choosing an algorithm that is Asymptotically slower but faster for your software.

Next – Analysis of Algorithms | Set 2 (Worst, Average and Best Cases)

References:
MIT’s Video lecture 1 on Introduction to Algorithms.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.








My Personal Notes
arrow_drop_up





Save


Recommended Posts:Analysis of Algorithms | Set 3 (Asymptotic Notations)Asymptotic Analysis and comparison of sorting algorithmsAnalysis of Algorithms | Set 4 (Analysis of Loops)Analysis of Algorithms | Big-O analysisAnalysis of Algorithm | Set 5 (Amortized Analysis Introduction)Analysis of Algorithms | Set 5 (Practice Problems)Analysis of algorithms | little o and little omega notationsAnalysis of Algorithms | Set 2 (Worst, Average and Best Cases)Algorithms  Sample Questions | Set 3 | Time Order AnalysisAnalysis of different sorting techniquesComplexity Analysis of Binary SearchAnalysis of Algorithm | Set 4 (Solving Recurrences)Amortized analysis for increment in counterDifference between Posteriori and Priori analysisPractice Questions on Time Complexity AnalysisImproved By :  Danail Kozhuharov

Article Tags : AnalysisArticles
 

thumb_up
142



To-do

Done



1.3


Based on 452 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Analysis of Algorithms | Set 2 (Worst, Average and Best Cases)


In the previous post, we discussed how Asymptotic analysis overcomes the problems of naive way of analyzing algorithms. In this post, we will take an example of Linear Search and analyze it using Asymptotic analysis.
We can have three cases to analyze an algorithm:
1) Worst Case
2) Average Case
3) Best Case
Let us consider the following implementation of Linear Search.

C++












filter_none

Analysis of Algorithms | Set 3 (Asymptotic Notations)


We have discussed Asymptotic Analysis, and Worst, Average and Best Cases of Algorithms. The main idea of asymptotic analysis is to have a measure of efficiency of algorithms that doesn’t depend on machine specific constants, and doesn’t require algorithms to be implemented and time taken by programs to be compared. Asymptotic notations are mathematical tools to represent time complexity of algorithms for asymptotic analysis. The following 3 asymptotic notations are mostly used to represent time complexity of algorithms.
1) Θ Notation: The theta notation bounds a functions from above and below, so it defines exact asymptotic behavior.
A simple way to get Theta notation of an expression is to drop low order terms and ignore leading constants. For example, consider the following expression.
3n3 + 6n2 + 6000 = Θ(n3)
Dropping lower order terms is always fine because there will always be a n0 after which Θ(n3) has higher values than Θn2) irrespective of the constants involved.
For a given function g(n), we denote Θ(g(n)) is following set of functions.
Θ(g(n)) = {f(n): there exist positive constants c1, c2 and n0 such 
                 that 0 <= c1*g(n) <= f(n) <= c2*g(n) for all n >= n0}
The above definition means, if f(n) is theta of g(n), then the value f(n) is always between c1*g(n) and c2*g(n) for large values of n (n >= n0). The definition of theta also requires that f(n) must be non-negative for values of n greater than n0.







Analysis of algorithms | little o and little omega notations


The main idea of asymptotic analysis is to have a measure of efficiency of algorithms that doesn’t depend on machine specific constants, mainly because this analysis doesn’t require algorithms to be implemented and time taken by programs to be compared. We have already discussed Three main asymptotic notations

Lower and Upper Bound Theory


The Lower and Upper Bound Theory provides a way to find the lowest complexity algorithm to solve a problem. Before understanding the theory, first lets have a brief look on what actually Lower and Upper bounds are. 

Lower Bound –
Let L(n) be the running time of an algorithm A(say), then g(n) is the Lower Bound of A if there exist two constants C and N such that L(n) <= C*g(n) for n > N. Lower bound of an algorithm is shown by the asymptotic notation called Big Omega (or just Omega). 

Analysis of Algorithms | Set 4 (Analysis of Loops)


We have discussed Asymptotic Analysis,  Worst, Average and Best Cases  and Asymptotic Notations in previous posts. In this post, analysis of iterative programs with simple examples is discussed.
1) O(1): Time complexity of a function (or set of statements) is considered as O(1) if it doesn’t contain loop, recursion and call to any other non-constant time function.
   // set of non-recursive and non-loop statements
For example swap() function has O(1) time complexity.
A loop or recursion that runs a constant number of times is also considered as O(1). For example the following loop is O(1).





   // Here c is a constant   
   for (int i = 1; i <= c; i++) {  
        // some O(1) expressions
   }
2) O(n): Time Complexity of a loop is considered as O(n) if the loop variables is incremented / decremented by a constant amount. For example following functions have O(n) time complexity.
   // Here c is a positive integer constant   
   for (int i = 1; i <= n; i += c) {  
        // some O(1) expressions
   }

   for (int i = n; i > 0; i -= c) {
        // some O(1) expressions
   }
3) O(nc): Time complexity of nested loops is equal to the number of times the innermost statement is executed. For example the following sample loops have O(n2) time complexity
  
   for (int i = 1; i <=n; i += c) {
       for (int j = 1; j <=n; j += c) {
          // some O(1) expressions
       }
   }

   for (int i = n; i > 0; i -= c) {
       for (int j = i+1; j <=n; j += c) {
          // some O(1) expressions
   }
For example Selection sort and Insertion Sort have O(n2) time complexity.
4) O(Logn) Time Complexity of a loop is considered as O(Logn) if the loop variables is divided / multiplied by a constant amount.
   for (int i = 1; i <=n; i *= c) {
       // some O(1) expressions
   }
   for (int i = n; i > 0; i /= c) {
       // some O(1) expressions
   }
For example Binary Search(refer iterative implementation) has O(Logn) time complexity. Let us see mathematically how it is O(Log n). The series that we get in first loop is 1, c, c2, c3, … ck.  If we put k equals to Logcn, we get cLogcn which is n.
5) O(LogLogn) Time Complexity of a loop is considered as O(LogLogn) if the loop variables is reduced / increased exponentially by a constant amount.
   // Here c is a constant greater than 1   
   for (int i = 2; i <=n; i = pow(i, c)) { 
       // some O(1) expressions
   }
   //Here fun is sqrt or cuberoot or any other constant root
   for (int i = n; i > 1; i = fun(i)) { 
       // some O(1) expressions
   }
See this for mathematical details.
How to combine time complexities of consecutive loops?
When there are consecutive loops, we calculate time complexity as sum of time complexities of individual loops.
   for (int i = 1; i <=m; i += c) {  
        // some O(1) expressions
   }
   for (int i = 1; i <=n; i += c) {
        // some O(1) expressions
   }
   Time complexity of above code is O(m) + O(n) which is O(m+n)
   If m == n, the time complexity becomes O(2n) which is O(n).   

How to calculate time complexity when there are many if, else statements inside loops?
As discussed here, worst case time complexity is the most useful among best, average and worst. Therefore we need to consider worst case. We evaluate the situation when values in if-else conditions cause maximum number of statements to be executed.
For example consider the linear search function where we consider the case when element is present at the end or not present at all.
When the code is too complex to consider all if-else cases, we can get an upper bound by ignoring if else and other complex control statements.
How to calculate time complexity of recursive functions?
Time complexity of a recursive function can be written as a mathematical recurrence relation. To calculate time complexity, we must know how to solve recurrences. We will soon be discussing recurrence solving techniques as a separate post.
Quiz on Analysis of Algorithms
Next – Analysis of Algorithm | Set 4 (Solving Recurrences)
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Analysis of Algorithms | Set 1 (Asymptotic Analysis)Analysis of Algorithms | Big-O analysisAnalysis of Algorithm | Set 5 (Amortized Analysis Introduction)Analysis of Algorithms | Set 5 (Practice Problems)Analysis of algorithms | little o and little omega notationsAnalysis of Algorithms | Set 3 (Asymptotic Notations)Asymptotic Analysis and comparison of sorting algorithmsAnalysis of Algorithms | Set 2 (Worst, Average and Best Cases)Algorithms  Sample Questions | Set 3 | Time Order AnalysisAnalysis of different sorting techniquesAnalysis of Algorithm | Set 4 (Solving Recurrences)Complexity Analysis of Binary SearchDifference between Posteriori and Priori analysisAmortized analysis for increment in counterPractice Questions on Time Complexity Analysis

Article Tags : AnalysisArticles
 

thumb_up
67



To-do

Done



1.4


Based on 201 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Analysis of Algorithm | Set 4 (Solving Recurrences)



In the previous post, we discussed analysis of loops. Many algorithms are recursive in nature. When we analyze them, we get a recurrence relation for time complexity. We get running time on an input of size n as a function of n and the running time on inputs of smaller sizes. For example in Merge Sort, to sort a given array, we divide it in two halves and recursively repeat the process for the two halves. Finally we merge the results. Time complexity of Merge Sort can be written as T(n) = 2T(n/2) + cn. There are many other algorithms like Binary Search, Tower of Hanoi, etc.
There are mainly three ways for solving recurrences.
1) Substitution Method: We make a guess for the solution and then we use mathematical induction to prove the guess is correct or incorrect.






For example consider the recurrence T(n) = 2T(n/2) + n

We guess the solution as T(n) = O(nLogn). Now we use induction
to prove our guess.

We need to prove that T(n) <= cnLogn. We can assume that it is true
for values smaller than n.

T(n) = 2T(n/2) + n
    <= cn/2Log(n/2) + n
    =  cnLogn - cnLog2 + n
    =  cnLogn - cn + n
    <= cnLogn
2) Recurrence Tree Method: In this method, we draw a recurrence tree and calculate the time taken by every level of tree. Finally, we sum the work done at all levels. To draw the recurrence tree, we start from the given recurrence and keep drawing till we find a pattern among levels. The pattern is typically a arithmetic or geometric series.
For example consider the recurrence relation 
T(n) = T(n/4) + T(n/2) + cn2

           cn2
         /      \
     T(n/4)     T(n/2)

If we further break down the expression T(n/4) and T(n/2), 
we get following recursion tree.

                cn2
           /           \      
       c(n2)/16      c(n2)/4
      /      \          /     \
  T(n/16)     T(n/8)  T(n/8)    T(n/4) 
Breaking down further gives us following
                 cn2
            /            \      
       c(n2)/16          c(n2)/4
       /      \            /      \
c(n2)/256   c(n2)/64  c(n2)/64    c(n2)/16
 /    \      /    \    /    \       /    \  

To know the value of T(n), we need to calculate sum of tree 
nodes level by level. If we sum the above tree level by level, 
we get the following series
T(n)  = c(n^2 + 5(n^2)/16 + 25(n^2)/256) + ....
The above series is geometrical progression with ratio 5/16.

To get an upper bound, we can sum the infinite series. 
We get the sum as (n2)/(1 - 5/16) which is O(n2)
3) Master Method:
Master Method is a direct way to get the solution. The master method works only for following type of recurrences or for recurrences that can be transformed to following type.
T(n) = aT(n/b) + f(n) where a >= 1 and b > 1
There are following three cases:
1. If f(n) = Θ(nc) where c < Logba then T(n) = Θ(nLogba)
2. If f(n) = Θ(nc) where c = Logba then T(n) = Θ(ncLog n)
3.If f(n) = Θ(nc) where c > Logba then T(n) = Θ(f(n))
How does this work?
Master method is mainly derived from recurrence tree method. If we draw recurrence tree of T(n) = aT(n/b) + f(n), we can see that the work done at root is f(n) and work done at all leaves is Θ(nc) where c is Logba. And the height of recurrence tree is Logbn

In recurrence tree method, we calculate total work done. If the work done at leaves is polynomially more, then leaves are the dominant part, and our result becomes the work done at leaves (Case 1). If work done at leaves and root is asymptotically same, then our result becomes height multiplied by work done at any level (Case 2). If work done at root is asymptotically more, then our result becomes work done at root (Case 3).
Examples of some standard algorithms whose time complexity can be evaluated using Master Method 
Merge Sort: T(n) = 2T(n/2) + Θ(n). It falls in case 2 as c is 1 and Logba] is also 1. So the solution is Θ(n Logn)
Binary Search: T(n) = T(n/2) + Θ(1). It also falls in case 2 as c is 0 and Logba is also 0. So the solution is Θ(Logn)
Notes: 
1) It is not necessary that a recurrence of the form T(n) = aT(n/b) + f(n) can be solved using Master Theorem. The given three cases have some gaps between them. For example, the recurrence T(n) = 2T(n/2) + n/Logn cannot be solved using master method.
2) Case 2 can be extended for f(n) = Θ(ncLogkn)
If f(n) = Θ(ncLogkn) for some constant k >= 0 and c = Logba, then T(n) = Θ(ncLogk+1n)
Practice Problems and Solutions on Master Theorem.
Next – Analysis of Algorithm | Set 5 (Amortized Analysis Introduction)
References:
http://en.wikipedia.org/wiki/Master_theorem
MIT Video Lecture on Asymptotic Notation | Recurrences | Substitution, Master Method
Introduction to Algorithms 3rd Edition by Clifford Stein, Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Analysis of Algorithms | Set 1 (Asymptotic Analysis)Analysis of Algorithms | Set 2 (Worst, Average and Best Cases)Analysis of Algorithms | Set 3 (Asymptotic Notations)Analysis of Algorithms | Set 4 (Analysis of Loops)Analysis of Algorithm | Set 5 (Amortized Analysis Introduction)Algorithm Practice Question for Beginners | Set 1Asymptotic Analysis and comparison of sorting algorithmsAnalysis of Algorithms | Set 5 (Practice Problems)Master Theorem For Subtract and Conquer RecurrencesJump Pointer AlgorithmAnalysis of algorithms | little o and little omega notationsOnline AlgorithmPractice Questions on Time Complexity AnalysisAdvanced master theorem for divide and conquer recurrencesAnalysis of different sorting techniquesImproved By :  Manish Dhanuka

Article Tags : Analysis
 

thumb_up
27



To-do

Done



2.8


Based on 189 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Analysis of Algorithm | Set 5 (Amortized Analysis Introduction)


Amortized Analysis is used for algorithms where an occasional operation is very slow, but most of the other operations are faster.  In Amortized Analysis, we analyze a sequence of operations and guarantee a worst case average time which is lower than the worst case time of a particular expensive operation.
The example data structures whose operations are analyzed using Amortized Analysis are Hash Tables, Disjoint Sets and Splay Trees.
Let us consider an example of a simple hash table insertions. How do we decide table size? There is a trade-off between space and time, if we make hash-table size big, search time becomes fast, but space required becomes high.






The solution to this trade-off problem is to use Dynamic Table (or Arrays). The idea is to increase size of table whenever it becomes full. Following are the steps to follow when table becomes full.
1) Allocate memory for a larger table of size, typically twice the old table.
2) Copy the contents of old table to new table.
3) Free the old table.
If the table has space available, we simply insert new item in available space.
What is the time complexity of n insertions using the above scheme?
If we use simple analysis, the worst case cost of an insertion is O(n). Therefore, worst case cost of n inserts is n * O(n) which is O(n2). This analysis gives an upper bound, but not a tight upper bound for n insertions as all insertions don’t take Θ(n) time.

So using Amortized Analysis, we could prove that the Dynamic Table scheme has O(1) insertion time which is a great result used in hashing.  Also, the concept of dynamic table is used in vectors in C++, ArrayList in Java.
Following are few important notes.
1)  Amortized cost of a sequence of operations can be seen as expenses of a salaried person. The average monthly expense of the person is less than or equal to the salary, but the person can spend more money in a particular month by buying a car or something. In other months, he or she saves money for the expensive month.
2) The above Amortized Analysis done for Dynamic Array example is called Aggregate Method.  There are two more powerful ways to do Amortized analysis called Accounting Method and Potential Method.  We will be discussing the other two methods in separate posts.  
3)  The amortized analysis doesn’t involve probability. There is also another different notion of average case running time where algorithms use randomization to make them faster and expected running time is faster than the worst case running time. These algorithms are analyzed using Randomized Analysis. Examples of these algorithms are Randomized Quick Sort, Quick Select and Hashing. We will soon be covering Randomized analysis in a different post.
Sources:
Berkeley Lecture 35: Amortized Analysis 
MIT Lecture 13: Amortized Algorithms, Table Doubling, Potential Method 
http://www.cs.cornell.edu/courses/cs3110/2011sp/lectures/lec20-amortized/amortized.htm
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Analysis of Algorithms | Set 1 (Asymptotic Analysis)Analysis of Algorithms | Set 2 (Worst, Average and Best Cases)Analysis of Algorithms | Set 3 (Asymptotic Notations)NP-Completeness | Set 1 (Introduction)Analysis of Algorithm | Set 4 (Solving Recurrences)Analysis of Algorithms | Set 4 (Analysis of Loops)Algorithm Practice Question for Beginners | Set 1Asymptotic Analysis and comparison of sorting algorithmsAnalysis of Algorithms | Set 5 (Practice Problems)Jump Pointer AlgorithmAnalysis of algorithms | little o and little omega notationsOnline AlgorithmPractice Questions on Time Complexity AnalysisAnalysis of different sorting techniquesAnalysis of Algorithms | Big-O analysis

Article Tags : Analysis
 

thumb_up
24



To-do

Done



2.6


Based on 113 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



What does ‘Space Complexity’ mean?


Space Complexity:
The term Space Complexity is misused for Auxiliary Space at many places. Following are the correct definitions of Auxiliary Space and Space Complexity.
Auxiliary Space is the extra space or temporary space used by an algorithm.
Space Complexity of an algorithm is total space taken by the algorithm with respect to the input size.  Space complexity includes both  Auxiliary space and space used by input.





For example, if we want to compare standard sorting algorithms on the basis of space, then Auxiliary Space would be a better criteria than Space Complexity.  Merge Sort uses O(n) auxiliary space, Insertion sort and Heap Sort use O(1) auxiliary space.  Space complexity of all these sorting algorithms is O(n) though.
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Number of pairs in an array having sum equal to productMinimize the sum of digits of A and B such that A + B = NMultiplication on Array : Range update query in O(1)Optimal Strategy for a Game | Special Gold CoinFind the coordinates of a triangle whose Area = (S / 2)Rearrange array elements such that Bitwise AND of first N - 1 elements is equal to last elementMaximum prime moves to convert X to YSum of Digits of the Good StringsCount non-adjacent subsets from numbers arranged in Circular fashionMinimize sum by dividing all elements of a subarray by KFind Range Value of the ExpressionMinimum numbers with one's place as 9 to be added to get NMinimum increment or decrement operations required to make the array sortedSum of numbers in a range [L, R] whose count of divisors is primeMinimize the cost of partitioning an array into K groups

Article Tags : Analysis
 

thumb_up
32



To-do

Done



1.5


Based on 158 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Pseudo-polynomial Algorithms


What is Pseudo-polynomial? 
An algorithm whose worst case time complexity depends on numeric value of input (not number of inputs) is called Pseudo-polynomial algorithm.
For example, consider the problem of counting frequencies of all elements in an array of positive numbers. A pseudo-polynomial time solution for this is to first find the maximum value, then iterate from 1 to maximum value and for each value, find its frequency in array. This solution requires time according to maximum value in input array, therefore pseudo-polynomial. On the other hand, an algorithm whose time complexity is only based on number of elements in array (not value) is considered as polynomial time algorithm.
Pseudo-polynomial and NP-Completeness
Some NP-Complete problems have Pseudo Polynomial time solutions. For example, Dynamic Programming Solutions of 0-1 Knapsack, Subset-Sum and Partition problems are Pseudo-Polynomial. NP complete problems that can be solved using a pseudo-polynomial time algorithms are called weakly NP-complete.
Reference:
https://en.wikipedia.org/wiki/Pseudo-polynomial_time





This article is contributed by Dheeraj Gupta. If you like GeeksforGeeks and would like to contribute, you can also write an article and mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Algorithms | Recurrences | Set 1Analysis of algorithms | little o and little omega notationsAlgorithms Sample Questions | Recurrences | Set 2Analysis of Algorithms | Set 3 (Asymptotic Notations)Analysis of Algorithms | Set 5 (Practice Problems)Asymptotic Analysis and comparison of sorting algorithmsSorting Algorithms Visualization : Bubble SortAnalysis of Algorithms | Set 2 (Worst, Average and Best Cases)Algorithms  Sample Questions | Set 3 | Time Order AnalysisLoop Invariant Condition with Examples of Sorting AlgorithmsAnalysis of Algorithms | Set 1 (Asymptotic Analysis)Difference between Deterministic and Non-deterministic AlgorithmsAnalysis of Algorithms | Set 4 (Analysis of Loops)Analysis of Algorithms | Big-O analysis

Article Tags : Analysisknapsack
 

thumb_up
7



To-do

Done



2.3


Based on 79 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



NP-Completeness | Set 1 (Introduction)



We have been writing about efficient algorithms to solve complex problems, like shortest path, Euler graph, minimum spanning tree, etc. Those were all success stories of algorithm designers. In this post, failure stories of computer science are discussed.
Can all computational problems be solved by a computer? There are computational problems that can not be solved by algorithms even with unlimited time. For example Turing Halting problem (Given a program and an input, whether the program will eventually halt when run with that input, or will run forever). Alan Turing proved that general algorithm to solve the halting problem for all possible program-input pairs cannot exist. A key part of the proof is, Turing machine was used as a mathematical definition of a computer and program (Source  Halting Problem).
Status of NP Complete problems is another failure story, NP complete problems are problems whose status is unknown. No polynomial time algorithm has yet been discovered for any NP complete problem, nor has anybody yet been able to prove that no polynomial-time algorithm exist for any of them. The interesting part is, if any one of the NP complete problems can be solved in polynomial time, then all of them can be solved.






What are NP, P, NP-complete and NP-Hard problems?
P is set of problems that can be solved by a deterministic Turing machine in Polynomial time.
NP is set of decision problems that can be solved by a Non-deterministic Turing Machine in Polynomial time. P is subset of NP (any problem that can be solved by deterministic machine in polynomial time can also be solved by non-deterministic machine in polynomial time).
Informally, NP is set of decision problems which can be solved by a polynomial time via a “Lucky Algorithm”, a magical algorithm that always makes a right guess among the given set of choices (Source Ref 1).
NP-complete problems are the hardest problems in NP set.  A decision problem L is NP-complete if:
1) L is in NP (Any given solution for NP-complete problems can be verified quickly, but there is no efficient known solution).
2) Every problem in NP is reducible to L in polynomial time (Reduction is defined below).
A problem is NP-Hard if it follows property 2 mentioned above, doesn’t need to follow property 1. Therefore, NP-Complete set is also a subset of NP-Hard set.

Decision vs Optimization Problems
NP-completeness applies to the realm of decision problems.  It was set up this way because it’s easier to compare the difficulty of decision problems than that of optimization problems.   In reality, though, being able to solve a decision problem in polynomial time will often permit us to solve the corresponding optimization problem in polynomial time (using a polynomial number of calls to the decision problem). So, discussing the difficulty of decision problems is often really equivalent to discussing the difficulty of optimization problems. (Source Ref 2).
For example, consider the vertex cover problem (Given a graph, find out the minimum sized vertex set that covers all edges). It is an optimization problem. Corresponding decision problem is, given undirected graph G and k, is there a vertex cover of size k?
What is Reduction?
Let L1 and L2 be two decision problems. Suppose algorithm A2 solves L2. That is, if y is an input for L2 then algorithm A2 will answer Yes or No depending upon whether y belongs to L2 or not.
The idea is to find a transformation from L1 to L2 so that the algorithm A2 can be part of an algorithm A1 to solve L1.

Learning reduction in general is very important. For example, if we have library functions to solve certain problem and if we can reduce a new problem to one of the solved problems, we save a lot of time. Consider the example of a problem where we have to find minimum product path in a given directed graph where product of path is multiplication of weights of edges along the path. If we have code for Dijkstra’s algorithm to find shortest path, we can take log of all weights and use Dijkstra’s algorithm to find the minimum product path rather than writing a fresh code for this new problem.
How to prove that a given problem is NP complete?
From the definition of NP-complete, it appears impossible to prove that a problem L is NP-Complete.  By definition, it requires us to that show every problem in NP is polynomial time reducible to L.   Fortunately, there is an alternate way to prove it.   The idea is to take a known NP-Complete problem and reduce it to L.  If polynomial time reduction is possible, we can prove that L is NP-Complete by transitivity of reduction (If a NP-Complete problem is reducible to L in polynomial time, then all problems are reducible to L in polynomial time).
What was the first problem proved as NP-Complete?
There must be some first NP-Complete problem proved by definition of NP-Complete problems.  SAT (Boolean satisfiability problem) is the first NP-Complete problem proved by Cook (See CLRS book for proof).
It is always useful to know about NP-Completeness even for engineers. Suppose you are asked to write an efficient algorithm to solve an extremely important problem for your company. After a lot of thinking, you can only come up exponential time approach which is impractical. If you don’t know about NP-Completeness, you can only say that I could not come with an efficient algorithm. If you know about NP-Completeness and prove that the problem as NP-complete, you can proudly say that the polynomial time solution is unlikely to exist. If there is a polynomial time solution possible, then that solution solves a big problem of computer science many scientists have been trying for years.
We will soon be discussing more NP-Complete problems and their proof for NP-Completeness.
References:
MIT Video Lecture on Computational Complexity
Introduction to Algorithms 3rd Edition by Clifford Stein, Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest
http://www.ics.uci.edu/~eppstein/161/960312.html
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Introduction to ES6DHTML | IntroductionIntroduction to NodeJSIntroduction and Installation of  GitIntroduction to Blockchain technology | Set 2Introduction to Programming LanguagesImage Splicing | Set 1 (Introduction)Transportation Problem | Set 1 (Introduction)Introduction to RSS(Rich Summary Site)Vertex Cover Problem | Set 1 (Introduction and Approximate Algorithm)Introduction to Microsoft Azure | A cloud computing serviceAnalysis of Algorithm | Set 5 (Amortized Analysis Introduction)Introduction to Model View View Model (MVVM)Number of pairs in an array having sum equal to product

Article Tags : AnalysisArticlesNPHard
 

thumb_up
34



To-do

Done



4.1


Based on 145 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Polynomial Time Approximation Scheme


It is a very well know fact that there is no known polynomial time solution for NP Complete problems and these problems occur a lot in real world (See this, this and this for example).  So there must be a way to handle them.  We have seen algorithms to these problems which are p approximate (For example 2 approximate for Travelling Salesman). Can we do better?
Polynomial Time Approximation Scheme (PTAS) is a type of approximate algorithms that provide user to control over accuracy which is a desirable feature.  These algorithms take an additional parameter ε > 0 and provide a solution that is (1 + ε) approximate for minimization and (1 – ε) for maximization.  For example consider a minimization problem, if ε is 0.5, then the solution provided by the PTAS  algorithm is 1.5 approximate. The running time of PTAS must be polynomial in terms of n, however, it can be exponential in terms of ε. 
In PTAS algorithms, the exponent of the polynomial can increase dramatically as ε reduces, for example if the runtime is O(n(1/ε)!) which is a problem. There is a stricter scheme, Fully Polynomial Time Approximation Scheme (FPTAS).  In FPTAS,  algorithm need to polynomial in both the problem size n and 1/ε. 





Example (0-1 knapsack problem): 
      We know that 0-1 knapsack is NP Complete. There is a DP based  pseudo polynomial solution for this. But if input values are high, then the solution becomes infeasible and there is a need of approximate solution. One approximate solution is to use Greedy Approach (compute value per kg  for all items and put the highest value per kg first if it is smaller than W), but Greedy approach is not PTAS, so we don’t have control over accuracy.  
Below is a FPTAS solution for 0-1 Knapsack problem:
Input:
W (Capacity of Knapsack)
val[0..n-1] (Values of Items)
wt[0..n-1]  (Weights of Items)

Find the maximum valued item, i.e., find maximum value in val[]. Let this maximum value be maxVal. 
Compute adjustment factor k for all values
      k  = (maxVal * ε) / n

 Adjust all values, i.e., create a new array val'[] that values divided by k. Do following for every value val[i].
      val'[i] = floor(val[i] / k)

 Run DP based solution for reduced values, i,e, val'[0..n-1] and all other parameter same. 

The above solution works in polynomial time in terms of both n and ε. The solution provided by this FPTAS is (1 – ε) approximate. The idea is to rounds off some of the least significant digits of values then they will be bounded by a polynomial and 1/ε.
Example: 
val[] = {12, 16, 4, 8}
wt[]  = {3, 4, 5, 2}
W = 10
ε = 0.5
 
maxVal = 16 [maximum value in val[]]
Adjustment factor, k = (16 * 0.5)/4 = 2.0

Now we apply DP based solution on below modified 
instance of problem.

val'[] = {6, 8, 2, 4}  [ val'[i] = floor(val[i]/k) ]
wt[] = {3, 4, 5, 2}
W = 10

How is the solution (1 – ε) * OPT?
Here OPT is the optimal value. Let S be the set produced by above FPTAS algorithm and total value of S be val(S).  We need to show that 
       val(S) >= (1 - ε)*OPT 
Let O be the set produced by optimal solution (the solution with total value OPT), i.e., val(O) = OPT.
       val(O) - k*val'(O) <= n*k 
       [Because val'[i] = floor(val[i]/k) ] 
After the dynamic programming step, we get a set that is optimal for the scaled instance
and therefore must be at least as good as choosing the set O with the smaller profits. From that, we can conclude, 
      val'(S) >= k . val'(O)
              >= val(O) - nk
              >= OPT - ε * maxVal
              >= OPT - ε * OPT [OPT >= maxVal]
              >= (1 - ε) * OPT 
Sources: 
http://math.mit.edu/~goemans/18434S06/knapsack-katherine.pdf
https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme
This article is contributed by Dheeraj Gupta. If you like GeeksforGeeks and would like to contribute, you can also write an article and mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Count Fibonacci numbers in given range in O(Log n) time and O(1) spacePriority CPU Scheduling with different arrival time - Set 2Extended Mo's Algorithm with ≈ O(1) time complexityQueries of nCr%p in O(1) time complexityGenerating OTP (One time Password) in PHPMaximum removal from array when removal time >= waiting timeFind maximum in a stack in O(1) time and O(1) extra spaceSchedule elevator to reduce the total time takenCount of sub-strings that do not contain all the characters from the set {'a', 'b', 'c'} at the same timeMicrosoft Interview experience for full time position of software engineer at Microsoft Ireland ResearchAlgorithms  Sample Questions | Set 3 | Time Order AnalysisConstruct the Rooted tree by using start and finish time of its DFS traversalAppend two elements to make the array satisfy the given conditionRemove minimum elements from ends of array so that sum decreases by at least K | O(N)Improved By :  jokic07, shubhamagarwal0312

Article Tags : Algorithms
Practice Tags : Algorithms 

thumb_up
2



To-do

Done



4.5


Based on 61 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



A Time Complexity Question


What is the time complexity of following function fun()? Assume that log(x) returns log value in base 2. 





filter_none

Time Complexity of building a heap


Consider the following algorithm for building a Heap of an input array A.  
BUILD-HEAP(A) 
    heapsize := size(A); 
    for i := floor(heapsize/2) downto 1 
        do HEAPIFY(A, i); 
    end for 
END

A quick look over the above algorithm suggests that the running time is , since each call to Heapify costs  and Build-Heap makes  such calls.
This upper bound, though correct, is not asymptotically tight.
We can derive a tighter bound by observing that the running time of Heapify depends on the height of the tree ‘h’ (which is equal to lg(n), where n is number of nodes) and the heights of most sub-trees are small.
The height ’h’ increases as we move upwards along the tree. Line-3 of Build-Heap runs a loop from the index of the last internal node (heapsize/2) with height=1, to the index of root(1) with height = lg(n). Hence, Heapify takes different time for each node, which is .





For finding the Time Complexity of building a heap, we must know the number of nodes having height h.
For this we use the fact that, A heap of size n has at most  nodes with height h. 
Now to derive the time complexity, we express the total cost of Build-Heap as-
 (1)    
Step 2 uses the properties of the Big-Oh notation to ignore the ceiling function and the constant 2(). Similarly in Step three, the upper limit of the summation can be increased to infinity since we are using Big-Oh notation.
Sum of infinite G.P. (x < 1)
 (2)    
On differentiating both sides and multiplying by x, we get
 (3)    
Putting the result obtained in (3) back in our derivation (1), we get
 (4)    
Hence Proved that the Time complexity for Building a Binary Heap is .
Reference : 
http://www.cs.sfu.ca/CourseCentral/307/petra/2009/SLN_2.pdf
This article is contributed by Chirag Manwani. If you like GeeksforGeeks and would like to contribute, you can also write an article using contribute.geeksforgeeks.org or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Python Code for time Complexity plot of Heap SortBuilding Heap from ArrayA Time Complexity QuestionTime Complexity of Loop with PowersAn interesting time complexity questionPractice Questions on Time Complexity AnalysisTime Complexity where loop variable is incremented by 1, 2, 3, 4  ..Understanding Time Complexity with Simple ExamplesTime complexity of  recursive Fibonacci programTime Complexity Analysis | Tower Of Hanoi (Recursion)Time Complexity of a Loop when Loop variable  “Expands or Shrinks”  exponentiallyHeap Sort for decreasing order using min heapConvert min Heap to max HeapCyclomatic ComplexityWhat does 'Space Complexity' mean?

Article Tags : AnalysisHeap
Practice Tags : Heap 

thumb_up
32



To-do

Done



2.8


Based on 128 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Time Complexity where loop variable is incremented by 1, 2, 3, 4  ..


What is the time complexity of below code?





filter_none

Time Complexity of Loop with Powers


What is the time complexity of below function?





filter_none

Performance of loops (A caching question)


Consider below two C language functions to compute sum of elements in a 2D array. Ignoring the compiler optimizations, which of the two is better implementation of sum?





filter_none

Linear Search


Problem: Given an array arr[] of n elements, write a function to search a given element x in arr[].
Examples :
Input : arr[] = {10, 20, 80, 30, 60, 50, 
                     110, 100, 130, 170}
          x = 110;
Output : 6
Element x is present at index 6

Input : arr[] = {10, 20, 80, 30, 60, 50, 
                     110, 100, 130, 170}
           x = 175;
Output : -1
Element x is not present in arr[].



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Binary Search


Given a sorted array arr[] of n elements, write a function to search a given element x in arr[].
A simple approach is to do linear search.The time complexity of above algorithm is O(n). Another approach to perform the same task is using Binary Search.  
Binary Search: Search a sorted array by repeatedly dividing the search interval in half. Begin with an interval covering the whole array. If the value of the search key is less than the item in the middle of the interval, narrow the interval to the lower half. Otherwise narrow it to the upper half. Repeatedly check until the value is found or the interval is empty.





Example :

The idea of binary search is to use the information that the array is sorted and reduce the time complexity to O(Log n). 


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Jump Search


Like Binary Search, Jump Search is a searching algorithm for sorted arrays. The basic idea is to check fewer elements (than linear search) by jumping ahead by fixed steps or skipping some elements in place of searching all elements.
For example, suppose we have an array arr[] of size n and block (to be jumped) size m. Then we search at the indexes arr[0], arr[m], arr[2m]…..arr[km] and so on. Once we find the interval (arr[km] < x < arr[(k+1)m]), we perform a linear search operation from the index km to find the element x.
Let’s consider the following array: (0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610). Length of the array is 16. Jump search will find the value of 55 with the following steps assuming that the block size to be jumped is 4.
STEP 1: Jump from index 0 to index 4;
STEP 2: Jump from index 4 to index 8;
STEP 3: Jump from index 8 to index 12;
STEP 4: Since the element at index 12 is greater than 55 we will jump back a step to come to index 8.
STEP 5: Perform linear search from index 8 to get the element 55.





What is the optimal block size to be skipped?
In the worst case, we have to do n/m jumps and if the last checked value is greater than the element to be searched for, we perform m-1 comparisons more for linear search. Therefore the total number of comparisons in the worst case will be ((n/m) + m-1). The value of the function ((n/m) + m-1) will be minimum when m = √n. Therefore, the best step size is m = √n.

C++






filter_none

Interpolation Search



Given a sorted array of n uniformly distributed values arr[], write a function to search for a particular element x in the array. 
Linear Search finds the element in O(n) time, Jump Search takes O(√ n) time and Binary Search take O(Log n) time.
The Interpolation Search is an improvement over Binary Search for instances, where the values in a sorted array are uniformly distributed.  Binary Search always goes to the middle element to check.  On the other hand, interpolation search may go to different locations according to the value of the key being searched.  For example, if the value of the key is closer to the last element, interpolation search is likely to start search toward the end side.
To find the position to be searched, it uses following formula. 











// The idea of formula is to return higher value of pos
// when element to be searched is closer to arr[hi]. And
// smaller value when closer to arr[lo]
pos = lo + [ (x-arr[lo])*(hi-lo) / (arr[hi]-arr[Lo]) ]

arr[] ==> Array where elements need to be searched
x     ==> Element to be searched
lo    ==> Starting index in arr[]
hi    ==> Ending index in arr[]

Algorithm
Rest of the Interpolation algorithm is the same except the above partition logic. 
Step1: In a loop, calculate the value of “pos” using the probe position formula.
Step2: If it is a match, return the index of the item, and exit.
Step3: If the item is less than arr[pos], calculate the probe position of the left sub-array. Otherwise calculate the same in the right sub-array.
Step4: Repeat until a match is found or the sub-array reduces to zero.
Below is the implementation of algorithm.

C++







filter_none

Exponential Search


The name of this searching algorithm may be misleading as it works in O(Log n) time. The name comes from the way it searches an element.
Given a sorted array, and an element x to be 
searched, find position of x in the array.

Input:  arr[] = {10, 20, 40, 45, 55}
        x = 45
Output: Element found at index 3

Input:  arr[] = {10, 15, 25, 45, 55}
        x = 15
Output: Element found at index 1


Recommended: Please try your approach on {IDE} first, before moving on to the solution.

We have discussed, linear search, binary search for this problem.
Exponential search involves two steps:






Find range where element is present
Do Binary Search in above found range.

How to find the range where element may be present?
The idea is to start with subarray size 1, compare its last element with x, then try size 2, then 4 and so on until last element of a subarray is not greater.
Once we find an index i (after repeated doubling of i), we know that the element must be present between i/2 and i (Why i/2? because we could not find a greater value in previous iteration)
Given below are the implementations of above steps.

C++






filter_none

Why is Binary Search preferred over Ternary Search?


The following is a simple recursive Binary Search function in C++ taken from here.






filter_none

Selection Sort


The selection sort algorithm sorts an array by repeatedly finding the minimum element (considering ascending order) from unsorted part and putting it at the beginning. The algorithm maintains two subarrays in a given array.
1) The subarray which is already sorted.
2) Remaining subarray which is unsorted.
In every iteration of selection sort, the minimum element (considering ascending order) from the unsorted subarray  is picked and moved to the sorted subarray. 





Following example explains the above steps:






arr[] = 64 25 12 22 11

// Find the minimum element in arr[0...4]
// and place it at beginning
11 25 12 22 64

// Find the minimum element in arr[1...4]
// and place it at beginning of arr[1...4]
11 12 25 22 64

// Find the minimum element in arr[2...4]
// and place it at beginning of arr[2...4]
11 12 22 25 64

// Find the minimum element in arr[3...4]
// and place it at beginning of arr[3...4]
11 12 22 25 64 
Flowchart of the Selection Sort:


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.


C++






filter_none

Bubble Sort



Bubble Sort is the simplest sorting algorithm that works by repeatedly swapping the adjacent elements if they are in wrong order.
Example:
First Pass:
( 5 1 4 2 8 ) –> ( 1 5 4 2 8 ), Here, algorithm compares the first two elements, and swaps since 5 > 1.
( 1 5 4 2 8 ) –>  ( 1 4 5 2 8 ), Swap since 5 > 4
( 1 4 5 2 8 ) –>  ( 1 4 2 5 8 ), Swap since 5 > 2
( 1 4 2 5 8 ) –> ( 1 4 2 5 8 ), Now, since these elements are already in order (8 > 5), algorithm does not swap them.
Second Pass:
( 1 4 2 5 8 ) –> ( 1 4 2 5 8 )
( 1 4 2 5 8 ) –> ( 1 2 4 5 8 ), Swap since 4 > 2
( 1 2 4 5 8 ) –> ( 1 2 4 5 8 )
( 1 2 4 5 8 ) –>  ( 1 2 4 5 8 )
Now, the array is already sorted, but our algorithm does not know if it is completed. The algorithm needs one whole pass without any swap to know it is sorted.
Third Pass:
( 1 2 4 5 8 ) –> ( 1 2 4 5 8 )
( 1 2 4 5 8 ) –> ( 1 2 4 5 8 )
( 1 2 4 5 8 ) –> ( 1 2 4 5 8 )
( 1 2 4 5 8 ) –> ( 1 2 4 5 8 )








Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Insertion Sort



Insertion sort is a simple sorting algorithm that works the way we sort playing cards in our hands.
Algorithm
// Sort an arr[] of size n
insertionSort(arr, n)
Loop from i = 1 to n-1.
……a) Pick element arr[i] and insert it into sorted sequence arr[0…i-1]      
Example: 

Another Example: 
12, 11, 13, 5, 6
Let us loop for i = 1 (second element of the array) to 4 (last element of the array)
i = 1.   Since 11 is smaller than 12, move 12 and insert 11 before 12
11, 12, 13, 5, 6
i = 2.  13 will remain at its position as all elements in A[0..I-1] are smaller than 13
11, 12, 13, 5, 6
i = 3.  5 will move to the beginning and all other elements from 11 to 13 will move one position ahead of their current position.
5, 11, 12, 13, 6
i = 4.  6 will move to position after 5, and elements from 11 to 13 will move one position ahead of their current position.
5, 6, 11, 12, 13 







Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.


C++






filter_none

Merge Sort


Like QuickSort, Merge Sort is a Divide and Conquer algorithm.  It divides input array in two halves, calls itself for the two halves and then merges the two sorted halves. The merge() function is used for merging two halves.  The merge(arr, l, m, r) is key process that assumes that arr[l..m] and arr[m+1..r] are sorted and merges the two sorted sub-arrays into one. See following C implementation for details.
MergeSort(arr[], l,  r)
If r > l
     1. Find the middle point to divide the array into two halves:  
             middle m = (l+r)/2
     2. Call mergeSort for first half:   
             Call mergeSort(arr, l, m)
     3. Call mergeSort for second half:
             Call mergeSort(arr, m+1, r)
     4. Merge the two halves sorted in step 2 and 3:
             Call merge(arr, l, m, r)
The following diagram from wikipedia shows the complete merge sort process for an example array {38, 27, 43, 3, 9, 82, 10}. If we take a closer look at the diagram, we can see that the array is recursively divided in two halves till the size becomes 1. Once the size becomes 1, the merge processes comes into action and starts merging arrays back till the complete array is merged.







Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.


C/C++






filter_none

HeapSort


Heap sort is a comparison based sorting technique based on Binary Heap data structure. It is similar to selection sort where we first find the maximum element and place the maximum element at the end.  We repeat the same process for remaining element.
What is Binary Heap?
Let us first define a Complete Binary Tree. A complete binary tree is a binary tree in which every level, except possibly the last, is completely filled, and all nodes are as far left as possible (Source Wikipedia)
A Binary Heap is a Complete Binary Tree where items are stored in a special order such that value in a parent node is greater(or smaller) than the values in its two children nodes.  The former is called as max heap  and the latter is called min heap. The heap can be represented by binary tree or array.





Why array based representation for Binary Heap?
Since a Binary Heap is a Complete Binary Tree, it can be easily represented as array and array based representation is space efficient. If the parent node is stored at index I, the left child can be calculated by 2 * I + 1 and right child by 2 * I + 2 (assuming the indexing starts at 0).
Heap Sort Algorithm for sorting in increasing order:
1. Build a max heap from the input data.
2. At this point, the largest item is stored at the root of the heap. Replace it with the last item of the heap followed by reducing the size of heap by 1. Finally, heapify the root of tree.
3. Repeat above steps while size of heap is greater than 1.
How to build the heap?
Heapify procedure can be applied to a node only if its children nodes are heapified.  So the heapification must be performed in the bottom up order.
Lets understand with the help of an example:
Input data: 4, 10, 3, 5, 1
         4(0)
        /   \
     10(1)   3(2)
    /   \
 5(3)    1(4)

The numbers in bracket represent the indices in the array 
representation of data.

Applying heapify procedure to index 1:
         4(0)
        /   \
    10(1)    3(2)
    /   \
5(3)    1(4)

Applying heapify procedure to index 0:
        10(0)
        /  \
     5(1)  3(2)
    /   \
 4(3)    1(4)
The heapify procedure calls itself recursively to build heap
 in top down manner.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.


C++






filter_none

QuickSort



Like Merge Sort, QuickSort is a Divide and Conquer algorithm. It picks an element as pivot and partitions the given array around the picked pivot.  There are many different versions of quickSort that pick pivot in different ways. 

 Always pick first element as pivot.
 Always pick last element as pivot (implemented below)
 Pick a random element as pivot.
 Pick median as pivot.

The key process in quickSort is partition().  Target of partitions is, given an array and an element x of array as pivot, put x at its correct position in sorted array and put all smaller elements (smaller than x) before x, and put all greater elements (greater than x) after x.  All this should be done in linear time.
Pseudo Code for recursive QuickSort function : 











/* low  --> Starting index,  high  --> Ending index */
quickSort(arr[], low, high)
{
    if (low < high)
    {
        /* pi is partitioning index, arr[pi] is now
           at right place */
        pi = partition(arr, low, high);

        quickSort(arr, low, pi - 1);  // Before pi
        quickSort(arr, pi + 1, high); // After pi
    }
}


Partition Algorithm
There can be many ways to do partition, following pseudo code adopts the method given in CLRS book. The logic is simple, we start from the leftmost element and keep track of index of smaller (or equal to) elements as i.  While traversing, if we find a smaller element, we swap current element with arr[i]. Otherwise we ignore current element.
/* low  --> Starting index,  high  --> Ending index */
quickSort(arr[], low, high)
{
    if (low < high)
    {
        /* pi is partitioning index, arr[pi] is now
           at right place */
        pi = partition(arr, low, high);

        quickSort(arr, low, pi - 1);  // Before pi
        quickSort(arr, pi + 1, high); // After pi
    }
}

Pseudo code for partition()
/* This function takes last element as pivot, places
   the pivot element at its correct position in sorted
    array, and places all smaller (smaller than pivot)
   to left of pivot and all greater elements to right
   of pivot */
partition (arr[], low, high)
{
    // pivot (Element to be placed at right position)
    pivot = arr[high];  
 
    i = (low - 1)  // Index of smaller element

    for (j = low; j <= high- 1; j++)
    {
        // If current element is smaller than the pivot
        if (arr[j] < pivot)
        {
            i++;    // increment index of smaller element
            swap arr[i] and arr[j]
        }
    }
    swap arr[i + 1] and arr[high])
    return (i + 1)
}

Illustration of partition() :
arr[] = {10, 80, 30, 90, 40, 50, 70}
Indexes:  0   1   2   3   4   5   6 

low = 0, high =  6, pivot = arr[h] = 70
Initialize index of smaller element, i = -1

Traverse elements from j = low to high-1
j = 0 : Since arr[j] <= pivot, do i++ and swap(arr[i], arr[j])
i = 0 
arr[] = {10, 80, 30, 90, 40, 50, 70} // No change as i and j 
                                     // are same

j = 1 : Since arr[j] > pivot, do nothing
// No change in i and arr[]

j = 2 : Since arr[j] <= pivot, do i++ and swap(arr[i], arr[j])
i = 1
arr[] = {10, 30, 80, 90, 40, 50, 70} // We swap 80 and 30 

j = 3 : Since arr[j] > pivot, do nothing
// No change in i and arr[]

j = 4 : Since arr[j] <= pivot, do i++ and swap(arr[i], arr[j])
i = 2
arr[] = {10, 30, 40, 90, 80, 50, 70} // 80 and 40 Swapped
j = 5 : Since arr[j] <= pivot, do i++ and swap arr[i] with arr[j] 
i = 3 
arr[] = {10, 30, 40, 50, 80, 90, 70} // 90 and 50 Swapped 

We come out of loop because j is now equal to high-1.
Finally we place pivot at correct position by swapping
arr[i+1] and arr[high] (or pivot) 
arr[] = {10, 30, 40, 50, 70, 90, 80} // 80 and 70 Swapped 

Now 70 is at its correct place. All elements smaller than
70 are before it and all elements greater than 70 are after
it.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







Implementation:
Following are the implementations of QuickSort:

C++







filter_none

Radix Sort


The lower bound for Comparison based sorting algorithm (Merge Sort, Heap Sort, Quick-Sort .. etc) is Ω(nLogn), i.e., they cannot do better than nLogn. 
Counting sort is a linear time sorting algorithm that sort in O(n+k) time when elements are in range from 1 to k.
What if the elements are in range from 1 to n2? 
We can’t use counting sort because counting sort will take O(n2) which is worse than comparison based sorting algorithms.  Can we sort such an array in linear time?
Radix Sort is the answer. The idea of Radix Sort is to do digit by digit sort starting from least significant digit to most significant digit.  Radix sort uses counting sort as a subroutine to sort.





The Radix Sort Algorithm
1) Do following for each digit i where i varies from least significant digit to the most significant digit.
………….a) Sort input array using counting sort (or any stable sort) according to the i’th digit.
Example:
Original, unsorted list:

170, 45, 75, 90, 802, 24, 2, 66

Sorting by least significant digit (1s place) gives: [*Notice that we keep 802 before 2, because 802 occurred before 2 in the original list, and similarly for pairs 170 & 90 and 45 & 75.]

170, 90, 802, 2, 24, 45, 75, 66

Sorting by next digit (10s place) gives: [*Notice that 802 again comes before 2 as 802 comes before 2 in the previous list.]

802, 2, 24, 45, 66, 170, 75, 90

Sorting by most significant digit (100s place) gives:

2, 24, 45, 66, 75, 90, 170, 802

What is the running time of Radix Sort?
Let there be d digits in input integers.  Radix Sort takes O(d*(n+b)) time where b is the base for representing numbers, for example, for decimal system, b is 10.  What is the value of d? If k is the maximum possible value, then d would be  O(logb(k)). So overall time complexity is O((n+b) * logb(k)). Which looks more than the time complexity of comparison based sorting algorithms for a large k.  Let us first limit k.  Let k <= nc where c is a constant. In that case, the complexity becomes O(nLogb(n)). But it still doesn’t beat comparison based sorting algorithms.
What if we make value of b larger?. What should be the value of b to make the time complexity linear?  If we set b as n, we get the time complexity as O(n).  In other words, we can sort an array of integers with range from 1 to nc if the numbers are represented in base n (or every digit takes log2(n) bits). 
Is Radix Sort preferable to Comparison based sorting algorithms like Quick-Sort?
If we have log2n bits for every digit, the running time of Radix appears to be better than Quick Sort for a wide range of input numbers.  The constant factors hidden in asymptotic notation are higher for Radix Sort and Quick-Sort uses hardware caches more effectively. Also, Radix sort uses counting sort as a subroutine and counting sort takes extra space to sort numbers.

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

Implementation of Radix Sort
Following is a simple implementation of Radix Sort. For simplicity, the value of d is assumed to be 10. We recommend you to see Counting Sort for details of countSort() function in below code.

C/C++






filter_none

Counting Sort



Counting sort is a sorting technique based on keys between a specific range. It works by counting the number of objects having distinct key values (kind of hashing). Then doing some arithmetic to calculate the position of each object in the output sequence.
Let us understand it with the help of an example. 
For simplicity, consider the data in the range 0 to 9. 
Input data: 1, 4, 1, 2, 7, 5, 2
  1) Take a count array to store the count of each unique object.
  Index:     0  1  2  3  4  5  6  7  8  9
  Count:     0  2  2  0   1  1  0  1  0  0

  2) Modify the count array such that each element at each index 
  stores the sum of previous counts. 
  Index:     0  1  2  3  4  5  6  7  8  9
  Count:     0  2  4  4  5  6  6  7  7  7

The modified count array indicates the position of each object in 
the output sequence.
 
  3) Output each object from the input sequence followed by 
  decreasing its count by 1.
  Process the input data: 1, 4, 1, 2, 7, 5, 2. Position of 1 is 2.
  Put data 1 at index 2 in output. Decrease count by 1 to place 
  next data 1 at an index 1 smaller than this index.



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Bucket Sort


Bucket sort is mainly useful when input is uniformly distributed over a range.  For example, consider the following problem. 
Sort a large set of floating point numbers which are in range from 0.0 to 1.0 and are uniformly distributed across the range. How do we sort the numbers efficiently?
A simple way is to apply a comparison based sorting algorithm. The lower bound for Comparison based sorting algorithm (Merge Sort, Heap Sort, Quick-Sort .. etc) is Ω(n Log n), i.e., they cannot do better than nLogn.
Can we sort the array in linear time? Counting sort can not be applied here as we use keys as index in counting sort. Here keys are floating point numbers. 
The idea is to use bucket sort.  Following is bucket algorithm.
bucketSort(arr[], n)
1) Create n empty buckets (Or lists).
2) Do following for every array element arr[i].
.......a) Insert arr[i] into bucket[n*array[i]]
3) Sort individual buckets using insertion sort.
4) Concatenate all sorted buckets.



ShellSort



ShellSort is mainly a variation of Insertion Sort. In insertion sort, we move elements only one position ahead. When an element has to be moved far ahead, many movements are involved. The idea of shellSort is to allow exchange of far items. In shellSort, we make the array h-sorted for a large value of h. We keep reducing the value of h until it becomes 1. An array is said to be h-sorted if all sublists of every h’th element is sorted.
Following is the implementation of ShellSort.

C++






filter_none

Comb Sort


Comb Sort is mainly an improvement over Bubble Sort. Bubble sort always compares adjacent values. So all inversions are removed one by one. Comb Sort improves on Bubble Sort by using gap of size more than 1. The gap starts with a large value and shrinks by a factor of 1.3 in every iteration until it reaches the value 1. Thus Comb Sort removes more than one inversion counts with one swap and performs better than Bubble Sort.
The shrink factor has been empirically found to be 1.3 (by testing Combsort on over 200,000 random lists) [Source: Wiki]
Although, it works better than Bubble Sort on average, worst case remains O(n2).





Below is the implementation.

C++






filter_none

Pigeonhole Sort


Pigeonhole sorting is a sorting algorithm that is suitable for sorting lists of elements where the number of elements and the number of possible key values are approximately the same.
It requires O(n + Range) time where n is number of elements in input array and ‘Range’ is number of possible values in array. 
Working of Algorithm : 

Find minimum and maximum values in array. Let the minimum and maximum values be ‘min’ and ‘max’ respectively.  Also find range as ‘max-min-1’.
Set up an array of initially empty “pigeonholes” the same size as of the range.
Visit each element of the array and then put each element in its pigeonhole. An element arr[i] is put in hole at index arr[i] – min.
Start the loop all over the pigeonhole array in order and put the elements from non- empty holes back into the original array.

Comparison with Counting Sort : 
It is similar to counting sort, but differs in that it “moves items twice: once to the bucket array and again to the final destination “. 







Cycle Sort


Cycle sort is an in-place sorting Algorithm, unstable sorting algorithm, a comparison sort that is theoretically optimal in terms of the total number of writes to the original array. 

It is optimal in terms of number of memory writes. It  minimizes the number of memory writes to sort (Each value is either written zero times, if it’s already in its correct position, or written one time to its correct position.)
It is based on the idea that array to be sorted can be divided into cycles. Cycles can be visualized as a graph. We have n nodes and an edge directed from node i to node j if the element at i-th index must be present at j-th index in the sorted array.
Cycle in arr[] = {2, 4, 5, 1, 3}


Interpolation search vs Binary search


Interpolation search works better than Binary Search for a sorted and uniformly distributed array. 
On average the interpolation search makes about log(log(n)) comparisons (if the elements are uniformly distributed), where n is the number of elements to be searched. In the worst case (for instance where the numerical values of the keys increase exponentially) it can make up to O(n) comparisons.
Interpolation Search Article





Sources:
http://en.wikipedia.org/wiki/Interpolation_search







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Interpolation SearchWhy is Binary Search preferred over Ternary Search?Meta Binary Search | One-Sided Binary SearchLinear Search vs Binary SearchRepeatedly search an element by doubling it after every successful searchBinary SearchBinary Search in PHPBinary Search a StringUniform Binary SearchThe Ubiquitous Binary Search | Set 1Binary Search using pthreadVariants of Binary SearchBinary Search In JavaScriptBinary Search in JavaBinary Search (bisect) in Python

Article Tags : SearchingBinary Search
Practice Tags : SearchingBinary Search 

thumb_up
4



To-do

Done



2


Based on 66 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Stability in sorting algorithms


Stability is mainly important when we have key value pairs with duplicate keys possible (like people names as keys and their details as values). And we wish to sort these objects by keys.  
What is it?
A sorting algorithm is said to be stable if two objects with equal keys appear in the same order in sorted output as they appear in the input array to be sorted.
Formally stability may be defined as,
Let  be an array, and let  be a strict weak ordering on the elements of .
A sorting algorithm is stable if-

where  is the sorting permutation ( sorting moves  to position  )
Informally, stability means that equivalent elements retain their relative positions, after sorting.






Do we care for simple arrays like array of integers?
When equal elements are indistinguishable, such as with integers, or more generally, any data where the entire element is the key, stability is not an issue. Stability is also not an issue if all keys are different.
An example where it is useful
Consider the following dataset of Student Names and their respective class sections.

If we sort this data according to name only, then it is highly unlikely that the resulting dataset will be grouped according to sections as well.

So we might have to sort again to obtain list of students section wise too. But in doing so, if the sorting algorithm is not stable, we might get a result like this-

The dataset is now sorted according to sections, but not according to names.
In the name-sorted dataset, the tuple  was before , but since the sorting algorithm is not stable, the relative order is lost.
If on the other hand we used a stable sorting algorithm, the result would be-





Here the relative order between different tuples is maintained.  It may be the case that the relative order is maintained in an Unstable Sort but that is highly unlikely.
Which sorting algorithms are stable?
Some Sorting Algorithms are stable by nature, such as Bubble Sort, Insertion Sort, Merge Sort, Count Sort etc.
Comparison based stable sorts such as Merge Sort and Insertion Sort, maintain stability by ensuring that-
Element  comes before  if and only if , here i, j are indices and .
Since , the relative order is preserved  i.e.  comes before.
Other non-comparison based sorts such as Counting Sort maintain stability by ensuring that the Sorted Array is filled in a reverse order so that elements with equivalent keys have the same relative position.
Some sorts such as Radix Sort depend on another sort, with the only requirement that the other sort should be stable.
Which sorting algorithms are unstable?
Quick Sort, Heap Sort etc., can be made stable by also taking the position of the elements into consideration. This change may be done in a way which does not compromise a lot on the performance and takes some extra space, possibly .
Can we make any sorting algorithm stable?
Any given sorting algo which is not stable can be modified to be stable. There can be sorting algo specific ways to make it stable, but in general, any comparison based sorting algorithm which is not stable by nature can be modified to be stable by changing the key comparison operation so that the comparison of two keys considers position as a factor for objects with equal keys. 
References:
http://www.math.uic.edu/~leon/cs-mcs401-s08/handouts/stability.pdf
http://en.wikipedia.org/wiki/Sorting_algorithm#Stability
This article is contributed by Chirag Manwani. If you like GeeksforGeeks and would like to contribute, you can also write an article using contribute.geeksforgeeks.org or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Time Complexities of all Sorting AlgorithmsSorting Algorithms Visualization | Selection SortSorting Algorithms Visualization : Bubble SortAsymptotic Analysis and comparison of sorting algorithmsLoop Invariant Condition with Examples of Sorting AlgorithmsLower bound for comparison based sorting algorithmsKnow Your Sorting Algorithm | Set 1 (Sorting Weapons used by Programming Languages)Sorting objects using In-Place sorting algorithmKnow Your Sorting Algorithm | Set 2  (Introsort- C++’s Sorting Weapon)External SortingAlternative SortingSorting TerminologySorting Big IntegersSorting in JavaPancake sorting

Article Tags : SortingMerge SortQuick Sort
Practice Tags : SortingMerge Sort 

thumb_up
41



To-do

Done



1.8


Based on 121 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



When does the worst case of Quicksort occur?


The answer depends on strategy for choosing pivot. In early versions of Quick Sort where leftmost (or rightmost) element is chosen as pivot, the worst occurs in following cases.
1) Array is already sorted in same order.
2) Array is already sorted in reverse order.
3) All elements are same (special case of case 1 and 2) 
Since these cases are very common use cases, the problem was easily solved by choosing either a random index for the pivot, choosing the middle index of the partition or (especially for longer partitions) choosing the median of the first, middle and last element of the partition for the pivot. With these modifications, the worst case of Quick sort has less chances to occur, but worst case can still occur if the input array is such that the maximum (or minimum) element is always chosen as pivot. 





References:
http://en.wikipedia.org/wiki/Quicksort







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Can QuickSort be implemented in O(nLogn) worst case time complexity?QuickSort Tail Call Optimization (Reducing worst case space to Log n )Find a permutation that causes worst case of Merge SortQuickSortC++ Program for QuickSortStable QuickSortWhy quicksort is better than mergesort ?Python Program for QuickSortJava Program for QuickSortDual pivot QuicksortQuickSort using Random PivotingGeneric Implementation of QuickSort Algorithm in C3-Way QuickSort (Dutch National Flag)QuickSort on Singly Linked ListQuickSort on Doubly Linked List

Article Tags : SortingQuick Sort
Practice Tags : Sorting 

thumb_up
4



To-do

Done



1.5


Based on 69 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Lower bound for comparison based sorting algorithms


The problem of sorting can be viewed as following.
Input: A sequence of n numbers <a1, a2, . . . , an>.
Output: A permutation (reordering) <a‘1, a‘2, . . . , a‘n> of the input sequence such that a‘1 <= a‘2 ….. <= a

Which sorting algorithm makes minimum number of memory writes?


Minimizing the number of writes is useful when making writes to some huge data set is very expensive, such as with EEPROMs or Flash memory, where each write reduces the lifespan of the memory.
Among the sorting algorithms that we generally study in our data structure and algorithm courses,  Selection Sort makes least number of writes (it makes O(n) swaps).   But, Cycle Sort almost always makes less number of writes compared to Selection Sort.  In Cycle Sort, each value is either written zero times, if it’s already in its correct  position, or written one time to its correct position. This matches the  minimal number of overwrites required for a completed in-place sort.
Sources:
http://en.wikipedia.org/wiki/Cycle_sort
http://en.wikipedia.org/wiki/Selection_sort





Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Find the Minimum length Unsorted Subarray, sorting which makes the complete array sortedStability in sorting algorithmsLower bound for comparison based sorting algorithmsGiven a number, find the next smallest palindromePancake sortingA Pancake Sorting ProblemFind number of pairs (x, y) in an array such that x^y > y^xFind memory conflicts among multiple threadsRearrange an array in maximum minimum form | Set 1External SortingFind minimum difference between any two elementsCartesian Tree SortingSorting 2D Vector in C++ | Set 2 (In descending order by row and column)Minimum sum of two numbers formed from digits of an arrayKnow Your Sorting Algorithm | Set 1 (Sorting Weapons used by Programming Languages)

Article Tags : Sorting
Practice Tags : Sorting 

thumb_up
2



To-do

Done



2.3


Based on 59 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Find the Minimum length Unsorted Subarray, sorting which makes the complete array sorted


Given an unsorted array arr[0..n-1] of size n, find the minimum length subarray arr[s..e] such that sorting this subarray makes the whole array sorted.

Examples:
1) If the input array is [10, 12, 20, 30, 25, 40, 32, 31, 35, 50, 60], your program should be able to find that the subarray lies between the indexes 3 and 8.
2) If the input array is [0, 1, 15, 25, 6, 7, 30, 40, 50], your program should be able to find that the subarray lies between the indexes 2 and 5.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Solution:
1) Find the candidate unsorted subarray 
a) Scan from left to right and find the first element which is greater than the next element.  Let s be the index of such an element. In the above example 1, s is 3 (index of 30).
b) Scan from right to left and find the first element (first in right to left order) which is smaller than the next element (next in right to left order).  Let e be the index of such an element. In the above example 1, e is 7 (index of 31).





2) Check whether sorting the candidate unsorted subarray makes the complete array sorted or not. If not, then include more elements in the subarray.
a) Find the minimum and maximum values in arr[s..e]. Let minimum and maximum values be min and max. min and max for [30, 25, 40, 32, 31] are 25 and 40 respectively.
b) Find the first element (if there is any) in arr[0..s-1] which is greater than min,  change s to index of this element. There is no such element in above example 1.
c) Find the last element (if there is any) in arr[e+1..n-1] which is smaller than max, change e to index of this element. In the above example 1, e is changed to 8 (index of 35)
3) Print s and e.


Merge Sort for Linked Lists



Merge sort is often preferred for sorting a linked list. The slow random-access performance of a linked list makes some other algorithms (such as quicksort) perform poorly, and others (such as heapsort) completely impossible.

Let head be the first node of the linked list to be sorted and headRef be the pointer to head. Note that we need a reference to head in MergeSort() as the below implementation changes next links to sort the linked lists (not data at the nodes), so head node has to be changed if the data at the original head is not the smallest value in the linked list.
MergeSort(headRef)
1) If the head is NULL or there is only one element in the Linked List 
    then return.
2) Else divide the linked list into two halves.  
      FrontBackSplit(head, &a, &b); /* a and b are two halves */
3) Sort the two halves a and b.
      MergeSort(a);
      MergeSort(b);
4) Merge the sorted a and b (using SortedMerge() discussed here) 
   and update the head pointer using headRef.
     *headRef = SortedMerge(a, b);


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.








C++






filter_none

Sort a nearly sorted (or K sorted) array



Given an array of n elements, where each element is at most k away from its target position, devise an algorithm that sorts in O(n log k) time.  For example, let us consider k is 2, an element at index 7 in the sorted array, can be at indexes 5, 6, 7, 8, 9 in the given array.
Examples:
Input : arr[] = {6, 5, 3, 2, 8, 10, 9}
            k = 3 
Output : arr[] = {2, 3, 5, 6, 8, 9, 10}

Input : arr[] = {10, 9, 8, 7, 4, 70, 60, 50}
         k = 4
Output : arr[] = {4, 7, 8, 9, 10, 50, 60, 70}









Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Iterative Quick Sort


Following is a typical recursive implementation of Quick Sort that uses last element as pivot. 

C++







filter_none

QuickSort on Singly Linked List


QuickSort on Doubly Linked List is discussed here.  QuickSort on Singly linked list was given as an exercise. Following is C++ implementation for same.  The important things about implementation are, it changes pointers rather swapping data and time complexity is same as the implementation for Doubly Linked List.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

In partition(), we consider last element as pivot. We traverse through the current list and if a node has value greater than pivot, we move it after tail.  If the node has smaller value, we keep it at its current position.
In QuickSortRecur(), we first call partition() which places pivot at correct position and returns pivot.  After pivot is placed at correct position, we find tail node of left side (list before pivot) and recur for left list. Finally, we recur for right list.

C++






filter_none

QuickSort on Doubly Linked List


Following is a typical recursive implementation of QuickSort for arrays. The implementation uses last element as pivot. 





filter_none

Find k closest elements to a given value


Given a sorted array arr[] and a value X, find the k closest elements to X in arr[]. 
Examples:
Input: K = 4, X = 35
       arr[] = {12, 16, 22, 30, 35, 39, 42, 
               45, 48, 50, 53, 55, 56}
Output: 30 39 42 45

Note that if the element is present in array, then it should not be in output, only the other closest elements are required.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Sort n numbers in range from 0 to n^2 – 1 in linear time


Given an array of numbers of size n. It is also given that the array elements are in range from 0 to n2 – 1. Sort the given array in linear time.
Examples:
Since there are 5 elements, the elements can be from 0 to 24.
Input: arr[] = {0, 23, 14, 12, 9}
Output: arr[] = {0, 9, 12, 14, 23}

Since there are 3 elements, the elements can be from 0 to 8.
Input: arr[] = {7, 0, 2}
Output: arr[] = {0, 2, 7}



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



A Problem in Many Binary Search Implementations


Consider the following C implementation of Binary Search function, is there anything wrong in this?





filter_none

Search in an almost sorted array


Given an array which is sorted, but after sorting some elements are moved to either of the adjacent positions, i.e., arr[i] may be present at arr[i+1] or arr[i-1]. Write an efficient function to search an element in this array. Basically the element arr[i] can only be swapped with either arr[i+1] or arr[i-1].
For example consider the array {2, 3, 10, 4, 40}, 4 is moved to next position and 10 is moved to previous position.
Example : 





Input: arr[] =  {10, 3, 40, 20, 50, 80, 70}, key = 40
Output: 2 
Output is index of 40 in given array

Input: arr[] =  {10, 3, 40, 20, 50, 80, 70}, key = 90
Output: -1
-1 is returned to indicate element is not present
A simple solution is to linearly search the given key in given array. Time complexity of this solution is O(n). We can modify binary search to do it in O(Logn) time.  
The idea is to compare the key with middle 3 elements, if present then return the index.  If not present, then compare the key with middle element to decide whether to go in left half or right half.  Comparing with middle element is enough as all the elements after mid+2 must be greater than element mid and all elements before mid-2 must be smaller than mid element.
Following is the implementation of this approach.

C++






filter_none

Sort an array in wave form


Given an unsorted array of integers, sort the array into a wave like array. An array ‘arr[0..n-1]’ is sorted in wave form if arr[0] >= arr[1] <= arr[2] >= arr[3] <= arr[4] >= …..
Examples:
 Input:  arr[] = {10, 5, 6, 3, 2, 20, 100, 80}
 Output: arr[] = {10, 5, 6, 2, 20, 3, 100, 80} OR
                 {20, 5, 10, 2, 80, 6, 100, 3} OR
                 any other array that is in wave form

 Input:  arr[] = {20, 10, 8, 6, 4, 2}
 Output: arr[] = {20, 8, 10, 4, 6, 2} OR
                 {10, 8, 20, 2, 6, 4} OR
                 any other array that is in wave form

 Input:  arr[] = {2, 4, 6, 8, 10, 20}
 Output: arr[] = {4, 2, 8, 6, 20, 10} OR
                 any other array that is in wave form

 Input:  arr[] = {3, 6, 5, 10, 7, 20}
 Output: arr[] = {6, 3, 10, 5, 20, 7} OR
                 any other array that is in wave form


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

A Simple Solution is to use sorting.  First sort the input array, then swap all adjacent elements.





For example, let the input array be {3, 6, 5, 10, 7, 20}. After sorting, we get {3, 5, 6, 7, 10, 20}. After swapping adjacent elements, we get {5, 3, 7, 6, 20, 10}.  
Below are implementations of this simple approach.

C++






filter_none

Why is Binary Search preferred over Ternary Search?


The following is a simple recursive Binary Search function in C++ taken from here.






filter_none

K’th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time)


We recommend reading the following post as a prerequisite of this post.
K’th Smallest/Largest Element in Unsorted Array | Set 1
Given an array and a number k where k is smaller than the size of the array, we need to find the k’th smallest element in the given array. It is given that all array elements are distinct.





Examples:
Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 3
Output: 7

Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 4
Output: 10
We have discussed three different solutions here.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



K’th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time)


We recommend reading the following post as a prerequisite of this post.
K’th Smallest/Largest Element in Unsorted Array | Set 1
Given an array and a number k where k is smaller than the size of the array, we need to find the k’th smallest element in the given array. It is given that all array elements are distinct.





Examples:
Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 3
Output: 7

Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 4
Output: 10
We have discussed three different solutions here.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



K’th Smallest/Largest Element in Unsorted Array | Set 3 (Worst Case Linear Time)


We recommend reading following posts as a prerequisite of this post.
K’th Smallest/Largest Element in Unsorted Array | Set 1
K’th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time)
Given an array and a number k where k is smaller than the size of the array, we need to find the k’th smallest element in the given array. It is given that all array elements are distinct.





Examples:
Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 3
Output: 7

Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 4
Output: 10


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Find the closest pair from two sorted arrays


Given two sorted arrays and a number x, find the pair whose sum is closest to x and the pair has an element from each array. 
We are given two arrays ar1[0…m-1] and ar2[0..n-1] and a number x, we need to find the pair ar1[i] + ar2[j] such that absolute value of (ar1[i] + ar2[j] – x) is minimum.
Example:  





Input:  ar1[] = {1, 4, 5, 7};
        ar2[] = {10, 20, 30, 40};
        x = 32      
Output:  1 and 30

Input:  ar1[] = {1, 4, 5, 7};
        ar2[] = {10, 20, 30, 40};
        x = 50      
Output:  7 and 40

We strongly recommend to minimize your browser and try this yourself first.
A Simple Solution is to run two loops. The outer loop considers every element of first array and inner loop checks for the pair in second array.  We keep track of minimum difference between ar1[i] + ar2[j] and x.
We can do it in O(n) time using following steps.
1) Merge given two arrays into an auxiliary array of size m+n using merge process of merge sort.  While merging keep another boolean array of size m+n to indicate whether the current element in merged array is from ar1[] or ar2[].
2) Consider the merged array and use the linear time algorithm to find the pair with sum closest to x.  One extra thing we need to consider only those pairs which have one element from ar1[] and other from ar2[], we use the boolean array for this purpose.
Can we do it in a single pass and O(1) extra space?
The idea is to start from left side of one array and right side of another array, and use the algorithm same as step 2 of above approach.  Following is detailed algorithm. 
1) Initialize a variable diff as infinite (Diff is used to store the 
   difference between pair and x).  We need to find the minimum diff.
2) Initialize two index variables l and r in the given sorted array.
       (a) Initialize first to the leftmost index in ar1:  l = 0
       (b) Initialize second  the rightmost index in ar2:  r = n-1
3) Loop while  l = 0
       (a) If  abs(ar1[l] + ar2[r] - sum) < diff  then 
           update diff and result 
       (b) If (ar1[l] + ar2[r] <  sum )  then l++
       (c) Else r--    
4) Print the result. 
Following is the implementation of this approach.

C++







filter_none

Find common elements in three sorted arrays


Given three arrays sorted in non-decreasing order, print all common elements in these arrays.
Examples:

Input:
ar1[] = {1, 5, 10, 20, 40, 80}
ar2[] = {6, 7, 20, 80, 100}
ar3[] = {3, 4, 15, 20, 30, 70, 80, 120}
Output: 20, 80





Input:
ar1[] = {1, 5, 5}
ar2[] = {3, 4, 5, 5, 10}
ar3[] = {5, 5, 10, 20}
Output: 5, 5


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Given a sorted array and a number x, find the pair in array whose sum is closest to x


Given a sorted array and a number x, find a pair in array whose sum is closest to x.
Examples:
Input: arr[] = {10, 22, 28, 29, 30, 40}, x = 54
Output: 22 and 30

Input: arr[] = {1, 3, 4, 7, 10}, x = 15
Output: 4 and 10

A simple solution is to consider every pair and keep track of closest pair (absolute difference between pair sum and x is minimum).  Finally print the closest pair.  Time complexity of this solution is O(n2)





An efficient solution can find the pair in O(n) time.  The idea is similar to method 2 of this post.  Following is detailed algorithm.
1) Initialize a variable diff as infinite (Diff is used to store the 
   difference between pair and x).  We need to find the minimum diff.
2) Initialize two index variables l and r in the given sorted array.
       (a) Initialize first to the leftmost index:  l = 0
       (b) Initialize second  the rightmost index:  r = n-1
3) Loop while l < r.
       (a) If  abs(arr[l] + arr[r] - sum) < diff  then 
           update diff and result 
       (b) Else if(arr[l] + arr[r] <  sum )  then l++
       (c) Else r--    
Following is the implementation of above algorithm.

C++






filter_none

Count 1’s in a sorted binary array


Given a binary array sorted in non-increasing order, count the number of 1’s in it. 
Examples: 
Input: arr[] = {1, 1, 0, 0, 0, 0, 0}
Output: 2

Input: arr[] = {1, 1, 1, 1, 1, 1, 1}
Output: 7

Input: arr[] = {0, 0, 0, 0, 0, 0, 0}
Output: 0

A simple solution is to linearly traverse the array.  The time complexity of the simple solution is O(n).  We can use Binary Search to find count in O(Logn) time. The idea is to look for last occurrence of 1 using Binary Search. Once we find the index last occurrence, we return index + 1 as count.





The following is the implementation of above idea. 

C++






filter_none

Binary Insertion Sort


We can use binary search to reduce the number of comparisons in normal insertion sort. Binary Insertion Sort uses binary search to find the proper location to insert the selected item at each iteration. 
In normal insertion sort, it takes O(n) comparisons(at nth iteration) in worst case. We can reduce it to O(log n) by using binary search.

C/C++






filter_none

Insertion Sort for Singly Linked List


We have discussed Insertion Sort for arrays.  In this article same for linked list is discussed. 
Below is simple insertion sort algorithm for linked list.
1) Create an empty sorted (or result) list
2) Traverse the given list, do following for every node.
......a) Insert current node in sorted way in sorted or result list.
3) Change head of given linked list to head of sorted (or result) list.


Recommended: Please try your approach on {IDE} first, before moving on to the solution.

The main step is (2.a) which has been covered in below post.
Sorted Insert for Singly Linked List





Below is implementation of above algorithm

C++






filter_none

Why Quick Sort preferred for Arrays and Merge Sort for Linked Lists?


Why is Quick Sort preferred for arrays?
Below are recursive and iterative implementations of Quick Sort and Merge Sort for arrays.
Recursive Quick Sort for array.
Iterative Quick Sort for arrays.
Recursive Merge Sort for arrays
Iterative Merge Sort for arrays






Quick Sort in its general form is an in-place sort (i.e. it doesn’t require any extra storage) whereas merge sort requires O(N) extra storage, N denoting the array size which may be quite expensive. Allocating and de-allocating the extra space used for merge sort increases the running time of the algorithm. 
Comparing average complexity we find that both type of sorts have O(NlogN) average complexity but the constants differ. For arrays, merge sort loses due to the use of extra O(N) storage space.  
Most practical implementations of Quick Sort use randomized version. The randomized version has expected time complexity of O(nLogn). The worst case is possible in randomized version also, but worst case doesn’t occur for a particular pattern (like sorted array) and randomized Quick Sort works well in practice.  
Quick Sort is also a cache friendly sorting algorithm as it has good locality of reference when used for arrays.
Quick Sort is also tail recursive, therefore tail call optimizations is done.

Why is Merge Sort preferred for Linked Lists?
Below are implementations of Quicksort and Mergesort for singly and doubly linked lists.
Quick Sort for Doubly Linked List
Quick Sort for Singly Linked List
Merge Sort for Singly Linked List
Merge Sort for Doubly Linked List

In case of linked lists the case is different mainly due to difference in memory allocation of arrays and linked lists. Unlike arrays, linked list nodes may not be adjacent in memory.  
Unlike array, in linked list, we can insert items in the middle in O(1) extra space and O(1) time.  Therefore merge operation of merge sort can be implemented without extra space for linked lists. 
In arrays, we can do random access as elements are continuous in memory. Let us say we have an integer (4-byte) array A and let the address of A[0] be x then to access A[i], we can directly access the memory at (x + i*4). Unlike arrays, we can not do random access in linked list.
 Quick Sort requires a lot of this kind of access. In linked list to access i’th index, we have to travel each and every node from the head to i’th node as we don’t have continuous block of memory. Therefore, the overhead increases for quick sort. Merge sort accesses data sequentially and the need of random access is low. 

Related Articles:

Why quicksort is better than mergesort ?
Know Your Sorting Algorithm | Set 1 (Sorting Weapons used by Programming Languages)
Iterative Merge Sort
Iterative Quick Sort

Thanks to Sayan Mukhopadhyay for providing initial draft for above article. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Merge Sort for Linked ListsMerge Sort for Linked Lists in JavaScriptUnion and Intersection of two linked lists | Set-2 (Using Merge Sort)Quick Sort vs Merge SortMerge Sort for Doubly Linked ListIterative Merge Sort for Linked Listp5.js | Quick SortIterative Quick SortC Program for Iterative Quick SortJava Program for Iterative Quick SortMerge Sort with O(1) extra space merge and O(n lg n) timeComparison among Bubble Sort, Selection Sort and Insertion SortMerge Sort3-way Merge SortIterative Merge Sort

Article Tags : SortingLinked-List-SortingMerge SortQuick Sort
Practice Tags : SortingMerge Sort 

thumb_up
19



To-do

Done



2.2


Based on 78 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Merge Sort for Doubly Linked List


Given a doubly linked list, write a function to sort the doubly linked list in increasing order using merge sort.
For example, the following doubly linked list should be changed to 24810







Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Merge sort for singly linked list is already discussed.  The important change here is to modify the previous pointers also when merging two lists.
Below is the implementation of merge sort for doubly linked list.

C++







filter_none

Minimum adjacent swaps to move maximum and minimum to corners


Given N number of elements, find the minimum number of swaps required so that the maximum element is at the beginning and the minimum element is at last with the condition that only swapping of adjacent elements is allowed.
Examples:

Input: a[] = {3, 1, 5, 3, 5, 5, 2}
Output: 6
Step 1: Swap 5 with 1 to make the array as {3, 5, 1, 3, 5, 5, 2}
Step 2: Swap 5 with 3 to make the array as {5, 3, 1, 3, 5, 5, 2}
Step 3: Swap 1 with 3 at its right to make the array as {5, 3, 3, 1, 5, 5, 2}
Step 4: Swap 1 with 5 at its right to make the array as {5, 3, 3, 5, 1, 5, 2}
Step 5: Swap 1 with 5 at its right to make the array as {5, 3, 3, 5, 5, 1, 2}
Step 6: Swap 1 with 2 at its right to make the array as {5, 3, 3, 5, 5, 2, 1}
After performing 6 swapping operations 5 is at the beginning and 1 at the end





Input: a[] = {5, 6, 1, 3}
Output: 2

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

The approach will be to find the index of the largest element(let l). Find the index of the leftmost largest element if largest element appears in the array more than once. Similarly, find the index of the rightmost smallest element(let r). There exists two cases to solve this problem.  

Case 1:  If l < r: Number of swaps = l + (n-r-1)
Case 2:  If l > r: Number of swaps = l + (n-r-2), as one swap has already been performed while swapping the larger element to the front


C++






filter_none

Activity Selection Problem | Greedy Algo-1



Greedy is an algorithmic paradigm that builds up a solution piece by piece, always choosing the next piece that offers the most obvious and immediate benefit. Greedy algorithms are used for optimization problems. An optimization problem can be solved using Greedy if the problem has the following property: At every step, we can make a choice that looks best at the moment, and we get the optimal solution of the complete problem.
If a Greedy Algorithm can solve a problem, then it generally becomes the best method to solve that problem as the Greedy algorithms are in general more efficient than other techniques like Dynamic Programming. But Greedy algorithms cannot always be applied. For example, Fractional Knapsack problem (See this) can be solved using Greedy, but 0-1 Knapsack cannot be solved using Greedy.
Following are some standard algorithms that are Greedy algorithms.
1) Kruskal’s Minimum Spanning Tree (MST): In Kruskal’s algorithm, we create a MST by picking edges one by one. The Greedy Choice is to pick the smallest weight edge that doesn’t cause a cycle in the MST constructed so far.
2) Prim’s Minimum Spanning Tree: In Prim’s algorithm also, we create a MST by picking edges one by one. We maintain two sets: a set of the vertices already included in MST and the set of the vertices not yet included. The Greedy Choice is to pick the smallest weight edge that connects the two sets.
3) Dijkstra’s Shortest Path: The Dijkstra’s algorithm is very similar to Prim’s algorithm. The shortest path tree is built up, edge by edge. We maintain two sets: a set of the vertices already included in the tree and the set of the vertices not yet included. The Greedy Choice is to pick the edge that connects the two sets and is on the smallest weight path from source to the set that contains not yet included vertices.
4) Huffman Coding: Huffman Coding is a loss-less compression technique. It assigns variable-length bit codes to different characters. The Greedy Choice is to assign least bit length code to the most frequent character.
The greedy algorithms are sometimes also used to get an approximation for Hard optimization problems. For example, Traveling Salesman Problem is a NP-Hard problem. A Greedy choice for this problem is to pick the nearest unvisited city from the current city at every step. This solutions don’t always produce the best optimal solution but can be used to get an approximately optimal solution.





Let us consider the Activity Selection problem as our first example of Greedy algorithms. Following is the problem statement.
You are given n activities with their start and finish times. Select the maximum number of activities that can be performed by a single person, assuming that a person can only work on a single activity at a time.
Example:
Example 1 : Consider the following 3 activities sorted by
by finish time.
     start[]  =  {10, 12, 20};
     finish[] =  {20, 25, 30};
A person can perform at most two activities. The 
maximum set of activities that can be executed 
is {0, 2} [ These are indexes in start[] and 
finish[] ]

Example 2 : Consider the following 6 activities 
sorted by by finish time.
     start[]  =  {1, 3, 0, 5, 8, 5};
     finish[] =  {2, 4, 6, 7, 9, 9};
A person can perform at most four activities. The 
maximum set of activities that can be executed 
is {0, 1, 3, 4} [ These are indexes in start[] and 
finish[] ]







The greedy choice is to always pick the next activity whose finish time is least among the remaining activities and the start time is more than or equal to the finish time of previously selected activity. We can sort the activities according to their finishing time so that we always consider the next activity as minimum finishing time activity.
1) Sort the activities according to their finishing time
2) Select the first activity from the sorted array and print it.
3) Do following for remaining activities in the sorted array.
…….a) If the start time of this activity is greater than or equal to the finish time of previously selected activity then select this activity and print it.
In the following C implementation, it is assumed that the activities are already sorted according to their finish time.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2


What is Minimum Spanning Tree?
Given a connected and undirected graph, a spanning tree of that graph is a subgraph that is a tree and connects all the vertices together. A single graph can have many different spanning trees. A minimum spanning tree (MST) or minimum weight spanning tree for a weighted, connected and undirected graph is a spanning tree with weight less than or equal to the weight of every other spanning tree. The weight of a spanning tree is the sum of weights given to each edge of the spanning tree.
How many edges does a minimum spanning tree has?
A minimum spanning tree has (V – 1) edges where V is the number of vertices in the given  graph. 
What are the applications of Minimum Spanning Tree?
See this for applications of MST.





Below are the steps for finding MST using Kruskal’s algorithm

1. Sort all the edges in non-decreasing order of their weight.
2. Pick the smallest edge. Check if it forms a cycle with the spanning tree formed so far. If cycle is not formed, include this edge. Else, discard it.
3. Repeat step#2 until there are (V-1) edges in the spanning tree.
The step#2 uses Union-Find algorithm to detect cycle. So we recommend to read following post as a prerequisite.
Union-Find Algorithm | Set 1 (Detect Cycle in a Graph)
Union-Find Algorithm | Set 2 (Union By Rank and Path Compression)
The algorithm is a Greedy Algorithm. The Greedy Choice is to pick the smallest weight edge that does not cause a cycle in the MST constructed so far. Let us understand it with an example: Consider the below input graph. 

The graph contains 9 vertices and 14 edges. So, the minimum spanning tree formed will be having (9 – 1) = 8 edges. 
After sorting:
Weight   Src    Dest
1         7      6
2         8      2
2         6      5
4         0      1
4         2      5
6         8      6
7         2      3
7         7      8
8         0      7
8         1      2
9         3      4
10        5      4
11        1      7
14        3      5






Now pick all edges one by one from sorted list of edges
1. Pick edge 7-6: No cycle is formed, include it.

2. Pick edge 8-2: No cycle is formed, include it.

3. Pick edge 6-5: No cycle is formed, include it.

4. Pick edge 0-1: No cycle is formed, include it.





5. Pick edge 2-5: No cycle is formed, include it.

6. Pick edge 8-6: Since including this edge results in cycle, discard it.
7. Pick edge 2-3: No cycle is formed, include it.

8. Pick edge 7-8: Since including this edge results in cycle, discard it.
9. Pick edge 0-7: No cycle is formed, include it.

10. Pick edge 1-2: Since including this edge results in cycle, discard it.
11. Pick edge 3-4: No cycle is formed, include it.

Since the number of edges included equals (V – 1), the algorithm stops here.

Recommended: Please try your approach on {IDE} first, before moving on to the solution.


C++






filter_none

Huffman Coding | Greedy Algo-3


Prefix Codes

Efficient Huffman Coding for Sorted Input | Greedy Algo-4


We recommend to read following post as a prerequisite for this.
Greedy Algorithms | Set 3 (Huffman Coding)
Time complexity of the algorithm discussed in above post is O(nLogn).  If we know that the given array is sorted (by non-decreasing order of frequency), we can generate Huffman codes in O(n) time. Following is a O(n) algorithm for sorted input.





1.  Create two empty queues.
2. Create a leaf node for each unique character and Enqueue it to the first queue in non-decreasing order of frequency. Initially second queue is empty.
3. Dequeue two nodes with the minimum frequency by examining the front of both queues.  Repeat following steps two times
…..a) If second queue is empty, dequeue from first queue.
…..b) If first queue is empty, dequeue from second queue.
…..c) Else, compare the front of two queues and dequeue the minimum. 
4. Create a new internal node with frequency equal to the sum of the two nodes frequencies. Make the first Dequeued node as its left child and the second Dequeued node as right child. Enqueue this node to second queue.
5. Repeat steps#3 and #4 until there is more than one node in the queues. The remaining node is the root node and the tree is complete.

C++







filter_none

Prim’s Minimum Spanning Tree (MST) | Greedy Algo-5



We have discussed Kruskal’s algorithm for Minimum Spanning Tree. Like Kruskal’s algorithm, Prim’s algorithm is also a Greedy algorithm. It starts with an empty spanning tree. The idea is to maintain two sets of vertices. The first set contains the vertices already included in the MST, the other set contains the vertices not yet included. At every step, it considers all the edges that connect the two sets, and picks the minimum weight edge from these edges. After picking the edge, it moves the other endpoint of the edge to the set containing MST.
A group of edges that connects two set of vertices in a graph is called cut in graph theory. So, at every step of Prim’s algorithm, we find a cut (of two sets, one contains the vertices already included in MST and other contains rest of the verices), pick the minimum weight edge from the cut and include this vertex to MST Set (the set that contains already included vertices).
How does Prim’s Algorithm Work? The idea behind Prim’s algorithm is simple, a spanning tree means all vertices must be connected. So the two disjoint subsets (discussed above) of vertices must be connected to make a Spanning Tree. And they must be connected with the minimum weight edge to make it a Minimum Spanning Tree.
Algorithm
1) Create a set mstSet that keeps track of vertices already included in MST.
2) Assign a key value to all vertices in the input graph.  Initialize all key values as INFINITE. Assign key value as 0 for the first vertex so that it is picked first.
3) While mstSet doesn’t include all vertices
….a) Pick a vertex u which is not there in mstSet and has minimum key value.
….b) Include u to mstSet.
….c) Update key value of all adjacent vertices of u. To update the key values, iterate through all adjacent vertices. For every adjacent vertex v, if weight of edge u-v is less than the previous key value of v, update the key value as weight of u-v





The idea of using key values is to pick the minimum weight edge from cut. The key values are used only for vertices which are not yet included in MST, the key value for these vertices indicate the minimum weight edges connecting them to the set of vertices included in MST. 






Let us understand with the following example:

The set mstSet is initially empty and keys assigned to vertices are {0, INF, INF, INF, INF, INF, INF, INF} where INF indicates infinite.  Now pick the vertex with minimum key value.  The vertex 0 is picked, include it in mstSet. So mstSet becomes {0}.  After including to mstSet, update key values of adjacent vertices. Adjacent vertices of 0 are 1 and 7.  The key values of 1 and 7 are updated as 4 and 8.  Following subgraph shows vertices and their key values, only the vertices with finite key values are shown. The vertices included in MST are shown in green color.

Pick the vertex with minimum key value and not already included in MST (not in mstSET).  The vertex 1 is picked and added to mstSet.  So mstSet now becomes {0, 1}.  Update the key values of adjacent vertices of 1. The key value of vertex 2 becomes 8.

Pick the vertex with minimum key value and not already included in MST (not in mstSET).  We can either pick vertex 7 or vertex 2, let vertex 7 is picked.  So mstSet now becomes {0, 1, 7}.  Update the key values of adjacent vertices of 7. The key value of vertex 6 and 8 becomes finite (1 and 7 respectively).

Pick the vertex with minimum key value and not already included in MST (not in mstSET). Vertex 6 is picked. So mstSet now becomes {0, 1, 7, 6}. Update the key values of adjacent vertices of 6. The key value of vertex 5 and 8 are updated.

We repeat the above steps until mstSet  includes all vertices of given graph. Finally, we get the following graph.






Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

How to implement the above algorithm?
 We use a boolean array mstSet[] to represent the set of vertices included in MST.  If a value mstSet[v] is true, then vertex v is included in MST, otherwise not. Array key[] is used to store key values of all vertices. Another array parent[] to store indexes of parent nodes in MST. The parent array is the output array which is used to show the constructed MST.

C++







filter_none

Prim’s MST for Adjacency List Representation | Greedy Algo-6


We recommend to read following two posts as a prerequisite of this post.
1. Greedy Algorithms | Set 5 (Prim’s Minimum Spanning Tree (MST))
2. Graph and its representations
We have discussed Prim’s algorithm and its implementation for adjacency matrix representation of graphs. The time complexity for the matrix representation is O(V^2). In this post, O(ELogV) algorithm for adjacency list representation is discussed.
As discussed in the previous post, in Prim’s algorithm, two sets are maintained, one set contains list of vertices already included in MST, other set contains vertices not yet included. With adjacency list representation, all vertices of a graph can be traversed in O(V+E) time using BFS. The idea is to traverse all vertices of graph using BFS and use a Min Heap to store the vertices not yet included in MST. Min Heap is used as a priority queue to get the minimum weight edge from the cut. Min Heap is used as time complexity of operations like extracting minimum element and decreasing key value is O(LogV) in Min Heap.





Following are the detailed steps.
1) Create a Min Heap of size V where V is the number of vertices in the given graph. Every node of min heap contains vertex number and key value of the vertex.
2) Initialize Min Heap with first vertex as root (the key value assigned to first vertex is 0). The key value assigned to all other vertices is INF (infinite).
3)  While Min Heap is not empty, do following
…..a) Extract the min value node from Min Heap. Let the extracted vertex be u.
…..b) For every adjacent vertex v of u, check if v is in Min Heap (not yet included in MST). If v is in Min Heap and its key value is more than weight of u-v, then update the key value of v as weight of u-v.
Let us understand the above algorithm with the following example:

Initially, key value of first vertex is 0 and INF (infinite) for all other vertices. So vertex 0 is extracted from Min Heap and key values of vertices adjacent to 0 (1 and 7) are updated. Min Heap contains all vertices except vertex 0.
The vertices in green color are the vertices included in MST.

Since key value of vertex 1 is minimum among all nodes in Min Heap, it is extracted from Min Heap and key values of vertices adjacent to 1 are updated (Key is updated if the a vertex is not in Min Heap and previous key value is greater than the weight of edge from 1 to the adjacent). Min Heap contains all vertices except vertex 0 and 1.

Since key value of vertex 7 is minimum among all nodes in Min Heap, it is extracted from Min Heap and key values of vertices adjacent to 7 are updated (Key is updated if the a vertex is not in Min Heap and previous key value is greater than the weight of edge from 7 to the adjacent). Min Heap contains all vertices except vertex 0, 1 and 7.

Since key value of vertex 6 is minimum among all nodes in Min Heap, it is extracted from Min Heap and key values of vertices adjacent to 6 are updated (Key is updated if the a vertex is not in Min Heap and previous key value is greater than the weight of edge from 6 to the adjacent). Min Heap contains all vertices except vertex 0, 1, 7 and 6.

The above steps are repeated for rest of the nodes in Min Heap till Min Heap becomes empty


C++






filter_none

Dijkstra’s shortest path algorithm | Greedy Algo-7



Given a graph and a source vertex in the graph, find shortest paths from source to all vertices in the given graph.
Dijkstra’s algorithm is very similar to Prim’s algorithm for minimum spanning tree. Like Prim’s MST, we generate a SPT (shortest path tree) with given source as root. We maintain two sets, one set contains vertices included in shortest path tree, other set includes vertices not yet included in shortest path tree. At every step of the algorithm, we find a vertex which is in the other set (set of not yet included) and has a minimum distance from the source.
Below are the detailed steps used in Dijkstra’s algorithm to find the shortest path from a single source vertex to all other vertices in the given graph.
Algorithm
1) Create a set sptSet (shortest path tree set) that keeps track of vertices included in shortest path tree, i.e., whose minimum distance from source is calculated and finalized. Initially, this set is empty.
2) Assign a distance value to all vertices in the input graph. Initialize all distance values as INFINITE. Assign distance value as 0 for the source vertex so that it is picked first.
3) While sptSet doesn’t include all vertices
….a) Pick a vertex u which is not there in sptSet and has minimum distance value.
….b) Include u to sptSet.
….c) Update distance value of all adjacent vertices of u. To update the distance values, iterate through all adjacent vertices. For every adjacent vertex v, if sum of distance value of u (from source) and weight of edge u-v, is less than the distance value of v, then update the distance value of v.






Let us understand with the following example:

The set sptSet is initially empty and distances assigned to vertices are {0, INF, INF, INF, INF, INF, INF, INF} where INF indicates infinite. Now pick the vertex with minimum distance value. The vertex 0 is picked, include it in sptSet. So sptSet becomes {0}. After including 0 to sptSet, update distance values of its adjacent vertices. Adjacent vertices of 0 are 1 and 7. The distance values of 1 and 7 are updated as 4 and 8. Following subgraph shows vertices and their distance values, only the vertices with finite distance values are shown. The vertices included in SPT are shown in green colour.

Pick the vertex with minimum distance value and not already included in SPT (not in sptSET). The vertex 1 is picked and added to sptSet. So sptSet now becomes {0, 1}. Update the distance values of adjacent vertices of 1. The distance value of vertex 2 becomes 12.

Pick the vertex with minimum distance value and not already included in SPT (not in sptSET). Vertex 7 is picked. So sptSet now becomes {0, 1, 7}. Update the distance values of adjacent vertices of 7. The distance value of vertex 6 and 8 becomes finite (15 and 9 respectively).

Pick the vertex with minimum distance value and not already included in SPT (not in sptSET). Vertex 6 is picked. So sptSet now becomes {0, 1, 7, 6}. Update the distance values of adjacent vertices of 6. The distance value of vertex 5 and 8 are updated.

We repeat the above steps until sptSet  does include all vertices of given graph. Finally, we get the following Shortest Path Tree (SPT).

How to implement the above algorithm?


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Dijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8


We recommend reading the following two posts as a prerequisite of this post.
1. Greedy Algorithms | Set 7 (Dijkstra’s shortest path algorithm)
2. Graph and its representations
We have discussed Dijkstra’s algorithm and its implementation for adjacency matrix representation of graphs. The time complexity for the matrix representation is O(V^2). In this post, O(ELogV) algorithm for adjacency list representation is discussed.





As discussed in the previous post, in Dijkstra’s algorithm, two sets are maintained, one set contains list of vertices already included in SPT (Shortest Path Tree), other set contains vertices not yet included. With adjacency list representation, all vertices of a graph can be traversed in O(V+E) time using BFS. The idea is to traverse all vertices of graph using BFS and use a Min Heap to store the vertices not yet included in SPT (or the vertices for which shortest distance is not finalized yet).  Min Heap is used as a priority queue to get the minimum distance vertex from set of not yet included vertices. Time complexity of operations like extract-min and decrease-key value is O(LogV) for Min Heap.
Following are the detailed steps.
1) Create a Min Heap of size V where V is the number of vertices in the given graph. Every node of min heap contains vertex number and distance value of the vertex.
2) Initialize Min Heap with source vertex as root (the distance value assigned to source vertex is 0). The distance value assigned to all other vertices is INF (infinite).
3) While Min Heap is not empty, do following
…..a) Extract the vertex with minimum distance value node from Min Heap. Let the extracted vertex be u.
…..b) For every adjacent vertex v of u, check if v is in Min Heap. If v is in Min Heap and distance value is more than weight of u-v plus distance value of u, then update the distance value of v.
Let us understand with the following example. Let the given source vertex be 0

Initially, distance value of source vertex is 0 and INF (infinite) for all other vertices. So source vertex is extracted from Min Heap and distance values of vertices adjacent to 0 (1 and 7) are updated. Min Heap contains all vertices except vertex 0.
The vertices in green color are the vertices for which minimum distances are finalized and are not in Min Heap

Since distance value of vertex 1 is minimum among all nodes in Min Heap, it is extracted from Min Heap and distance values of vertices adjacent to 1 are updated (distance is updated if the a vertex is not in Min Heap and distance through 1 is shorter than the previous distance). Min Heap contains all vertices except vertex 0 and 1.

Pick the vertex with minimum distance value from min heap. Vertex 7 is picked. So min heap now contains all vertices except 0, 1 and 7. Update the distance values of adjacent vertices of 7. The distance value of vertex 6 and 8 becomes finite (15 and 9 respectively).

Pick the vertex with minimum distance from min heap. Vertex 6 is picked. So min heap now contains all vertices except 0, 1, 7 and 6. Update the distance values of adjacent vertices of 6. The distance value of vertex 5 and 8 are updated.





Above steps are repeated till min heap doesn’t become empty. Finally, we get the following shortest path tree.


C++






filter_none

Job Sequencing Problem



Given an array of jobs where every job has a deadline and associated profit if the job is finished before the deadline.  It is also given that every job takes single unit of time, so the minimum possible deadline for any job is 1. How to maximize total profit if only one job can be scheduled at a time.
Examples:
Input: Four Jobs with following 
deadlines and profits
JobID  Deadline  Profit
  a      4        20   
  b      1        10
  c      1        40  
  d      1        30
Output: Following is maximum 
profit sequence of jobs
        c, a   


Input:  Five Jobs with following
deadlines and profits
JobID   Deadline  Profit
  a       2        100
  b       1        19
  c       2        27
  d       1        25
  e       3        15
Output: Following is maximum 
profit sequence of jobs
        c, a, e









Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.




Greedy Algorithms






12 






Greedy Algorithms


<div class="mtq_javawarning" id="mtq_javawarning-1">
  Please wait while the activity loads.</div>

Greedy Algorithm to find Minimum number of Coins


Given a value V, if we want to make change for V Rs, and we have infinite supply of each of the denominations in Indian currency, i.e., we have infinite supply of { 1, 2, 5, 10, 20, 50, 100, 500, 1000} valued coins/notes, what is the minimum number of coins and/or notes needed to make the change?
Examples:
Input: V = 70
Output: 2
We need a 50 Rs note and a 20 Rs note.

Input: V = 121
Output: 3
We need a 100 Rs note, a 20 Rs note and a 
1 Rs coin. 


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



K Centers Problem | Set 1 (Greedy Approximate Algorithm)


Given n cities and distances between every pair of cities, select k cities to place warehouses (or ATMs or Cloud Server) such that the maximum distance of a city to a warehouse (or ATM  or Cloud Server) is minimized. 
For example consider the following four cities, 0, 1, 2 and 3 and distances between them, how do place 2 ATMs among these 4 cities so that the maximum distance of a city to an ATM is minimized.






There is no polynomial time solution available for this problem as the problem is a known NP-Hard problem. There is a polynomial time Greedy approximate algorithm, the greedy algorithm provides a solution which is never worse that twice the optimal solution.  The greedy solution works only if the distances between cities follow Triangular Inequality (Distance between two points is always smaller than sum of distances through a third point). 
The 2-Approximate Greedy Algorithm:
1) Choose the first center arbitrarily.
2) Choose remaining k-1 centers using the following criteria.
            Let c1, c2, c3, … ci be the already chosen centers. Choose
            (i+1)’th center by picking the city which is farthest from already
            selected centers, i.e, the point p which has following value as maximum
                           Min[dist(p, c1), dist(p, c2), dist(p, c3), …. dist(p, ci)]

Example (k = 3 in the above shown Graph)
a) Let the first arbitrarily picked vertex be 0. 
b) The next vertex is 1 because 1 is the farthest vertex from 0. 
c) Remaining cities are 2 and 3. Calculate their distances from already selected centers (0 and 1).  The greedy algorithm basically calculates following values.
        Minimum of all distanced from 2 to already considered centers
        Min[dist(2, 0), dist(2, 1)] = Min[7, 8] = 7
        Minimum of all distanced from 3 to already considered centers
        Min[dist(3, 0), dist(3, 1)] = Min[6, 5] = 5
        After computing the above values, the city 2 is picked as the value corresponding to 2 is maximum.




Note that the greedy algorithm doesn’t give best solution for k = 2 as this is just an approximate algorithm with bound as twice of optimal.
Proof that the above greedy algorithm is 2 approximate.
Let OPT be the maximum distance of a city from a center in the Optimal solution.  We need to show that the maximum distance obtained from Greedy algorithm is 2*OPT.
The proof can be done using contradiction.
a) Assume that the distance from the furthest point to all centers is > 2·OPT.
b) This means that distances between all centers are also > 2·OPT.
c) We have k + 1 points with distances > 2·OPT between every pair.
d) Each point has a center of the optimal solution with distance <= OPT to it. 
e) There exists a pair of points with the same center X in the optimal solution (pigeonhole principle: k optimal centers, k+1 points)
f) The distance between them is at most 2·OPT (triangle inequality) which is a contradiction.
Source:
http://algo2.iti.kit.edu/vanstee/courses/kcenter.pdf
This article is contributed by Harshit. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Set Cover Problem | Set 1 (Greedy Approximate Algorithm)Vertex Cover Problem | Set 1 (Introduction and Approximate Algorithm)Travelling Salesman Problem | Set 2 (Approximate using MST)Activity Selection Problem | Greedy Algo-1Boruvka's algorithm | Greedy Algo-9Greedy Algorithm for Egyptian FractionGraph Coloring | Set 2 (Greedy Algorithm)Dijkstra's shortest path algorithm | Greedy Algo-7Greedy Algorithm to find Minimum number of CoinsDijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2Hungarian Algorithm for Assignment Problem | Set 1 (Introduction)Ford-Fulkerson Algorithm for Maximum Flow ProblemWidest Path Problem | Practical application of Dijkstra's AlgorithmCorrectness of Greedy Algorithms

Article Tags : GraphGreedy
Practice Tags : GreedyGraph 

thumb_up
1



To-do

Done



4.3


Based on 42 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Minimum Number of Platforms Required for a Railway/Bus Station


Given arrival and departure times of all trains that reach a railway station, the task is to find the minimum number of platforms required for the railway station so that no train waits.
We are given two arrays which represent arrival and departure times of trains that stop
Examples:

Input:  arr[]  = {9:00,  9:40, 9:50,  11:00, 15:00, 18:00}
        dep[]  = {9:10, 12:00, 11:20, 11:30, 19:00, 20:00}
Output: 3
There are at-most three trains at a time (time between 11:00 to 11:20)









Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Overlapping Subproblems Property in Dynamic Programming | DP-1



Dynamic Programming is an algorithmic paradigm that solves a given complex problem by breaking it into subproblems and stores the results of subproblems to avoid computing the same results again. Following are the two main properties of a problem that suggests that the given problem can be solved using Dynamic programming.
In this post, we will discuss first property (Overlapping Subproblems) in detail. The second property of Dynamic programming is discussed in next post i.e. Set 2.
1) Overlapping Subproblems
2) Optimal Substructure
1) Overlapping Subproblems:
Like Divide and Conquer, Dynamic Programming combines solutions to sub-problems. Dynamic Programming is mainly used when solutions of same subproblems are needed again and again. In dynamic programming, computed solutions to subproblems are stored in a table so that these don’t have to be recomputed. So Dynamic Programming is not useful when there are no common (overlapping) subproblems because there is no point storing the solutions if they are not needed again. For example, Binary Search doesn’t have common subproblems. If we take an example of following recursive program for Fibonacci Numbers, there are many subproblems which are solved again and again.





filter_none

Optimal Substructure Property in Dynamic Programming | DP-2



As we discussed in Set 1, following are the two main properties of a problem that suggest that the given problem can be solved using Dynamic programming:
1) Overlapping Subproblems
2) Optimal Substructure
We have already discussed Overlapping Subproblem property in the Set 1. Let us discuss Optimal Substructure property here.
 2) Optimal Substructure:  A given problems has Optimal Substructure Property if optimal solution of the given problem can be obtained by using optimal solutions of its subproblems.
For example, the Shortest Path problem has following optimal substructure property:
If a node x lies in the shortest path from a source node u to destination node v then the shortest path from u to v is combination of shortest path from u to x and shortest path from x to v. The standard All Pair Shortest Path algorithms like Floyd–Warshall and Bellman–Ford are typical examples of Dynamic Programming.
On the other hand, the Longest Path problem doesn’t have the Optimal Substructure property. Here by Longest Path we mean longest simple path (path without cycle) between two nodes. Consider the following unweighted graph given in the CLRS book. There are two longest paths from q to t: q→r→t and q→s→t. Unlike shortest paths, these longest paths do not have the optimal substructure property. For example, the longest path q→r→t is not a combination of longest path from q to r and longest path from r to t, because the longest path from q to r is q→s→t→r and the longest path from r to t is r→q→s→t.

We will be covering some example problems in future posts on Dynamic Programming.

Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.
References:
http://en.wikipedia.org/wiki/Optimal_substructure
CLRS book







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Overlapping Subproblems Property in Dynamic Programming | DP-1Bitmasking and Dynamic Programming | Set-2 (TSP)Dynamic Programming on Trees | Set 2Dynamic Programming on Trees | Set-1Convert N to M with given operations using dynamic programmingDynamic Programming | Building BridgesDouble Knapsack | Dynamic ProgrammingHow to solve a Dynamic Programming Problem ?Dynamic Programming vs Divide-and-ConquerNumber of Unique BST with a given key | Dynamic ProgrammingTop 20 Dynamic Programming Interview QuestionsGreedy approach vs Dynamic programmingCompute nCr % p  | Set 1 (Introduction and Dynamic Programming Solution)Longest subsequence with a given OR value : Dynamic Programming ApproachDistinct palindromic sub-strings of the given string using Dynamic ProgrammingImproved By :  ASAJ RAWAT

Article Tags : Dynamic Programming
Practice Tags : Dynamic Programming 

thumb_up
46



To-do

Done



1.7


Based on 261 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Longest Increasing Subsequence | DP-3



We have discussed Overlapping Subproblems and Optimal Substructure properties. 
Let us discuss Longest Increasing Subsequence (LIS) problem as an example problem that can be solved using Dynamic Programming.
The Longest Increasing Subsequence (LIS) problem is to find the length of the longest subsequence of a given sequence such that all elements of the subsequence are sorted in increasing order. For example, the length of LIS for {10, 22, 9, 33, 21, 50, 41, 60, 80} is 6 and LIS is {10, 22, 33, 50, 60, 80}.

More Examples:
Input  : arr[] = {3, 10, 2, 1, 20}
Output : Length of LIS = 3
The longest increasing subsequence is 3, 10, 20

Input  : arr[] = {3, 2}
Output : Length of LIS = 1
The longest increasing subsequences are {3} and {2}

Input : arr[] = {50, 3, 10, 7, 40, 80}
Output : Length of LIS = 4
The longest increasing subsequence is {3, 7, 40, 80}


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







Optimal Substructure:
Let arr[0..n-1] be the input array and L(i) be the length of the LIS ending at index i such that arr[i] is the last element of the LIS.
Then, L(i) can be recursively written as:
L(i) = 1 + max( L(j) ) where 0 < j < i and arr[j] < arr[i]; or
L(i) = 1, if no such j exists.
To find the LIS for a given array, we need to return max(L(i)) where 0 < i < n.
Thus, we see the LIS problem satisfies the optimal substructure property as the main problem can be solved using solutions to subproblems.
Following is a simple recursive implementation of the LIS problem. It follows the recursive structure discussed above.

C/C++






filter_none

Longest Common Subsequence | DP-4



We have discussed Overlapping Subproblems and Optimal Substructure properties in Set 1 and Set 2 respectively. We also discussed one example problem in Set 3. Let us discuss Longest Common Subsequence (LCS) problem as one more example problem that can be solved using Dynamic Programming.
LCS Problem Statement:  Given two sequences, find the length of longest subsequence present in both of them. A subsequence is a sequence that appears in the same relative order, but not necessarily contiguous. For example, “abc”, “abg”, “bdf”, “aeg”, ‘”acefg”, .. etc are subsequences of “abcdefg”. 
In order to find out the complexity of brute force approach, we need to first know the number of possible different subsequences of a string with length n, i.e., find the number of subsequences with lengths ranging from 1,2,..n-1. Recall from theory of permutation and combination that number of combinations with 1 element are nC1. Number of combinations with 2 elements are nC2 and so forth and so on. We know that nC0 + nC1 + nC2 + … nCn = 2n. So a string of length n has 2n-1 different possible subsequences since we do not consider the subsequence with length 0. This implies that the time complexity of the brute force approach will be O(n * 2n). Note that it takes O(n) time to check if a subsequence is common to both the strings. This time complexity can be improved using dynamic programming.
It is a classic computer science problem, the basis of diff (a file comparison program that outputs the differences between two files), and has applications in bioinformatics.
Examples:
LCS for input Sequences “ABCDGH” and “AEDFHR” is “ADH” of length 3.
LCS for input Sequences “AGGTAB” and “GXTXAYB” is “GTAB” of length 4.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







The naive solution for this problem is to generate all subsequences of both given sequences and find the longest matching subsequence.  This solution is exponential in term of time complexity.  Let us see how this problem possesses both important properties of a Dynamic Programming (DP) Problem. 
1) Optimal Substructure: 
Let the input sequences be X[0..m-1] and Y[0..n-1] of lengths m and n respectively. And let L(X[0..m-1],  Y[0..n-1]) be the length of LCS of the two sequences X and Y. Following is the recursive definition of L(X[0..m-1],  Y[0..n-1]).
If last characters of both sequences match (or X[m-1] == Y[n-1]) then
L(X[0..m-1],  Y[0..n-1]) =  1 + L(X[0..m-2],  Y[0..n-2])
If last characters of both sequences do not match (or X[m-1] != Y[n-1]) then
L(X[0..m-1],  Y[0..n-1]) =  MAX ( L(X[0..m-2],  Y[0..n-1]),   L(X[0..m-1],  Y[0..n-2]) )
Examples:
1) Consider the input strings “AGGTAB” and “GXTXAYB”.  Last characters match for the strings. So length of LCS can be written as:
L(“AGGTAB”, “GXTXAYB”) = 1 + L(“AGGTA”, “GXTXAY”)

2) Consider the input strings “ABCDGH” and “AEDFHR. Last characters do not match for the strings.  So length of LCS can be written as:
L(“ABCDGH”, “AEDFHR”) = MAX ( L(“ABCDG”, “AEDFHR”), L(“ABCDGH”, “AEDFH”) )
So the LCS problem has optimal substructure property as the main problem can be solved using solutions to subproblems.
2) Overlapping Subproblems:
Following is simple recursive implementation of the LCS problem. The implementation simply follows the recursive structure mentioned above.

C++







filter_none

Edit Distance | DP-5



Given two strings str1 and str2 and below operations that can performed on str1. Find minimum number of edits (operations) required to convert ‘str1’ into ‘str2’.

Insert
Remove
Replace

All of the above operations are of equal cost.

Examples: 
Input:   str1 = "geek", str2 = "gesek"
Output:  1
We can convert str1 into str2 by inserting a 's'.

Input:   str1 = "cat", str2 = "cut"
Output:  1
We can convert str1 into str2 by replacing 'a' with 'u'.

Input:   str1 = "sunday", str2 = "saturday"
Output:  3
Last three and first characters are same.  We basically
need to convert "un" to "atur".  This can be done using
below three operations. 
Replace 'n' with 'r', insert t, insert a


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Min Cost Path | DP-6



Given a cost matrix cost[][] and a position (m, n) in cost[][], write a function that returns cost of minimum cost path to reach (m, n) from (0, 0). Each cell of the matrix represents a cost to traverse through that cell. Total cost of a path to reach (m, n) is sum of all the costs on that path (including both source and destination). You can only traverse down, right and diagonally lower cells from a given cell, i.e., from a given cell (i, j), cells (i+1, j), (i, j+1) and (i+1, j+1) can be traversed. You may assume that all costs are positive integers.
For example, in the following figure, what is the minimum cost path to (2, 2)?

The path with minimum cost is highlighted in the following figure. The path is (0, 0) –> (0, 1) –> (1, 2) –> (2, 2). The cost of the path is 8 (1 + 2 + 2 + 3).


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







1) Optimal Substructure
The path to reach (m, n) must be through one of the 3 cells:  (m-1, n-1) or (m-1, n) or (m, n-1). So minimum cost to reach (m, n) can be written as “minimum of the 3 cells plus cost[m][n]”.
minCost(m, n) = min (minCost(m-1, n-1), minCost(m-1, n), minCost(m, n-1)) + cost[m][n]
2) Overlapping Subproblems
Following is simple recursive implementation of the MCP (Minimum Cost Path) problem. The implementation simply follows the recursive structure mentioned above.

C







filter_none

Coin Change | DP-7



Given a value N, if we want to make change for N cents, and we have infinite supply of each of S = { S1, S2, .. , Sm} valued coins, how many ways can we make the change? The order of coins doesn’t matter.
For example, for N = 4 and S = {1,2,3}, there are four solutions: {1,1,1,1},{1,1,2},{2,2},{1,3}. So output should be 4. For N = 10 and S = {2, 5, 3, 6}, there are five solutions: {2,2,2,2,2}, {2,2,3,3}, {2,2,6}, {2,3,5} and {5,5}. So the output should be 5.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Matrix Chain Multiplication | DP-8


Given a sequence of matrices, find the most efficient way to multiply these matrices together. The problem is not actually to perform the multiplications, but merely to decide in which order to perform the multiplications.
We have many options to multiply a chain of matrices because matrix multiplication is associative. In other words, no matter how we parenthesize the product, the result will be the same. For example, if we had four matrices A, B, C, and D, we would have:
    (ABC)D = (AB)(CD) = A(BCD) = ....

However, the order in which we parenthesize the product affects the number of simple arithmetic operations needed to compute the product, or the efficiency. For example, suppose A is a 10 × 30 matrix, B is a 30 × 5 matrix, and C is a 5 × 60 matrix. Then,





    (AB)C = (10×30×5) + (10×5×60) = 1500 + 3000 = 4500 operations
    A(BC) = (30×5×60) + (10×30×60) = 9000 + 18000 = 27000 operations.

Clearly the first parenthesization requires less number of operations.
Given an array p[] which represents the chain of matrices such that the ith matrix Ai is of dimension p[i-1] x p[i]. We need to write a function MatrixChainOrder() that should return the minimum number of multiplications needed to multiply the chain.
  Input: p[] = {40, 20, 30, 10, 30}   
  Output: 26000  
  There are 4 matrices of dimensions 40x20, 20x30, 30x10 and 10x30.
  Let the input 4 matrices be A, B, C and D.  The minimum number of 
  multiplications are obtained by putting parenthesis in following way
  (A(BC))D --> 20*30*10 + 40*20*10 + 40*10*30

  Input: p[] = {10, 20, 30, 40, 30} 
  Output: 30000 
  There are 4 matrices of dimensions 10x20, 20x30, 30x40 and 40x30. 
  Let the input 4 matrices be A, B, C and D.  The minimum number of 
  multiplications are obtained by putting parenthesis in following way
  ((AB)C)D --> 10*20*30 + 10*30*40 + 10*40*30

  Input: p[] = {10, 20, 30}  
  Output: 6000  
  There are only two matrices of dimensions 10x20 and 20x30. So there 
  is only one way to multiply the matrices, cost of which is 10*20*30



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Binomial Coefficient | DP-9


Following are common definition of Binomial Coefficients.

A binomial coefficient C(n, k) can be defined as the coefficient of X^k in the expansion of (1 + X)^n.
A binomial coefficient C(n, k) also gives the number of ways, disregarding order, that k objects can be chosen from among n objects; more formally, the number of k-element subsets (or k-combinations) of an n-element set.

The Problem
Write a function that takes two parameters n and k and returns the value of Binomial Coefficient C(n, k). For example, your function should return 6 for n = 4 and k = 2, and it should return 10 for n = 5 and k = 2.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

1) Optimal Substructure
The value of C(n, k) can be recursively calculated using following standard formula for Binomial Coefficients.





   C(n, k) = C(n-1, k-1) + C(n-1, k)
   C(n, 0) = C(n, n) = 1

Following is a simple recursive implementation that simply follows the recursive structure mentioned above.

C++







filter_none

0-1 Knapsack Problem | DP-10



Given weights and values of n items, put these items in a knapsack of capacity W to get the maximum total value in the knapsack.  In other words, given two integer arrays val[0..n-1] and wt[0..n-1] which represent values and weights associated with n items respectively. Also given an integer W which represents knapsack capacity, find out the maximum value subset of val[] such that sum of the weights of this subset is smaller than or equal to W. You cannot break an item, either pick the complete item, or don’t pick it (0-1 property).


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







A simple solution is to consider all subsets of items and calculate the total weight and value of all subsets. Consider the only subsets whose total weight is smaller than W. From all such subsets, pick the maximum value subset.
1) Optimal Substructure:
To consider all subsets of items, there can be two cases for every item: (1) the item is included in the optimal subset, (2) not included in the optimal set.
Therefore, the maximum value that can be obtained from n items is max of following two values.
1) Maximum value obtained by n-1 items and W weight (excluding nth item).
2) Value of nth item plus maximum value obtained by n-1 items and W minus weight of the nth item (including nth item).
If weight of nth item is greater than W, then the nth item cannot be included and case 1 is the only possibility.
2) Overlapping Subproblems
Following is recursive implementation that simply follows the recursive structure mentioned above.

C++







filter_none

Egg Dropping Puzzle | DP-11



The following is a description of the instance of this famous puzzle involving n=2 eggs and a building with k=36 floors.
Suppose that we wish to know which stories in a 36-story building are safe to drop eggs from, and which will cause the eggs to break on landing. We make a few assumptions:
…..An egg that survives a fall can be used again.
…..A broken egg must be discarded.
…..The effect of a fall is the same for all eggs.
…..If an egg breaks when dropped, then it would break if dropped from a higher floor.
…..If an egg survives a fall then it would survive a shorter fall.
…..It is not ruled out that the first-floor windows break eggs, nor is it ruled out that the 36th-floor do not cause an egg to break.
If only one egg is available and we wish to be sure of obtaining the right result, the experiment can be carried out in only one way. Drop the egg from the first-floor window; if it survives, drop it from the second floor window. Continue upward until it breaks. In the worst case, this method may require 36 droppings. Suppose 2 eggs are available. What is the least number of egg-droppings that is guaranteed to work in all cases?
The problem is not actually to find the critical floor, but merely to decide floors from which eggs should be dropped so that total number of trials are minimized.
Source: Wiki for Dynamic Programming


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Longest Palindromic Subsequence | DP-12



Given a sequence, find the length of the longest palindromic subsequence in it.

As another example, if the given sequence is “BBABCBCAB”, then the output should be 7 as “BABCBAB” is the longest palindromic subseuqnce in it. “BBBBB” and “BBCBB” are also palindromic subsequences of the given sequence, but not the longest ones.
The naive solution for this problem is to generate all subsequences of the given sequence and find the longest palindromic subsequence. This solution is exponential in term of time complexity. Let us see how this problem possesses both important properties of a Dynamic Programming (DP) Problem and can efficiently solved using Dynamic Programming.
1) Optimal Substructure: 
Let X[0..n-1] be the input sequence of length n and L(0, n-1) be the length of the longest palindromic subsequence of X[0..n-1]. 
If last and first characters of X are same, then L(0, n-1) = L(1, n-2) + 2.
Else L(0, n-1) = MAX (L(1, n-1), L(0, n-2)).  

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

Following is a general recursive solution with all cases handled.






// Every single character is a palindrome of length 1
L(i, i) = 1 for all indexes i in given sequence

// IF first and last characters are not same
If (X[i] != X[j])  L(i, j) =  max{L(i + 1, j),L(i, j - 1)} 

// If there are only 2 characters and both are same
Else if (j == i + 1) L(i, j) = 2  

// If there are more than two characters, and first and last 
// characters are same
Else L(i, j) =  L(i + 1, j - 1) + 2 

2) Overlapping Subproblems
Following is simple recursive implementation of the LPS problem. The implementation simply follows the recursive structure mentioned above.

C++







filter_none

Cutting a Rod | DP-13



Given a rod of length n inches and an array of prices that contains prices of all pieces of size smaller than n.  Determine the maximum value obtainable by cutting up the rod and selling the pieces. For example, if length of the rod is 8 and the values of different pieces are given as following, then the maximum obtainable value is 22 (by cutting in two pieces of lengths 2 and 6) 

length   | 1   2   3   4   5   6   7   8  
--------------------------------------------
price    | 1   5   8   9  10  17  17  20

And if the prices are as following, then the maximum obtainable value is 24 (by cutting in eight pieces of length 1)
length   | 1   2   3   4   5   6   7   8  
--------------------------------------------
price    | 3   5   8   9  10  17  17  20



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Maximum Sum Increasing Subsequence | DP-14


Given an array of n positive integers. Write a program to find the sum of maximum sum subsequence of the given array such that the integers in the subsequence are sorted in increasing order. For example, if input is {1, 101, 2, 3, 100, 4, 5}, then output should be 106 (1 + 2 + 3 + 100), if the input array is {3, 4, 5, 10}, then output should be 22 (3 + 4 + 5 + 10) and if the input array is {10, 5, 4, 3}, then output should be 10


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Longest Bitonic Subsequence | DP-15


Given an array arr[0 … n-1] containing n positive integers, a subsequence of arr[] is called Bitonic if it is first increasing, then decreasing. Write a function that takes an array as argument and returns the length of the longest bitonic subsequence.
A sequence, sorted in increasing order is considered Bitonic with the decreasing part as empty. Similarly, decreasing order sequence is considered Bitonic with the increasing part as empty. 
Examples:
Input arr[] = {1, 11, 2, 10, 4, 5, 2, 1};
Output: 6 (A Longest Bitonic Subsequence of length 6 is 1, 2, 10, 4, 2, 1)

Input arr[] = {12, 11, 40, 5, 3, 1}
Output: 5 (A Longest Bitonic Subsequence of length 5 is 12, 11, 5, 3, 1)

Input arr[] = {80, 60, 30, 40, 20, 10}
Output: 5 (A Longest Bitonic Subsequence of length 5 is 80, 60, 30, 20, 10)

Source:  Microsoft Interview Question






Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Solution
This problem is a variation of standard Longest Increasing Subsequence (LIS) problem. Let the input array be arr[] of length n. We need to construct two arrays lis[] and lds[] using Dynamic Programming solution of LIS problem.  lis[i] stores the length of the Longest Increasing subsequence ending with arr[i].  lds[i] stores the length of the longest Decreasing subsequence starting from arr[i]. Finally, we need to return the max value of lis[i] + lds[i] – 1 where i is from 0 to n-1.
Following is the implementation of the above Dynamic Programming solution.

C++







filter_none

Floyd Warshall Algorithm | DP-16



The Floyd Warshall Algorithm is for solving the All Pairs Shortest Path problem. The problem is to find shortest distances between every pair of vertices in a given edge weighted directed Graph. 
Example:
Input:
       graph[][] = { {0,   5,  INF, 10},
                    {INF,  0,  3,  INF},
                    {INF, INF, 0,   1},
                    {INF, INF, INF, 0} }
which represents the following graph
             10
       (0)------->(3)
        |         /|\
      5 |          |
        |          | 1
       \|/         |
       (1)------->(2)
            3       
Note that the value of graph[i][j] is 0 if i is equal to j 
And graph[i][j] is INF (infinite) if there is no edge from vertex i to j.

Output:
Shortest distance matrix
      0      5      8      9
    INF      0      3      4
    INF    INF      0      1
    INF    INF    INF      0 


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







Floyd Warshall Algorithm
We initialize the solution matrix same as the input graph matrix as a first step. Then we update the solution matrix by considering all vertices as an intermediate vertex. The idea is to one by one pick all vertices and updates all shortest paths which include the picked vertex as an intermediate vertex in the shortest path. When we pick vertex number k as an intermediate vertex, we already have considered vertices {0, 1, 2, .. k-1} as intermediate vertices. For every pair (i, j) of the source and destination vertices respectively, there are two possible cases.
1) k is not an intermediate vertex in shortest path from i to j. We keep the value of dist[i][j] as it is.
2) k is an intermediate vertex in shortest path from i to j. We update the value of dist[i][j] as dist[i][k] + dist[k][j] if dist[i][j] > dist[i][k] + dist[k][j]
The following figure shows the above optimal substructure property in the all-pairs shortest path problem.

Following is implementations of the Floyd Warshall algorithm.

C++







filter_none

Palindrome Partitioning | DP-17


Given a string, a partitioning of the string is a palindrome partitioning if every substring of the partition is a palindrome. For example, “aba|b|bbabb|a|b|aba” is a palindrome partitioning of “ababbbabbababa”. Determine the fewest cuts needed for palindrome partitioning of a given string.  For example, minimum 3 cuts are needed for “ababbbabbababa”. The three cuts are “a|babbbab|b|ababa”.  If a string is palindrome, then minimum 0 cuts are needed. If a string of length n containing all different characters, then minimum n-1 cuts are needed.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

This problem is a variation of Matrix Chain Multiplication problem. If the string is a palindrome, then we simply return 0. Else, like the Matrix Chain Multiplication problem, we try making cuts at all possible places, recursively calculate the cost for each cut and return the minimum value. 
Let the given string be str and minPalPartion() be the function that returns the fewest cuts needed for palindrome partitioning. following is the optimal substructure property.





// i is the starting index and j is the ending index. i must be passed as 0 and j as n-1
minPalPartion(str, i, j) = 0 if i == j. // When string is of length 1.
minPalPartion(str, i, j) = 0 if str[i..j] is palindrome.

// If none of the above conditions is true, then minPalPartion(str, i, j) can be 
// calculated recursively using the following formula.
minPalPartion(str, i, j) = Min { minPalPartion(str, i, k) + 1 +
                                 minPalPartion(str, k+1, j) } 
                           where k varies from i to j-1

Following is Dynamic Programming solution. It stores the solutions to subproblems in two arrays P[][] and C[][], and reuses the calculated values.

C++







filter_none

Partition problem | DP-18


Partition problem is to determine whether a given set can be partitioned into two subsets such that the sum of elements in both subsets is same. 
Examples:
arr[] = {1, 5, 11, 5}
Output: true 
The array can be partitioned as {1, 5, 5} and {11}

arr[] = {1, 5, 3}
Output: false 
The array cannot be partitioned into equal sum sets.







We strongly recommend that you click here and practice it, before moving on to the solution.


Word Wrap Problem | DP-19


Given a sequence of words, and a limit on the number of characters that can be put in one line (line width). Put line breaks in the given sequence such that the lines are printed neatly. Assume that the length of each word is smaller than the line width.
The word processors like MS Word do task of placing line breaks. The idea is to have balanced lines. In other words, not have few lines with lots of extra spaces and some lines with small amount of extra spaces.
The extra spaces includes spaces put at the end of every line except the last one.  
The problem is to minimize the following total cost.
 Cost of a line = (Number of extra spaces in the line)^3
 Total Cost = Sum of costs for all lines

For example, consider the following string and line width M = 15
 "Geeks for Geeks presents word wrap problem" 
     
Following is the optimized arrangement of words in 3 lines
Geeks for Geeks
presents word
wrap problem 

The total extra spaces in line 1, line 2 and line 3 are 0, 2 and 3 respectively. 
So optimal value of total cost is 0 + 2*2 + 3*3 = 13

Please note that the total cost function is not sum of extra spaces, but sum of cubes (or square is also used) of extra spaces. The idea behind this cost function is to balance the spaces among lines.  For example, consider the following two arrangement of same set of words:





1) There are 3 lines.  One line has 3 extra spaces and all other lines have 0 extra spaces.  Total extra spaces = 3 + 0 + 0 = 3. Total cost = 3*3*3 + 0*0*0 + 0*0*0 = 27.
2) There are 3 lines.  Each of the 3 lines has one extra space. Total extra spaces = 1 + 1 + 1 = 3. Total cost = 1*1*1 + 1*1*1 + 1*1*1 = 3.
Total extra spaces are 3 in both scenarios, but second arrangement should be preferred because extra spaces are balanced in all three lines. The cost function with cubic sum serves the purpose because the value of total cost in second scenario is less.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Method 1 (Greedy Solution)
The greedy solution is to place as many words as possible in the first line. Then do the same thing for the second line and so on until all words are placed.  This solution gives optimal solution for many cases, but doesn’t give optimal solution in all cases. For example, consider the following string “aaa bb cc ddddd” and line width as 6.  Greedy method will produce following output. 
aaa bb 
cc 
ddddd
Extra spaces in the above 3 lines are 0, 4 and 1 respectively. So total cost is 0 + 64 + 1 = 65.
But the above solution is not the best solution. Following arrangement has more balanced spaces. Therefore less value of total cost function.
aaa
bb cc
ddddd
Extra spaces in the above 3 lines are 3, 1 and 1 respectively. So total cost is 27 + 1 + 1 = 29.
Despite being sub-optimal in some cases, the greedy approach is used by many word processors like MS Word and OpenOffice.org Writer.
Method 2 (Dynamic Programming)
The following Dynamic approach strictly follows the algorithm given in solution of Cormen book. First we compute costs of all possible lines in a 2D table lc[][].  The value lc[i][j] indicates the cost to put words from i to j in a single line where i and j are indexes of words in the input sequences. If a sequence of words from i to j cannot fit in a single line, then lc[i][j] is considered infinite (to avoid it from being a part of the solution). Once we have the lc[][] table constructed, we can calculate total cost using following recursive formula.  In the following formula, C[j] is the optimized total cost for arranging words from 1 to j. 





The above recursion has overlapping subproblem property.  For example, the solution of subproblem c(2) is used by c(3), C(4) and so on. So Dynamic Programming   is used to store the results of subproblems. The array c[] can be computed from left to right, since each value depends only on earlier values.
To print the output, we keep track of what words go on what lines, we can keep a parallel p array that points to where each c value came from.  The last line starts at word p[n] and goes through word n. The previous line starts at word p[p[n]] and goes through word p[n] – 1, etc.  The function printSolution() uses p[] to print the solution.
In the below program, input is an array l[] that represents lengths of words in a sequence. The value l[i] indicates length of the ith word (i starts from 1) in theinput  sequence.

C++







filter_none

Maximum Length Chain of Pairs | DP-20


You are given n pairs of numbers. In every pair, the first number is always smaller than the second number. A pair (c, d) can follow another pair (a, b) if b < c. Chain of pairs can be formed in this fashion. Find the longest chain which can be formed from a given set of pairs.
Source: Amazon Interview | Set 2
For example, if the given pairs are {{5, 24}, {39, 60}, {15, 28}, {27, 40}, {50, 90} }, then the longest chain that can be formed is of length 3, and the chain is {{5, 24}, {27, 40}, {50, 90}}

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

This problem is a variation of standard Longest Increasing Subsequence problem. Following is a simple two step process.
1) Sort given pairs in increasing order of first (or smaller) element.  Why do not need sorting? Consider the example {{6, 8}, {3, 4}} to understand the need of sorting.  If we proceed to second step without sorting, we get output as 1.  But the correct output is 2.
2) Now run a modified LIS process where we compare the second element of already finalized LIS with the first element of new LIS being constructed. 





The following code is a slight modification of method 2 of this post.

C++







filter_none

Variations of LIS | DP-21


We have discussed Dynamic Programming solution for Longest Increasing Subsequence problem in this post and a O(nLogn) solution in this post.  Following are commonly asked variations of the standard LIS problem.
1. Building Bridges:  Consider a 2-D map with a horizontal river passing through its center. There are n cities on the southern bank with x-coordinates a(1) … a(n) and n cities on the northern bank with x-coordinates b(1) … b(n). You want to connect as many north-south pairs of cities as possible with bridges such that no two bridges cross. When connecting cities, you can only connect city i on the northern bank to city i on the southern bank. 
8     1     4     3     5     2     6     7  
<---- Cities on the other bank of river---->
--------------------------------------------
  <--------------- River--------------->
--------------------------------------------
1     2     3     4     5     6     7     8
<------- Cities on one bank of river------->

Source: Dynamic Programming Practice Problems. The link also has well explained solution for the problem.
The solution for this problem has been published here.







Box Stacking Problem | DP-22


You are given a set of n types of rectangular 3-D boxes, where the i^th box has height h(i), width w(i) and depth d(i) (all real numbers). You want to create a stack of boxes which is as tall as possible, but you can only stack a box on top of another box if the dimensions of the 2-D base of the lower box are each strictly larger than those of the 2-D base of the higher box. Of course, you can rotate a box so that any side functions as its base. It is also allowable to use multiple instances of the same type of box.
Source: http://people.csail.mit.edu/bdean/6.046/dp/. The link also has video for explanation of solution.


Program for Fibonacci numbers


The Fibonacci numbers are the numbers in the following integer sequence.
0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, ……..
In mathematical terms, the sequence Fn of Fibonacci numbers is defined by the recurrence relation





    Fn = Fn-1 + Fn-2
with seed values
   F0 = 0 and F1 = 1.

Given a number n, print n-th Fibonacci Number.
Examples:
Input  : n = 2
Output : 1

Input  : n = 9
Output : 34



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Minimum number of jumps to reach end



Given an array of integers where each element represents the max number of steps that can be made forward from that element. Write a function to return the minimum number of jumps to reach the end of the array (starting from the first element). If an element is 0, then cannot move through that element.
Example:
Input: arr[] = {1, 3, 5, 8, 9, 2, 6, 7, 6, 8, 9}
Output: 3 (1-> 3 -> 8 ->9)

First element is 1, so can only go to 3. Second element is 3, so can make at most 3 steps eg to 5 or 8 or 9.







Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Maximum size square sub-matrix with all 1s


Given a binary matrix, find out the maximum size square sub-matrix with all 1s. 
For example, consider the below binary matrix.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Algorithm:
Let the given binary matrix be M[R][C]. The idea of the algorithm is to construct an auxiliary size matrix S[][] in which each entry S[i][j] represents size of the square sub-matrix with all 1s including M[i][j] where M[i][j] is the rightmost and bottommost entry in sub-matrix.





1) Construct a sum matrix S[R][C] for the given M[R][C].
     a)    Copy first row and first columns as it is from M[][] to S[][]
     b)    For other entries, use following expressions to construct S[][]
         If M[i][j] is 1 then
            S[i][j] = min(S[i][j-1], S[i-1][j], S[i-1][j-1]) + 1
         Else /*If M[i][j] is 0*/
            S[i][j] = 0
2) Find the maximum entry in S[R][C]
3) Using the value and coordinates of maximum entry in S[i], print 
   sub-matrix of M[][]
For the given M[R][C] in above example, constructed S[R][C] would be:
   0  1  1  0  1
   1  1  0  1  0
   0  1  1  1  0
   1  1  2  2  0
   1  2  2  3  1
   0  0  0  0  0
The value of maximum entry in above matrix is 3 and coordinates of the entry are (4, 3). Using the maximum value and its coordinates, we can find out the required sub-matrix.

C++







filter_none

Ugly Numbers


Ugly numbers are numbers whose only prime factors are 2, 3 or 5. The sequence 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, … shows the first 11 ugly numbers. By convention, 1 is included. 
Given a number n, the task is to find n’th Ugly number.
Examples:





Input  : n = 7
Output : 8

Input  : n = 10
Output : 12

Input  : n = 15
Output : 24

Input  : n = 150
Output : 5832




Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Largest Sum Contiguous Subarray


Write an efficient program to find the sum of contiguous subarray within a one-dimensional array of numbers which has the largest sum. 



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Longest Palindromic Substring | Set 1



Given a string, find the longest substring which is palindrome.  For example, if the given string is “forgeeksskeegfor”, the output should be “geeksskeeg”.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Bellman–Ford Algorithm | DP-23


Given a graph and a source vertex src in graph, find shortest paths from src to all vertices in the given graph. The graph may contain negative weight edges.
We have discussed Dijkstra’s algorithm for this problem. Dijkstra’s algorithm is a Greedy algorithm and time complexity is O(VLogV) (with the use of Fibonacci heap). Dijkstra doesn’t work for Graphs with negative weight edges, Bellman-Ford works for such graphs. Bellman-Ford is also simpler than Dijkstra and suites well for distributed systems.  But time complexity of Bellman-Ford is O(VE), which is more than Dijkstra.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Optimal Binary Search Tree | DP-24


Given a sorted array keys[0.. n-1] of search keys and an array freq[0.. n-1] of frequency counts, where freq[i] is the number of searches to keys[i]. Construct a binary search tree of all keys such that the total cost of all the searches is as small as possible.
Let us first define the cost of a BST.  The cost of a BST node is level of that node multiplied by its frequency.   Level of root is 1.
Examples:





Input:  keys[] = {10, 12}, freq[] = {34, 50}
There can be following two possible BSTs 
        10                       12
          \                     / 
           12                 10
          I                     II
Frequency of searches of 10 and 12 are 34 and 50 respectively.
The cost of tree I is 34*1 + 50*2 = 134
The cost of tree II is 50*1 + 34*2 = 118 


Input:  keys[] = {10, 12, 20}, freq[] = {34, 8, 50}
There can be following possible BSTs
    10                12                 20         10              20
      \             /    \              /             \            /
      12          10     20           12               20         10  
        \                            /                 /           \
         20                        10                12             12  
     I               II             III             IV             V
Among all possible BSTs, cost of the fifth BST is minimum.  
Cost of the fifth BST is 1*50 + 2*34 + 3*8 = 142


Recommended: Please try your approach on {IDE} first, before moving on to the solution.

1) Optimal Substructure:
The optimal cost for freq[i..j] can be recursively calculated using following formula.

We need to calculate optCost(0, n-1) to find the result.  
The idea of above formula is simple, we one by one try all nodes as root (r varies from i to j in second term).  When we make rth node as root, we recursively calculate optimal cost from i to r-1 and r+1 to j.
We add sum of frequencies from i to j (see first term in the above formula), this is added because every search will go through root and one comparison will be done for every search.
2) Overlapping Subproblems
Following is recursive implementation that simply follows the recursive structure mentioned above.

C++







filter_none

Largest Independent Set Problem | DP-26


Given a Binary Tree, find size of the Largest Independent Set(LIS) in it. A subset of all tree nodes is an independent set if there is no edge between any two nodes of the subset.
For example, consider the following binary tree.  The largest independent set(LIS) is {10, 40, 60, 70, 80} and size of the LIS is 5.


Recommended: Please try your approach on {IDE} first, before moving on to the solution.

A Dynamic Programming solution solves a given problem using solutions of subproblems in bottom up manner.  Can the given problem be solved using solutions to subproblems? If yes, then what are the subproblems?  Can we find largest independent set size (LISS) for a node X if we know LISS for all descendants of X? If a node is considered as part of LIS, then its children cannot be part of LIS, but its grandchildren can be. Following is optimal substructure property.





1) Optimal Substructure:
Let LISS(X) indicates size of largest independent set of a tree with root X.  
     LISS(X) = MAX { (1 + sum of LISS for all grandchildren of X),
                     (sum of LISS for all children of X) }

The idea is simple, there are two possibilities for every node X, either X is a member of the set or not a member. If X is a member, then the value of LISS(X) is 1 plus LISS of all grandchildren.  If X is not a member, then the value is sum of LISS of all children.
2) Overlapping Subproblems
Following is recursive implementation that simply follows the recursive structure mentioned above.

C++







filter_none

Subset Sum Problem | DP-25



Given a set of non-negative integers, and a value sum, determine if there is a subset of the given set with sum equal to given sum.
Example:
Input:  set[] = {3, 34, 4, 12, 5, 2}, sum = 9
Output:  True  //There is a subset (4, 5) with sum 9.



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Maximum sum rectangle in a 2D matrix | DP-27


Given a 2D array, find the maximum sum subarray in it.  For example, in the following 2D array, the maximum sum subarray is highlighted with blue rectangle and sum of this subarray is 29.

This problem is mainly an extension of Largest Sum Contiguous Subarray for 1D array. 







Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count number of binary strings without consecutive 1’s


Given a positive integer N, count all possible distinct binary strings of length N such that there are no consecutive 1’s.
Examples:
Input:  N = 2
Output: 3
// The 3 strings are 00, 01, 10

Input: N = 3
Output: 5
// The 5 strings are 000, 001, 010, 100, 101


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Boolean Parenthesization Problem  | DP-37


Given a boolean expression with following symbols. 
Symbols
    'T' ---> true 
    'F' ---> false 
And following operators filled between symbols 
Operators
    &   ---> boolean AND
    |   ---> boolean OR
    ^   ---> boolean XOR 
Count the number of ways we can parenthesize the expression so that the value of expression evaluates to true. 





Let the input be in form of two arrays one contains the symbols (T and F) in order and other contains operators (&, | and ^}
Examples: 
Input: symbol[]    = {T, F, T}
       operator[]  = {^, &}
Output: 2
The given expression is "T ^ F & T", it evaluates true
in two ways "((T ^ F) & T)" and "(T ^ (F & T))"

Input: symbol[]    = {T, F, F}
       operator[]  = {^, |}
Output: 2
The given expression is "T ^ F | F", it evaluates true
in two ways "( (T ^ F) | F )" and "( T ^ (F | F) )". 

Input: symbol[]    = {T, T, F, T}
       operator[]  = {|, &, ^}
Output: 4
The given expression is "T | T & F ^ T", it evaluates true
in 4 ways ((T|T)&(F^T)), (T|(T&(F^T))), (((T|T)&F)^T) 
and (T|((T&F)^T)). 


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Solution:
Let T(i, j) represents the number of ways to parenthesize the symbols between i and j (both inclusive) such that the subexpression between i and j evaluates to true.

<!––>
Let F(i, j) represents the number of ways to parenthesize the symbols between i and j (both inclusive) such that the subexpression between i and j evaluates to false.

<!—
–>
Base Cases:
T(i, i) = 1 if symbol[i] = 'T' 
T(i, i) = 0 if symbol[i] = 'F' 

F(i, i) = 1 if symbol[i] = 'F' 
F(i, i) = 0 if symbol[i] = 'T'
If we draw recursion tree of above recursive solution, we can observe that it many overlapping subproblems.  Like other dynamic programming problems, it can be solved by filling a table in bottom up manner. Following is C++ implementation of dynamic programming solution.

C++







filter_none

Count ways to reach the n’th stair


There are n stairs, a person standing at the bottom wants to reach the top. The person can climb either 1 stair or 2 stairs at a time. Count the number of ways, the person can reach the top.

Consider the example shown in diagram.   The value of n is 3. There are 3 ways to reach the top. The diagram is taken from Easier Fibonacci puzzles





 
 
 
 
 
 
 
More Examples: 
Input: n = 1
Output: 1
There is only one way to climb 1 stair

Input: n = 2
Output: 2
There are two ways: (1, 1) and (2)

Input: n = 4
Output: 5
(1, 1, 1, 1), (1, 1, 2), (2, 1, 1), (1, 2, 1), (2, 2)



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Minimum Cost Polygon Triangulation


A triangulation of a convex polygon is formed by drawing diagonals between non-adjacent vertices (corners) such that the diagonals never intersect.  The problem is to find the cost of triangulation with the minimum cost.   The cost of a triangulation is sum of the weights of its component triangles.  Weight of each triangle is its perimeter (sum of lengths of all sides)
See following example taken from this source. 






Two triangulations of the same convex pentagon. The triangulation on the left has a cost of 8 + 2√2 + 2√5 (approximately 15.30), the one on the right has a cost of 4 + 2√2 + 4√5 (approximately 15.77). 

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

This problem has recursive substructure. The idea is to divide the polygon into three parts: a single triangle, the sub-polygon to the left, and the sub-polygon to the right. We try all possible divisions like this and find the one that minimizes the cost of the triangle plus the cost of the triangulation of the two sub-polygons.
Let Minimum Cost of triangulation of vertices from i to j be minCost(i, j)
If j <= i + 2 Then
  minCost(i, j) = 0
Else
  minCost(i, j) = Min { minCost(i, k) + minCost(k, j) + cost(i, k, j) }
                  Here k varies from 'i+1' to 'j-1'

Cost of a triangle formed by edges (i, j), (j, k) and (k, i) is 
  cost(i, j, k)  = dist(i, j) + dist(j, k) + dist(k, i)
Following is C++ implementation of above naive recursive formula.





filter_none

Mobile Numeric Keypad Problem


Given the mobile numeric keypad. You can only press buttons that are up, left, right or down to the current button. You are not allowed to press bottom row corner buttons (i.e. * and # ).

Given a number N, find out the number of possible numbers of given length. 
Examples:
For N=1, number of possible numbers would be 10 (0, 1, 2, 3, …., 9)
For N=2, number of possible numbers would be 36
Possible numbers: 00,08 11,12,14 22,21,23,25 and so on.
If we start with 0, valid numbers will be 00, 08 (count: 2)
If we start with 1, valid numbers will be 11, 12, 14 (count: 3)
If we start with 2, valid numbers will be 22, 21, 23,25 (count: 4)
If we start with 3, valid numbers will be 33, 32, 36 (count: 3)
If we start with 4, valid numbers will be 44,41,45,47 (count: 4)
If we start with 5, valid numbers will be 55,54,52,56,58 (count: 5)
………………………………
………………………………





We need to print the count of possible numbers.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count of n digit numbers whose sum of digits equals to given sum


Given two integers ‘n’ and ‘sum’, find count of all n digit numbers with sum of digits as ‘sum’. Leading 0’s are not counted as digits.
1 <= n <= 100 and
1 <= sum <= 500
Example: 
Input:  n = 2, sum = 2
Output: 2
Explanation: Numbers are 11 and 20

Input:  n = 2, sum = 5
Output: 5
Explanation: Numbers are 14, 23, 32, 41 and 50

Input:  n = 3, sum = 6
Output: 21



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Minimum Initial Points to Reach Destination


Given a grid with each cell consisting of positive, negative or no points i.e, zero points. We can move across a cell only if we have positive points ( > 0 ). Whenever we pass through a cell, points in that cell are added to our overall points. We need to find minimum initial points to reach cell (m-1, n-1) from (0, 0). 
Constraints :

From a cell (i, j) we can move to (i+1, j) or (i, j+1).
We cannot move from (i, j) if your overall points at (i, j) is <= 0.
We have to reach at (n-1, m-1) with minimum positive points i.e., > 0.
Example: 





Input: points[m][n] = { {-2, -3,   3}, 
                        {-5, -10,  1}, 
                        {10,  30, -5} 
                      };
Output: 7
Explanation: 
7 is the minimum value to reach destination with 
positive throughout the path. Below is the path.

(0,0) -> (0,1) -> (0,2) -> (1, 2) -> (2, 2)

We start from (0, 0) with 7, we reach(0, 1) 
with 5, (0, 2) with 2, (1, 2) with 5, (2, 2)
with and finally we have 1 point (we needed 
greater than 0 points at the end). 

We strongly recommend that you click here and practice it, before moving on to the solution.


Total number of non-decreasing numbers with n digits


A number is non-decreasing if every digit (except the first one) is greater than or equal to previous digit. For example, 223, 4455567, 899, are non-decreasing numbers.
So, given the number of digits n, you are required to find the count of total non-decreasing numbers with n digits.
Examples:





Input:  n = 1
Output: count  = 10

Input:  n = 2
Output: count  = 55

Input:  n = 3
Output: count  = 220
We strongly recommend you to minimize your browser and try this yourself first.
One way to look at the problem is, count of numbers is equal to count n digit number ending with 9 plus count of ending with digit 8 plus count for 7 and so on.  How to get count ending with a particular digit?  We can recur for n-1 length and digits smaller than or equal to the last digit.  So below is recursive formula.
Count of n digit numbers = (Count of (n-1) digit numbers Ending with digit 9) +
                           (Count of (n-1) digit numbers Ending with digit 8) +
                           .............................................+ 
                           .............................................+
                           (Count of (n-1) digit numbers Ending with digit 0) 
Let count ending with digit ‘d’ and length n be count(n, d)
count(n, d) = ∑(count(n-1, i)) where i varies from 0 to d

Total count = ∑count(n-1, d) where d varies from 0 to n-1
The above recursive solution is going to have many overlapping subproblems.  Therefore, we can use Dynamic Programming to build a table in bottom up manner.
Below is the implementation of above idea :

C++






filter_none

Find length of the longest consecutive path from a given starting character


Given a matrix of characters.  Find length of the longest path from a given character, such that all characters in the path are consecutive to each other, i.e., every character in path is next to previous in alphabetical order. It is allowed to move in all 8 directions from a cell.

Example 





Input: mat[][] = { {a, c, d},
                   {h, b, e},
                   {i, g, f}}
      Starting Point = 'e'

Output: 5
If starting point is 'e', then longest path with consecutive 
characters is "e f g h i".

Input: mat[R][C] = { {b, e, f},
                     {h, d, a},
                     {i, c, a}};
      Starting Point = 'b'

Output: 1
'c' is not present in all adjacent cells of 'b'
 

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

The idea is to first search given starting character in the given matrix.  Do Depth First Search (DFS) from all occurrences to find all consecutive paths.  While doing DFS, we may encounter many subproblems again and again.  So we use dynamic programming to store results of subproblems.
Below is the implementation of above idea.

C++







filter_none

Tiling Problem


Given a “2 x n” board and tiles of size “2 x 1”, count the number of ways to tile the given board using the 2 x 1 tiles. A tile can either be placed horizontally i.e., as a 1 x 2 tile or vertically i.e., as 2 x 1 tile. 
Examples: 
Input n = 3
Output: 3
Explanation:
We need 3 tiles to tile the board of size  2 x 3. 
We can tile the board using following ways
1) Place all 3 tiles vertically. 
2) Place first tile vertically and remaining 2 tiles horizontally.
3) Place first 2 tiles horizontally and remaining tiles vertically

Input n = 4
Output: 5
Explanation:
For a 2 x 4 board, there are 5 ways
1) All 4 vertical
2) All 4 horizontal
3) First 2 vertical, remaining 2 horizontal
4) First 2 horizontal, remaining 2 vertical
5) Corner 2 vertical, middle 2 horizontal







Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Let “count(n)” be the count of ways to place tiles on a “2 x n” grid, we have following two ways to place first tile.
1) If we place first tile vertically, the problem reduces to “count(n-1)”
2) If we place first tile horizontally, we have to place second tile also horizontally. So the problem reduces to “count(n-2)”
Therefore, count(n) can be written as below. 
   count(n) = n if n = 1 or n = 2
   count(n) = count(n-1) + count(n-2) 

The above recurrence is nothing but Fibonacci Number expression.  We can find n’th Fibonacci number in O(Log n) time, see below for all method to find n’th Fibonacci Number.
Different methods for n’th Fibonacci Number.
Count the number of ways to tile the floor of size n x m using 1 x m size tiles
This article is contributed by Saurabh Jain. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Tiling with DominoesNuts & Bolts Problem (Lock & Key problem) | Set 2 (Hashmap)Secretary Problem (A Optimal Stopping Problem)Nuts & Bolts Problem (Lock & Key problem) | Set 1Transportation Problem | Set 7 ( Degeneracy in Transportation Problem )Fibonacci problem (Value of Fib(N)*Fib(N) - Fib(N-1) * Fib(N+1))Subset Sum Problem | DP-2521 Matchsticks ProblemPartition problem | DP-180-1 Knapsack Problem | DP-10The Celebrity ProblemBox Stacking Problem | DP-22Water Jug Problem using MemoizationSequence Alignment  problemTransportation Problem | Set 5 ( Unbalanced )

Article Tags : Dynamic ProgrammingMathematicalAmazonFibonacci
Practice Tags :  AmazonDynamic ProgrammingMathematicalFibonacci 

thumb_up
24



To-do

Done



2.5


Based on 124 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Minimum number of squares whose sum equals to given number n


A number can always be represented as a sum of squares of other numbers. Note that 1 is a square and we can always break a number as (1*1 + 1*1 + 1*1 + …).  Given a number n, find the minimum number of squares that sum to X.
Examples :
Input:  n = 100
Output: 1
100 can be written as 102. Note that 100 can also be 
written as 52 + 52 + 52 + 52, but this
representation requires 4 squares.

Input:  n = 6
Output: 3


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

The idea is simple, we start from 1 and go till a number whose square is smaller than or equals to n.  For every number x, we recur for n-x.  Below is the recursive formula.





If n = 1 and x*x <= n 
Below is a simple recursive solution based on above recursive formula.

C++







filter_none

Find minimum number of coins that make a given value



Given a value V, if we want to make change for V cents, and we have infinite supply of each of C = { C1, C2, .. , Cm} valued coins, what is the minimum number of coins to make the change? 
Examples:
Input: coins[] = {25, 10, 5}, V = 30
Output: Minimum 2 coins required
We can use one coin of 25 cents and one of 5 cents 

Input: coins[] = {9, 6, 5, 1}, V = 11
Output: Minimum 2 coins required
We can use one coin of 6 cents and 1 coin of 5 cents



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Collect maximum points in a grid using two traversals


Given a matrix where every cell represents points. How to collect maximum points using two traversals under following conditions?
Let the dimensions of given grid be R x C.
1) The first traversal starts from top left corner, i.e., (0, 0) and should reach left bottom corner, i.e., (R-1, 0). The second traversal starts from top right corner, i.e., (0, C-1) and should reach bottom right corner, i.e., (R-1, C-1)/





2) From a point (i, j), we can move to (i+1, j+1) or (i+1, j-1) or (i+1, j)
3) A traversal gets all points of a particular cell through which it passes. If one traversal has already collected points of a cell, then the other traversal gets no points if goes through that cell again.
Input :
    int arr[R][C] = {{3, 6, 8, 2},
                     {5, 2, 4, 3},
                     {1, 1, 20, 10},
                     {1, 1, 20, 10},
                     {1, 1, 20, 10},
                    };

     Output: 73

Explanation :

First traversal collects total points of value 3 + 2 + 20 + 1 + 1 = 27

Second traversal collects total points of value 2 + 4 + 10 + 20 + 10 = 46.
Total Points collected = 27 + 46 = 73.
We strongly recommend you to minimize your browser and try this yourself first.
The idea is to do both traversals concurrently. We start first from (0, 0) and second traversal from (0, C-1) simultaneously.  The important thing to note is, at any particular step both traversals will be in same row as in all possible three moves, row number is increased.  Let (x1, y1) and (x2, y2) denote current positions of first and second traversals respectively. Thus at any time x1 will be equal to x2 as both of them move forward but variation is possible along y. Since variation in y could occur in 3 ways no change (y), go left (y – 1), go right (y + 1). So in total 9 combinations among y1, y2 are possible.   The 9 cases as mentioned below after base cases.
Both traversals always move forward along x
Base Cases:
// If destinations reached
if (x == R-1 && y1 == 0 && y2 == C-1)
maxPoints(arr, x, y1, y2) = arr[x][y1] + arr[x][y2];

// If any of the two locations is invalid (going out of grid)
if input is not valid
maxPoints(arr, x, y1, y2) = -INF  (minus infinite)

// If both traversals are at same cell, then we count the value of cell
// only once.
If y1 and y2 are same
    result = arr[x][y1]
Else
    result = arr[x][y1] + arr[x][y2] 

result  +=  max { // Max of 9 cases
                  maxPoints(arr, x+1, y1+1, y2),    
                  maxPoints(arr, x+1, y1+1, y2+1),
                  maxPoints(arr, x+1, y1+1, y2-1),
                  maxPoints(arr, x+1, y1-1, y2),    
                  maxPoints(arr, x+1, y1-1, y2+1),
                  maxPoints(arr, x+1, y1-1, y2-1),
                  maxPoints(arr, x+1, y1, y2),
                  maxPoints(arr, x+1, y1, y2+1),
                  maxPoints(arr, x+1, y1, y2-1) 
                }

The above recursive solution has many subproblems that are solved again and again. Therefore, we can use Dynamic Programming to solve the above problem more efficiently.  Below is memoization (Memoization is alternative to table based iterative solution in Dynamic Programming) based implementation.  In below implementation, we use a memoization table ‘mem’ to keep track of already solved problems.

C++







filter_none

Shortest Common Supersequence


Given two strings str1 and str2, find the shortest string that has both str1 and str2 as subsequences.
Examples :
Input:   str1 = "geek",  str2 = "eke"
Output: "geeke"

Input:   str1 = "AGGTAB",  str2 = "GXTXAYB"
Output:  "AGXGTXAYB"



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Compute sum of digits in all numbers from 1 to n


Given a number n, find sum of digits in all numbers from 1 to n.
Examples:
Input: n = 5
Output: Sum of digits in numbers from 1 to 5 = 15

Input: n = 12
Output: Sum of digits in numbers from 1 to 12 = 51

Input: n = 328
Output: Sum of digits in numbers from 1 to 328 = 3241

Naive Solution:
A naive solution is to go through every number x from 1 to n, and compute sum in x by traversing all digits of x. Below is the implementation of this idea.

C++







filter_none

Count possible ways to construct buildings


Given an input number of sections and each section has 2 plots on either sides of the road. Find all possible ways to construct buildings in the plots such that there is a space between any 2 buildings.
Example : 
N = 1
Output = 4
Place a building on one side.
Place a building on other side
Do not place any building.
Place a building on both sides.

N = 3 
Output = 25
3 sections, which means possible ways for one side are 
BSS, BSB, SSS, SBS, SSB where B represents a building 
and S represents an empty space
Total possible ways are 25, because a way to place on 
one side can correspond to any of 5 ways on other side.

N = 4 
Output = 64

We strongly recommend to minimize your browser and try this yourself first





We can simplify the problem to first calculate for one side only. If we know the result for one side, we can always do square of the result and get result for two sides.
A new building can be placed on a section if section just before it has space.  A space can be placed anywhere (it doesn’t matter whether the previous section has a building or not).
Let countB(i) be count of possible ways with i sections
              ending with a building.
    countS(i) be count of possible ways with i sections
              ending with a space.

// A space can be added after a building or after a space.
countS(N) = countB(N-1) + countS(N-1)

// A building can only be added after a space.
countB[N] = countS(N-1)

// Result for one side is sum of the above two counts.
result1(N) = countS(N) + countB(N)

// Result for two sides is square of result1(N)
result2(N) = result1(N) * result1(N) 
Below is the implementation of above idea.

C++






filter_none

Maximum profit by buying and selling a share at most twice


In a daily share trading, a buyer buys shares in the morning and sells it on the same day. If the trader is allowed to make at most 2 transactions in a day, whereas the second transaction can only start after the first one is complete (Sell->buy->sell->buy).  Given stock prices throughout the day, find out the maximum profit that a share trader could have made.
Examples: 
Input:   price[] = {10, 22, 5, 75, 65, 80}
Output:  87
Trader earns 87 as sum of 12 and 75
Buy at price 10, sell at 22, buy at 5 and sell at 80

Input:   price[] = {2, 30, 15, 10, 8, 25, 80}
Output:  100
Trader earns 100 as sum of 28 and 72
Buy at price 2, sell at 30, buy at 8 and sell at 80

Input:   price[] = {100, 30, 15, 10, 8, 25, 80};
Output:  72
Buy at price 8 and sell at 80.

Input:   price[] = {90, 80, 70, 60, 50}
Output:  0
Not possible to earn.

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

A Simple Solution is to consider every index ‘i’ and do following 





Max profit with at most two transactions =
       MAX {max profit with one transaction and subarray price[0..i] +
            max profit with one transaction and aubarray price[i+1..n-1]  }
i varies from 0 to n-1. 
Maximum possible using one transaction can be calculated using the following O(n) algorithm

The maximum difference between two elements such that larger element appears after the smaller number
Time complexity of above simple solution is O(n2).
We can do this O(n) using following Efficient Solution.  The idea is to store the maximum possible profit of every subarray and solve the problem in the following two phases.
1) Create a table profit[0..n-1] and initialize all values in it 0.
2) Traverse price[] from right to left and update profit[i] such that profit[i] stores maximum profit achievable from one transaction in subarray price[i..n-1]
3) Traverse price[] from left to right and update profit[i] such that profit[i] stores maximum profit such that profit[i] contains maximum achievable profit from two transactions in subarray price[0..i].
4) Return profit[n-1]
To do step 2, we need to keep track of the maximum price from right to left side and to do step 3, we need to keep track of the minimum price from left to right.  Why we traverse in reverse directions? The idea is to save space, in the third step, we use the same array for both purposes, maximum with 1 transaction and maximum with 2 transactions. After iteration i, the array profit[0..i] contains the maximum profit with 2 transactions and profit[i+1..n-1] contains profit with two transactions.
Below are implementations of the above idea.

C++






filter_none

How to print maximum number of  A’s using given four keys


This is a famous interview question asked in Google, Paytm and many other company interviews. 
Below is the problem statement.
Imagine you have a special keyboard with the following keys: 
Key 1:  Prints 'A' on screen
Key 2: (Ctrl-A): Select screen
Key 3: (Ctrl-C): Copy selection to buffer
Key 4: (Ctrl-V): Print buffer on screen appending it
                 after what has already been printed. 

If you can only press the keyboard for N times (with the above four
keys), write a program to produce maximum numbers of A's. That is to
say, the input parameter is N (No. of keys that you can press), the 
output is M (No. of As that you can produce).
Examples:





Input:  N = 3
Output: 3
We can at most get 3 A's on screen by pressing 
following key sequence.
A, A, A

Input:  N = 7
Output: 9
We can at most get 9 A's on screen by pressing 
following key sequence.
A, A, A, Ctrl A, Ctrl C, Ctrl V, Ctrl V

Input:  N = 11
Output: 27
We can at most get 27 A's on screen by pressing 
following key sequence.
A, A, A, Ctrl A, Ctrl C, Ctrl V, Ctrl V, Ctrl A, 
Ctrl C, Ctrl V, Ctrl V

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Below are few important points to note.
a) For N < 7, the output is N itself. 
b) Ctrl V can be used multiple times to print current buffer (See last two examples above). The idea is to compute the optimal string length for N keystrokes by using a simple insight. The sequence of N keystrokes which produces an optimal string length will end with a suffix of Ctrl-A, a Ctrl-C, followed by only Ctrl-V’s . (For N > 6)
The task is to find out the break=point after which we get the above suffix of keystrokes. Definition of a breakpoint is that instance after which we need to only press Ctrl-A, Ctrl-C once and the only Ctrl-V’s afterwards to generate the optimal length. If we loop from N-3 to 1 and choose each of these values for the break-point, and compute that optimal string they would produce. Once the loop ends, we will have the maximum of the optimal lengths for various breakpoints, thereby giving us the optimal length for N keystrokes.
Below is implementation based on above idea.

C






filter_none

Find the minimum cost to reach destination using a train


There are N stations on route of a train.  The train goes from station 0 to N-1.  The ticket cost for all pair of stations (i, j) is given where j is greater than i.  Find the minimum cost to reach the destination.
Consider the following example:
Input: 
cost[N][N] = { {0, 15, 80, 90},
              {INF, 0, 40, 50},
              {INF, INF, 0, 70},
              {INF, INF, INF, 0}
             };
There are 4 stations and cost[i][j] indicates cost to reach j 
from i. The entries where j < i are meaningless.

Output:
The minimum cost is 65
The minimum cost can be obtained by first going to station 1 
from 0. Then from station 1 to station 3.


Recommended: Please try your approach on {IDE} first, before moving on to the solution.

The minimum cost to reach N-1 from 0 can be recursively written as following:





minCost(0, N-1) = MIN { cost[0][n-1],  
                        cost[0][1] + minCost(1, N-1),  
                        minCost(0, 2) + minCost(2, N-1), 
                        ........, 
                        minCost(0, N-2) + cost[N-2][n-1] } 
The following is the implementation of above recursive formula.

C++






filter_none

Vertex Cover Problem | Set 2  (Dynamic Programming Solution for Tree)


A vertex cover of an undirected graph is a subset of its vertices such that for every edge (u, v) of the graph, either ‘u’ or ‘v’ is in vertex cover. Although the name is Vertex Cover, the set covers all edges of the given graph.
The problem to find minimum size vertex cover of a graph is NP complete. But it can be solved in polynomial time for trees.  In this post a solution for Binary Tree is discussed.  The same solution can be extended for n-ary trees.
For example, consider the following binary tree. The smallest vertex cover is {20, 50, 30} and size of the vertex cover is 3.

The idea is to consider following two possibilities for root and recursively for all nodes down the root.
1) Root is part of vertex cover: In this case root covers all children edges.  We recursively calculate size of vertex covers for left and right subtrees and add 1 to the result (for root).





2) Root is not part of vertex cover: In this case, both children of root must be included in vertex cover to cover all root to children edges.  We recursively calculate size of vertex covers of all grandchildren and number of children to the result (for two children of root).
Below are implementation of above idea.

C







filter_none

Count number of ways to reach a given score in a game


Consider a game where a player can score 3 or 5 or 10 points in a move.  Given a total score n, find number of ways to reach the given score.
Examples:
Input: n = 20
Output: 4
There are following 4 ways to reach 20
(10, 10)
(5, 5, 10)
(5, 5, 5, 5)
(3, 3, 3, 3, 3, 5)

Input: n = 13
Output: 2
There are following 2 ways to reach 13
(3, 5, 5)
(3, 10)


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

This problem is a variation of coin change problem and can be solved in O(n) time and O(n) auxiliary space.





The idea is to create a table of size n+1 to store counts of all scores from 0 to n.  For every possible move (3, 5 and 10), increment values in table.

C++







filter_none

Weighted Job Scheduling


Given N jobs where every job is represented by following three elements of it.

 Start Time
 Finish Time
 Profit or Value Associated (>= 0)

Find the maximum profit subset of jobs such that no two jobs in the subset overlap. 
Example: 





Input: Number of Jobs n = 4
       Job Details {Start Time, Finish Time, Profit}
       Job 1:  {1, 2, 50} 
       Job 2:  {3, 5, 20}
       Job 3:  {6, 19, 100}
       Job 4:  {2, 100, 200}
Output: The maximum profit is 250.
We can get the maximum profit by scheduling jobs 1 and 4.
Note that there is longer schedules possible Jobs 1, 2 and 3 
but the profit with this schedule is 20+50+100 which is less than 250. 

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

A simple version of this problem is discussed here where every job has same profit or value.  The Greedy Strategy for activity selection doesn’t work here as a schedule with more jobs may have smaller profit or value.
The above problem can be solved using following recursive solution.
1) First sort jobs according to finish time.
2) Now apply following recursive process. 
   // Here arr[] is array of n jobs
   findMaximumProfit(arr[], n)
   {
     a) if (n == 1) return arr[0];
     b) Return the maximum of following two profits.
         (i) Maximum profit by excluding current job, i.e., 
             findMaximumProfit(arr, n-1)
         (ii) Maximum profit by including the current job            
   }

How to find the profit including current job?
The idea is to find the latest job before the current job (in 
sorted array) that doesn't conflict with current job 'arr[n-1]'. 
Once we find such a job, we recur for all jobs till that job and
add profit of current job to result.
In the above example, "job 1" is the latest non-conflicting
for "job 4" and "job 2" is the latest non-conflicting for "job 3".
 
The following is C++ implementation of above naive recursive method.





filter_none

Longest Even Length Substring such that Sum of First and Second Half is same


Given a string ‘str’ of digits, find the length of the longest substring of ‘str’, such that the length of the substring is 2k digits and sum of left k digits is equal to the sum of right k digits. 
Examples :
Input: str = "123123"
Output: 6
The complete string is of even length and sum of first and second
half digits is same

Input: str = "1538023"
Output: 4
The longest substring with same first and second half sum is "5380"


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Simple Solution [ O(n3) ]
A Simple Solution is to check every substring of even length.  The following is the implementation of simple approach.

C++












filter_none

Naive algorithm for Pattern Searching


Given a text txt[0..n-1] and a pattern pat[0..m-1], write a function search(char pat[], char txt[]) that prints all occurrences of pat[] in txt[]. You may assume that n > m. 
Examples: 
Input:  txt[] = "THIS IS A TEST TEXT"
        pat[] = "TEST"
Output: Pattern found at index 10

Input:  txt[] =  "AABAACAADAABAABA"
        pat[] =  "AABA"
Output: Pattern found at index 0
        Pattern found at index 9
        Pattern found at index 12


Pattern searching is an important problem in computer science. When we do search for a string in notepad/word file or browser or database, pattern searching algorithms are used to show the search results. 







Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



KMP Algorithm for Pattern Searching



Given a text txt[0..n-1] and a pattern pat[0..m-1], write a function search(char pat[], char txt[]) that prints all occurrences of pat[] in txt[]. You may assume that n > m. 
Examples: 
Input:  txt[] = "THIS IS A TEST TEXT"
        pat[] = "TEST"
Output: Pattern found at index 10

Input:  txt[] =  "AABAACAADAABAABA"
        pat[] =  "AABA"
Output: Pattern found at index 0
        Pattern found at index 9
        Pattern found at index 12




Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Rabin-Karp Algorithm for Pattern Searching



Given a text txt[0..n-1] and a pattern pat[0..m-1], write a function search(char pat[], char txt[]) that prints all occurrences of pat[] in txt[]. You may assume that n > m.
Examples: 
Input:  txt[] = "THIS IS A TEST TEXT"
        pat[] = "TEST"
Output: Pattern found at index 10

Input:  txt[] =  "AABAACAADAABAABA"
        pat[] =  "AABA"
Output: Pattern found at index 0
        Pattern found at index 9
        Pattern found at index 12








The Naive String Matching algorithm slides the pattern one by one.  After each slide, it one by one checks characters at the current shift and if all characters match then prints the match.
Like the Naive Algorithm, Rabin-Karp algorithm also slides the pattern one by one. But unlike the Naive algorithm, Rabin Karp algorithm matches the hash value of the pattern with the hash value of current substring of text,  and if the hash values match then only it starts matching individual characters.  So Rabin Karp algorithm needs to calculate hash values for following strings.





1) Pattern itself.
2) All the substrings of text of length m. 
Since we need to efficiently calculate hash values for all the substrings of size m of text, we must have a hash function which has following property.
Hash at the next shift must be efficiently computable from the current hash value and next character in text or we can say hash(txt[s+1 .. s+m]) must be efficiently computable from hash(txt[s .. s+m-1]) and txt[s+m] i.e.,  hash(txt[s+1 .. s+m])= rehash(txt[s+m], hash(txt[s .. s+m-1])) and rehash must be O(1) operation.
The hash function suggested by Rabin and Karp calculates an integer value.  The integer value for a string is numeric value of a string. For example, if all possible characters are from 1 to 10, the numeric value of “122” will be 122. The number of possible characters is higher than 10 (256 in general) and pattern length can be large. So the numeric values cannot be practically stored as an integer. Therefore, the numeric value is calculated using modular arithmetic to make sure that the hash values can be stored in an integer variable (can fit in memory words).  To do rehashing, we need to take off the most significant digit and add the new least significant digit for in hash value.  Rehashing is done using the following formula. 
hash( txt[s+1 .. s+m] ) = ( d ( hash( txt[s .. s+m-1]) – txt[s]*h ) + txt[s + m] ) mod q 
hash( txt[s .. s+m-1] ) : Hash value at shift s.
hash( txt[s+1 .. s+m] ) :  Hash value at next shift (or shift s+1)
d:  Number of characters in the alphabet
q:  A prime number
h: d^(m-1)

How does above expression work? 

This is simple mathematics, we compute decimal value of current window from previous window.
For example pattern length is 3 and string is “23456”
You compute the value of first window (which is “234”) as 234.
How how will you compute value of next window “345”?  You will do (234 – 2*100)*10 + 5 and get 345.

C++






filter_none

Optimized Naive Algorithm for Pattern Searching


Question: We have discussed Naive String matching algorithm here. Consider a situation where all characters of pattern are different. Can we modify the original Naive String Matching algorithm so that it works better for these types of patterns.  If we can, then what are the changes to original algorithm?
Solution: In the original Naive String matching algorithm , we always slide the pattern by 1. When all characters of pattern are different, we can slide the pattern by more than 1. Let us see how can we do this. When a mismatch occurs after j matches, we know that the first character of pattern will not match the j matched characters because all characters of pattern are different.  So we can always slide the pattern by j without missing any valid shifts.  Following is the modified code that is optimized for the special patterns.

C++







filter_none

Finite Automata algorithm for Pattern Searching


Given a text txt[0..n-1] and a pattern pat[0..m-1], write a function search(char pat[], char txt[]) that prints all occurrences of pat[] in txt[]. You may assume that n > m.
Examples: 
Input:  txt[] = "THIS IS A TEST TEXT"
        pat[] = "TEST"
Output: Pattern found at index 10

Input:  txt[] =  "AABAACAADAABAABA"
        pat[] =  "AABA"
Output: Pattern found at index 0
        Pattern found at index 9
        Pattern found at index 12


Pattern searching is an important problem in computer science. When we do search for a string in notepad/word file or browser or database, pattern searching algorithms are used to show the search results. 





We have discussed the following algorithms in the previous posts:
Naive Algorithm 
KMP Algorithm
Rabin Karp Algorithm
In this post, we will discuss Finite Automata (FA) based pattern searching algorithm. In FA based algorithm, we preprocess the pattern and build a 2D array that represents a Finite Automata. Construction of the FA is the main tricky part of this algorithm. Once the FA is built, the searching is simple. In search, we simply need to start from the first state of the automata and the first character of the text. At every step, we consider next character of text, look for the next state in the built FA and move to a new state. If we reach the final state, then the pattern is found in the text. The time complexity of the search process is O(n).
Before we discuss FA construction, let us take a look at the following FA for pattern ACACAGA.


The above diagrams represent graphical and tabular representations of pattern ACACAGA.
Number of states in FA will be M+1 where M is length of the pattern. The main thing to construct FA is to get the next state from the current state for every possible character. Given a character x and a state k, we can get the next state by considering the string “pat[0..k-1]x” which is basically concatenation of pattern characters pat[0], pat[1] … pat[k-1] and the character x. The idea is to get length of the longest prefix of the given pattern such that the prefix is also suffix of “pat[0..k-1]x”. The value of length gives us the next state. For example, let us see how to get the next state from current state 5 and character ‘C’ in the above diagram. We need to consider the string, “pat[0..4]C” which is “ACACAC”. The length of the longest prefix of the pattern such that the prefix is suffix of “ACACAC”is 4 (“ACAC”). So the next state (from state 5) is 4 for character ‘C’. 
In the following code, computeTF() constructs the FA. The time complexity of the computeTF() is O(m^3*NO_OF_CHARS) where m is length of the pattern and NO_OF_CHARS is size of alphabet (total number of possible characters in pattern and text). The implementation tries all possible prefixes starting from the longest possible that can be a suffix of “pat[0..k-1]x”. There are better implementations to construct FA in O(m*NO_OF_CHARS) (Hint: we can use something like lps array construction in KMP algorithm). We have covered the better implementation in our next post on pattern searching.

C






filter_none

Pattern Searching | Set 6 (Efficient Construction of Finite Automata)


In the previous post, we discussed Finite Automata based pattern searching algorithm. The FA (Finite Automata) construction method discussed in previous post takes O((m^3)*NO_OF_CHARS) time. FA can be constructed in O(m*NO_OF_CHARS) time. In this post, we will discuss the O(m*NO_OF_CHARS) algorithm for FA construction. The idea is similar to lps (longest prefix suffix) array construction discussed in the KMP algorithm. We use previously filled rows to fill a new row. 


The above diagrams represent graphical and tabular representations of pattern ACACAGA.





Algorithm:
1) Fill the first row. All entries in first row are always 0 except the entry for pat[0] character. For pat[0] character, we always need to go to state 1.
2) Initialize lps as 0. lps for the first index is always 0.
3) Do following for rows at index i = 1 to M. (M is the length of the pattern)
…..a) Copy the entries from the row at index equal to lps.
…..b) Update the entry for pat[i] character to i+1.
…..c) Update lps “lps = TF[lps][pat[i]]” where TF is the 2D array which is being constructed.
Following is C/C++ implementation for the above algorithm.
Implementation

C++







filter_none

Boyer Moore Algorithm for Pattern Searching


Pattern searching is an important problem in computer science. When we do search for a string in notepad/word file or browser or database, pattern searching algorithms are used to show the search results. A typical problem statement would be-
Given a text txt[0..n-1] and a pattern pat[0..m-1], write a function search(char pat[], char txt[]) that prints all occurrences of pat[] in txt[]. You may assume that n > m. 
Examples: 
Input:  txt[] = "THIS IS A TEST TEXT"
        pat[] = "TEST"
Output: Pattern found at index 10

Input:  txt[] =  "AABAACAADAABAABA"
        pat[] =  "AABA"
Output: Pattern found at index 0
        Pattern found at index 9
        Pattern found at index 12


In this post, we will discuss Boyer Moore pattern searching algorithm. Like KMP and Finite Automata algorithms, Boyer Moore algorithm also preprocesses the pattern.
Boyer Moore is a combination of following two approaches.
1) Bad Character Heuristic
2) Good Suffix Heuristic 





Both of the above heuristics can also be used independently to search a pattern in a text.  Let us first understand how two independent approaches work together in the Boyer Moore algorithm.  If we take a look at the Naive algorithm, it slides the pattern over the text one by one. KMP algorithm does preprocessing over the pattern so that the pattern can be shifted by more than one. The Boyer Moore algorithm does preprocessing for the same reason. It processes the pattern and creates different arrays for both heuristics. At every step, it slides the pattern by the max of the slides suggested by the two heuristics. So it uses best of the two heuristics at every step.
Unlike the previous pattern searching algorithms, Boyer Moore algorithm starts matching from the last character of the pattern.
In this post, we will discuss bad character heuristic, and discuss Good Suffix heuristic in the next post. 
Bad Character Heuristic
The idea of bad character heuristic is simple. The character of the text which doesn’t match with the current character of the pattern is called the Bad Character. Upon mismatch, we shift the pattern until –
1) The mismatch becomes a match
2) Pattern P move past the mismatched character.
Case 1 – Mismatch become match
We will lookup the position of last occurrence of mismatching character in pattern and if mismatching character exist in pattern then we’ll shift the pattern such that it get aligned to the mismatching character in text T.
case 1
Explanation: In the above example, we got a mismatch at position 3. Here our mismatching character is “A”. Now we will search for last occurrence of “A” in pattern. We got “A” at position 1 in pattern (displayed in Blue) and this is the last occurrence of it. Now we will shift pattern 2 times so that “A” in pattern get aligned with “A” in text.
Case 2 – Pattern move past the mismatch character
We’ll lookup the position of last occurrence of mismatching character in pattern and if character does not exist we will shift pattern past the mismatching character.
case2
Explanation: Here we have a mismatch at position 7. The mismatching character “C” does not exist in pattern before position 7 so we’ll shift pattern past to the position 7 and eventually in above example we have got a perfect match of pattern (displayed in Green). We are doing this because, “C” do not exist in pattern so at every shift before position 7 we will get mismatch and our search will be fruitless.
In the following implementation, we preprocess the pattern and store the last occurrence of every possible character in an array of size equal to alphabet size. If the character is not present at all, then it may result in a shift by m (length of pattern). Therefore, the bad character heuristic takes  time in the best case.

C++







filter_none

Suffix Array | Set 1 (Introduction)


We strongly recommend to read following post on suffix trees as a pre-requisite for this post.
Pattern Searching | Set 8 (Suffix Tree Introduction)
A suffix array is a sorted array of all suffixes of a given string. The definition is similar to Suffix Tree which is compressed trie of all suffixes of the given text. Any suffix tree based algorithm can be replaced with an algorithm that uses a suffix array enhanced with additional information and solves the same problem in the same time complexity (Source Wiki).
A suffix array can be constructed from Suffix tree by doing a DFS traversal of the suffix tree. In fact Suffix array and suffix tree both can be constructed from each other in linear time.
Advantages of suffix arrays over suffix trees include improved space requirements, simpler linear time construction algorithms (e.g., compared to Ukkonen’s algorithm) and improved cache locality (Source: Wiki)





Example:
Let the given string be "banana".

0 banana                          5 a
1 anana     Sort the Suffixes     3 ana
2 nana      ---------------->     1 anana  
3 ana        alphabetically       0 banana  
4 na                              4 na   
5 a                               2 nana

So the suffix array for "banana" is {5, 3, 1, 0, 4, 2}
Naive method to build Suffix Array
A simple method to construct suffix array is to make an array of all suffixes and then sort the array. Following is implementation of simple method.





filter_none

Anagram Substring Search (Or Search for all permutations)


Given a text txt[0..n-1] and a pattern pat[0..m-1], write a function search(char pat[], char txt[]) that prints all occurrences of pat[] and its permutations (or anagrams) in txt[]. You may assume that n > m. 
Expected time complexity is O(n)
Examples: 
1) Input:  txt[] = "BACDGABCDA"  pat[] = "ABCD"
   Output:   Found at Index 0
             Found at Index 5
             Found at Index 6
2) Input: txt[] =  "AAABABAA" pat[] = "AABA"
   Output:   Found at Index 0
             Found at Index 1
             Found at Index 4






We strongly recommend that you click here and practice it, before moving on to the solution.


Pattern Searching using a Trie of all Suffixes


Problem Statement: Given a text txt[0..n-1] and a pattern pat[0..m-1], write a function search(char pat[], char txt[]) that prints all occurrences of pat[] in txt[]. You may assume that n > m.
As discussed in the previous post, we discussed that there are two ways efficiently solve the above problem.
1) Preprocess Pattern: KMP Algorithm, Rabin Karp Algorithm, Finite Automata, Boyer Moore Algorithm.





2) Preprocess Text: Suffix Tree
The best possible time complexity achieved by first (preprocssing pattern) is O(n) and by second (preprocessing text) is O(m) where m and n are lengths of pattern and text respectively.
Note that the second way does the searching only in O(m) time and it is preferred when text doesn’t doesn’t change very frequently and there are many search queries. We have discussed Suffix Tree (A compressed Trie of all suffixes of Text) .
Implementation of Suffix Tree may be time consuming for problems to be coded in a technical interview or programming contexts. In this post simple implementation of a Standard Trie of all Suffixes is discussed. The implementation is close to suffix tree, the only thing is, it’s a simple Trie instead of compressed Trie.
As discussed in Suffix Tree post, the idea is, every pattern that is present in text (or we can say every substring of text) must be a prefix of one of all possible suffixes. So if we build a Trie of all suffixes, we can find the pattern in O(m) time where m is pattern length.
Building a Trie of Suffixes
1) Generate all suffixes of given text.
2) Consider all suffixes as individual words and build a trie.
Let us consider an example text “banana\0” where ‘\0’ is string termination character. Following are all suffixes of “banana\0”
banana\0
anana\0
nana\0
ana\0
na\0
a\0
\0
If we consider all of the above suffixes as individual words and build a Trie, we get following.

How to search a pattern in the built Trie?
Following are steps to search a pattern in the built Trie.
1) Starting from the first character of the pattern and root of the Trie, do following for every character.
…..a) For the current character of pattern, if there is an edge from the current node, follow the edge.
…..b) If there is no edge, print “pattern doesn’t exist in text” and return.
2) If all characters of pattern have been processed, i.e., there is a path from root for characters of the given pattern, then print print all indexes where pattern is present. To store indexes, we use a list with every node that stores indexes of suffixes starting at the node.
Following is the implementation of the above idea.

C++







filter_none

Aho-Corasick Algorithm for Pattern Searching


Given an input text and an array of k words, arr[], find all occurrences of all words in the input text. Let n be the length of text and m be the total number characters in all words, i.e. m = length(arr[0]) + length(arr[1]) + … + length(arr[k-1]). Here k is total numbers of input words.
Example:
Input: text = "ahishers"    
       arr[] = {"he", "she", "hers", "his"}

Output:
   Word his appears from 1 to 3
   Word he appears from 4 to 5
   Word she appears from 3 to 5
   Word hers appears from 4 to 7

If we use a linear time searching algorithm like KMP, then we need to one by one search all words in text[]. This gives us total time complexity as O(n + length(word[0]) + O(n + length(word[1]) + O(n + length(word[2]) + … O(n + length(word[k-1]). This time complexity can be written as O(n*k + m).
Aho-Corasick Algorithm finds all words in O(n + m + z) time where z is total number of occurrences of words in text. The Aho–Corasick string matching algorithm formed the basis of the original Unix command fgrep.






Prepocessing : Build an automaton of all words in arr[]  The automaton has mainly three functions:
Go To :   This function simply follows edges
          of Trie of all words in arr[]. It is
          represented as 2D array g[][] where
          we store next state for current state 
          and character.

Failure : This function stores all edges that are
          followed when current character doesn't
          have edge in Trie.  It is represented as
          1D array f[] where we store next state for
          current state. 

Output :  Stores indexes of all words that end at 
          current state. It is represented as 1D 
          array o[] where we store indexes
          of all matching words as a bitmap for 
          current state.


Matching : Traverse the given text over built automaton to find all matching words.

Preprocessing: 


We first Build a Trie (or Keyword Tree) of all words.

­­kasai’s Algorithm for Construction of LCP array from Suffix Array


Background Suffix Array : A suffix array is a sorted array of all suffixes of a given string.
Let the given string be “banana”.
0 banana                          5 a
1 anana     Sort the Suffixes     3 ana
2 nana      ---------------->     1 anana  
3 ana        alphabetically       0 banana  
4 na                              4 na   
5 a                               2 nana
The suffix array for “banana” :
suffix[] = {5, 3, 1, 0, 4, 2}





We have discussed Suffix Array and it O(nLogn) construction .
Once Suffix array is built, we can use it to efficiently search a pattern in a text. For example, we can use Binary Search to find a pattern (Complete code for the same is discussed here)
LCP Array 
The Binary Search based solution discussed here takes O(m*Logn) time where m is length of the pattern to be searched and n is length of the text. With the help of LCP array, we can search a pattern in O(m + Log n) time. For example, if our task is to search “ana” in “banana”, m = 3, n = 5.
LCP Array is an array of size n (like Suffix Array). A value lcp[i] indicates length of the longest common prefix of the suffixes inexed by suffix[i] and suffix[i+1]. suffix[n-1] is not defined as there is no suffix after it.
txt[0..n-1] = "banana"
suffix[]  = {5, 3, 1, 0, 4, 2| 
lcp[]     = {1, 3, 0, 0, 2, 0}

Suffixes represented by suffix array in order are:
{"a", "ana", "anana", "banana", "na", "nana"}


lcp[0] = Longest Common Prefix of "a" and "ana"     = 1
lcp[1] = Longest Common Prefix of "ana" and "anana" = 3
lcp[2] = Longest Common Prefix of "anana" and "banana" = 0
lcp[3] = Longest Common Prefix of "banana" and "na" = 0
lcp[4] = Longest Common Prefix of "na" and "nana" = 2
lcp[5] = Longest Common Prefix of "nana" and None = 0
How to construct LCP array?
LCP array construction is done two ways:
1) Compute the LCP array as a byproduct to the suffix array (Manber & Myers Algorithm)
2) Use an already constructed suffix array in order to compute the LCP values. (Kasai Algorithm).
There exist algorithms that can construct Suffix Array in O(n) time and therefore we can always construct LCP array in O(n) time. But in the below implementation, a O(n Log n) algorithm is discussed.
kasai’s Algorithm 
In this article kasai’s Algorithm is discussed. The algorithm constructs LCP array from suffix array and input text in O(n) time. The idea is based on below fact:
Let lcp of suffix beginning at txt[i[ be k. If k is greater than 0, then lcp for suffix beginning at txt[i+1] will be at-least k-1. The reason is, relative order of characters remain same. If we delete the first character from both suffixes, we know that at least k characters will match. For example for substring “ana”, lcp is 3, so for string “na” lcp will be at-least 2. Refer this for proof.
Below is C++ implementation of Kasai’s algorithm.





filter_none

Z algorithm (Linear time pattern searching Algorithm)


This algorithm finds all occurrences of a pattern in a text in linear time.  Let length of text be n and of pattern be m, then total time taken is O(m + n) with linear space complexity.  Now we can see that both time and space complexity is same as KMP algorithm but this algorithm is Simpler to understand.
In this algorithm, we construct a Z array.
What is Z Array?
For a string str[0..n-1], Z array is of same length as string. An element Z[i] of Z array stores length of the longest substring starting from str[i] which is also a prefix of str[0..n-1]. The first entry of Z array is meaning less as complete string is always prefix of itself.





Example:
Index            0   1   2   3   4   5   6   7   8   9  10  11 
Text             a   a   b   c   a   a   b   x   a   a   a   z
Z values         X   1   0   0   3   1   0   0   2   2   1   0 
More Examples:
str  = "aaaaaa"
Z[]  = {x, 5, 4, 3, 2, 1}

str = "aabaacd"
Z[] = {x, 1, 0, 2, 1, 0, 0}

str = "abababab"
Z[] = {x, 0, 6, 0, 4, 0, 2, 0}
 
How is Z array helpful in Searching Pattern in Linear time?
The idea is to concatenate pattern and text, and create a string “P$T” where P is pattern, $ is a special character should not be present in pattern and text, and T is text.  Build the Z array for concatenated string.  In Z array, if Z value at any point is equal to pattern length, then pattern is present at that point. 
Example:
Pattern P = "aab",  Text T = "baabaa"

The concatenated string is = "aab$baabaa"

Z array for above concatenated string is {x, 1, 0, 0, 0, 
                                          3, 1, 0, 2, 1}.
Since length of pattern is 3, the value 3 in Z array 
indicates presence of pattern. 
How to construct Z array?
     A Simple Solution is two run two nested loops, the outer loop goes to every index and the inner loop finds length of the longest prefix that matches substring starting at current index. The time complexity of this solution is O(n2).
      We can construct Z array in linear time.  
The idea is to maintain an interval [L, R] which is the interval with max R
such that [L,R] is prefix substring (substring which is also prefix). 

Steps for maintaining this interval are as follows – 

1) If i > R then there is no prefix substring that starts before i and 
   ends after i, so we reset L and R and compute new [L,R] by comparing 
   str[0..] to str[i..] and get Z[i] (= R-L+1).

2) If i <= R then let K = i-L,  now Z[i] >= min(Z[K], R-i+1)  because 
   str[i..] matches with str[K..] for atleast R-i+1 characters (they are in
   [L,R] interval which we know is a prefix substring).     
   Now two sub cases arise – 
      a) If Z[K] < R-i+1  then there is no prefix substring starting at 
         str[i] (otherwise Z[K] would be larger)  so  Z[i] = Z[K]  and 
         interval [L,R] remains same.
      b) If Z[K] >= R-i+1 then it is possible to extend the [L,R] interval
         thus we will set L as i and start matching from str[R]  onwards  and
         get new R then we will update interval [L,R] and calculate Z[i] (=R-L+1).
For better understanding of above step by step procedure please check this animation – http://www.utdallas.edu/~besp/demo/John2010/z-algorithm.htm
The algorithm runs in linear time because  we never compare character less than R and with matching we increase R by one so there are at most T comparisons. In mismatch case, mismatch happen only once for each i (because of which R stops), that’s  another at most T comparison making overall linear complexity.
Below is the implementation of Z algorithm for pattern searching.

C++






filter_none

Program to wish Women’s Day


This article demonstrates the pattern to print the Venus Symbol (International gender symbol for females).

C++







filter_none

Manacher’s Algorithm – Linear Time Longest Palindromic Substring – Part 1


Given a string, find the longest substring which is palindrome. 

if the given string is “forgeeksskeegfor”, the output should be “geeksskeeg”
if the given string is “abaaba”, the output should be “abaaba”
if the given string is “abababa”, the output should be “abababa”
if the given string is “abcbabcbabcba”, the output should be “abcbabcba”

We have already discussed Naïve [O(n3)] and quadratic [O(n2)] approaches at Set 1 and Set 2.
In this article, we will talk about Manacher’s algorithm which finds Longest Palindromic Substring in linear time.
One way (Set 2) to find a palindrome is to start from the center of the string and compare characters in both directions one by one. If corresponding characters on both sides (left and right of the center) match, then they will make a palindrome.
Let’s consider string “abababa”.
Here center of the string is 4th character (with index 3) b. If we match characters in left and right of the center, all characters match and so string “abababa” is a palindrome.
                    
Here center position is not only the actual string character position but it could be the position between two characters also.
Consider string “abaaba” of even length. This string is palindrome around the position between 3rd and 4th characters a and a respectively.





                    
To find Longest Palindromic Substring of a string of length N, one way is take each possible 2*N + 1 centers (the N character positions, N-1 between two character positions and 2 positions at left and right ends), do the character match in both left and right directions at each 2*N+ 1 centers and keep track of LPS. This approach takes O(N^2) time and that’s what we are doing in Set 2.
Let’s consider two strings “abababa” and “abaaba” as shown below:
                    
                    
In these two strings, left and right side of the center positions (position 7 in 1st string and position 6 in 2nd string) are symmetric. Why? Because the whole string is palindrome around the center position.
If we need to calculate Longest Palindromic Substring at each 2*N+1 positions from left to right, then palindrome’s symmetric property could help to avoid some of the unnecessary computations (i.e. character comparison). If there is a palindrome of some length L centered at any position P, then we may not need to compare all characters in left and right side at position P+1. We already calculated LPS at positions before P and they can help to avoid some of the comparisons after position P.
This use of information from previous positions at a later point of time makes the Manacher’s algorithm linear. In Set 2, there is no reuse of previous information and so that is quadratic.
Manacher’s algorithm is probably considered complex to understand, so here we will discuss it in as detailed way as we can. Some of it’s portions may require multiple reading to understand it properly.
Let’s look at string “abababa”. In 3rd figure above, 15 center positions are shown. We need to calculate length of longest palindromic string at each of these positions.

At position 0, there is no LPS at all (no character on left side to compare), so length of LPS will be 0.
At position 1, LPS is a, so length of LPS will be 1.
At position 2, there is no LPS at all (left and right characters a and b don’t match), so length of LPS will be 0.
At position 3, LPS is aba, so length of LPS will be 3.
At position 4, there is no LPS at all (left and right characters b and a don’t match), so length of LPS will be 0.
At position 5, LPS is ababa, so length of LPS will be 5.

…… and so on
We store all these palindromic lengths in an array, say L. Then string S and LPS Length L look like below:
                    
Similarly, LPS Length L of string “abaaba” will look like:
                    
In LPS Array L:

LPS length value at odd positions (the actual character positions) will be odd and greater than or equal to 1 (1 will come from the center character itself if nothing else matches in left and right side of it)
LPS length value at even positions (the positions between two characters, extreme left and right positions) will be even and greater than or equal to 0 (0 will come when there is no match in left and right side)

Position and index for the string are two different things here. For a given string S of length N, indexes will be from 0 to N-1 (total N indexes) and positions will be from 0 to 2*N (total 2*N+1 positions).
LPS length value can be interpreted in two ways, one in terms of index and second in terms of position. LPS value d at position I (L[i] = d) tells that:

Substring from position i-d to i+d is a palindrome of length d (in terms of position)
Substring from index (i-d)/2 to [(i+d)/2 – 1] is a palindrome of length d (in terms of index)

e.g. in string “abaaba”, L[3] = 3 means substring from position 0 (3-3) to 6 (3+3) is a palindrome which is “aba” of length 3, it also means that substring from index 0 [(3-3)/2] to 2 [(3+3)/2 – 1] is a palindrome which is “aba” of length 3.
                    
Now the main task is to compute LPS array efficiently. Once this array is computed, LPS of string S will be centered at position with maximum LPS length value.
We will see it in Part 2.
This article is contributed by Anurag Singh. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 2Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 3Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 4Longest Palindromic Substring using Palindromic Tree | Set 3Longest Palindromic Substring | Set 1Longest Palindromic Substring | Set 2Longest Non-palindromic substringZ algorithm (Linear time pattern searching Algorithm)Suffix Tree Application 6 - Longest Palindromic SubstringFind the time which is palindromic and comes after the given timeMaximum length palindromic substring such that it starts and ends with given charLongest Palindromic Subsequence | DP-12Print Longest Palindromic SubsequenceFind a sorted subsequence of size 3 in linear timeFind Two Missing Numbers | Set 1 (An Interesting Linear Time Solution)Improved By :  Light_Kiera

Article Tags : ArraysPattern SearchingStringsMicrosoftpalindrome
Practice Tags :  MicrosoftArraysStringspalindromePattern Searching 

thumb_up
13



To-do

Done



3.9


Based on 83 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Manacher’s Algorithm – Linear Time Longest Palindromic Substring – Part 2


In Manacher’s Algorithm – Part 1, we gone through some of the basics and LPS length array.
Here we will see how to calculate LPS length array efficiently.
To calculate LPS array efficiently, we need to understand how LPS length for any position may relate to LPS length value of any previous already calculated position.
For string “abaaba”, we see following:
                    
If we look around position 3:






LPS length value at position 2 and position 4 are same
LPS length value at position 1 and position 5 are same

We calculate LPS length values from left to right starting from position 0, so we can see if we already know LPS length values at positions 1, 2 and 3 already then we may not need to calculate LPS length at positions 4 and 5 because they are equal to LPS length values at corresponding positions on left side of position 3.
If we look around position 6:

LPS length value at position 5 and position 7 are same
LPS length value at position 4 and position 8 are same

…………. and so on.
If we already know LPS length values at positions 1, 2, 3, 4, 5 and 6 already then we may not need to calculate LPS length at positions 7, 8, 9, 10 and 11 because they are equal to LPS length values at corresponding positions on left side of position 6.
For string “abababa”, we see following:
                    
If we already know LPS length values at positions 1, 2, 3, 4, 5, 6 and 7 already then we may not need to calculate LPS length at positions 8, 9, 10, 11, 12 and 13 because they are equal to LPS length values at corresponding positions on left side of position 7.
Can you see why LPS length values are symmetric around positions 3, 6, 9 in string “abaaba”? That’s because there is a palindromic substring around these positions. Same is the case in string “abababa” around position 7.
Is it always true that LPS length values around at palindromic center position are always symmetric (same)?
Answer is NO.
Look at positions 3 and 11 in string “abababa”. Both positions have LPS length 3. Immediate left and right positions are symmetric (with value 0), but not the next one. Positions 1 and 5 (around position 3) are not symmetric. Similarly, positions 9 and 13 (around position 11) are not symmetric.
At this point, we can see that if there is a palindrome in a string centered at some position, then LPS length values around the center position may or may not be symmetric depending on some situation. If we can identify the situation when left and right positions WILL BE SYMMETRIC around the center position, we NEED NOT calculate LPS length of the right position because it will be exactly same as LPS value of corresponding position on the left side which is already known. And this fact where we are avoiding LPS length computation at few positions makes Manacher’s Algorithm linear.
In situations when left and right positions WILL NOT BE SYMMETRIC around the center position, we compare characters in left and right side to find palindrome, but here also algorithm tries to avoid certain no of comparisons. We will see all these scenarios soon.
Let’s introduce few terms to proceed further:


centerPosition – This is the position for which LPS length is calculated and let’s say LPS length at centerPosition is d (i.e. L[centerPosition] = d)
centerRightPosition – This is the position which is right to the centerPosition and d position away from centerPosition (i.e. centerRightPosition = centerPosition + d)
centerLeftPosition – This is the position which is left to the centerPosition and d position away from centerPosition (i.e. centerLeftPosition = centerPosition – d)
currentRightPosition – This is the position which is right of the centerPosition for which LPS length is not yet known and has to be calculated
currentLeftPosition – This is the position on the left side of centerPosition which corresponds to the currentRightPosition
centerPosition  – currentLeftPosition = currentRightPosition – centerPosition
currentLeftPosition = 2* centerPosition  – currentRightPosition
i-left palindrome – The palindrome i positions left of centerPosition, i.e. at currentLeftPosition
i-right palindrome – The palindrome i positions right of centerPosition, i.e. at currentRightPosition
center palindrome – The palindrome at centerPosition

When we are at centerPosition for which LPS length is known, then we also know LPS length of all positions smaller than centerPosition. Let’s say LPS length at centerPosition is d, i.e.
L[centerPosition] = d
It means that substring between positions “centerPosition-d” to “centerPosition+d” is a palindrom.
Now we proceed further to calculate LPS length of positions greater than centerPosition.
Let’s say we are at currentRightPosition ( > centerPosition) where we need to find LPS length.
For this we look at LPS length of currentLeftPosition which is already calculated.




If LPS length of currentLeftPosition is less than “centerRightPosition – currentRightPosition”, then LPS length of currentRightPosition will be equal to LPS length of currentLeftPosition. So
L[currentRightPosition] = L[currentLeftPosition] if L[currentLeftPosition] < centerRightPosition – currentRightPosition. This is Case 1.
Let’s consider below scenario for string “abababa”:
                          (click to see it clearly)
                    
We have calculated LPS length up-to position 7 where L[7] = 7, if we consider position 7 as centerPosition, then centerLeftPosition will be 0 and centerRightPosition will be 14.
Now we need to calculate LPS length of other positions on the right of centerPosition.
For currentRightPosition = 8, currentLeftPosition is 6 and L[currentLeftPosition] = 0
Also centerRightPosition – currentRightPosition = 14 – 8 = 6
Case 1 applies here and so L[currentRightPosition] = L[8] = 0
Case 1 applies to positions 10 and 12, so,
L[10] = L[4] = 0
L[12] = L[2] = 0
If we look at position 9, then:
currentRightPosition = 9
currentLeftPosition = 2* centerPosition  – currentRightPosition = 2*7 – 9 = 5
centerRightPosition – currentRightPosition = 14 – 9 = 5
Here L[currentLeftPosition] = centerRightPosition – currentRightPosition, so Case 1 doesn’t apply here. Also note that centerRightPosition is the extreme end position of the string. That means center palindrome is suffix of input string. In that case, L[currentRightPosition] = L[currentLeftPosition]. This is Case 2.
Case 2 applies to positions 9, 11, 13 and 14, so:
L[9] = L[5] = 5
L[11] = L[3] = 3
L[13] = L[1] = 1
L[14] = L[0] = 0
What is really happening in Case 1 and Case 2? This is just utilizing the palindromic symmetric property and without any character match, it is finding LPS length of new positions.
When a bigger length palindrome contains a smaller length palindrome centered at left side of it’s own center, then based on symmetric property, there will be another same smaller palindrome centered on the right of bigger palindrome center. If left side smaller palindrome is not prefix of bigger palindrome, then Case 1 applies and if it is a prefix AND bigger palindrome is suffix of the input string itself, then Case 2 applies.
The longest palindrome i places to the right of the current center (the i-right palindrome) is as long as the longest palindrome i places to the left of the current center (the i-left palindrome) if the i-left palindrome is completely contained in the longest palindrome around the current center (the center palindrome) and the i-left palindrome is not a prefix of the center palindrome (Case 1) or (i.e. when i-left palindrome is a prefix of center palindrome) if the center palindrome is a suffix of the entire string (Case 2).




In Case 1 and Case 2, i-right palindrome can’t expand more than corresponding i-left palindrome (can you visualize why it can’t expand more?), and so LPS length of i-right palindrome is exactly same as LPS length of i-left palindrome.
Here both i-left and i-right palindromes are completely contained in center palindrome (i.e. L[currentLeftPosition] <= centerRightPosition – currentRightPosition)
Now if i-left palindrome is not a prefix of center palindrome (L[currentLeftPosition] < centerRightPosition – currentRightPosition), that means that i-left palindrome was not able to expand up-to position centerLeftPosition. 
If we look at following with centerPosition = 11, then
                          (click to see it clearly)
                    
centerLeftPosition would be 11 – 9 = 2, and centerRightPosition would be 11 + 9 = 20
If we take currentRightPosition = 15, it’s currentLeftPosition is 7. Case 1 applies here and so L[15] = 3. i-left palindrome at position 7 is “bab” which is completely contained in center palindrome at position 11 (which is “dbabcbabd”). We can see that i-right palindrome (at position 15) can’t expand more than i-left palindrome (at position 7). 
If there was a possibility of expansion, i-left palindrome could have expanded itself more already. But there is no such possibility as i-left palindrome is prefix of center palindrome. So due to symmetry property, i-right palindrome will be exactly same as i-left palindrome and it can’t expand more. This makes L[currentRightPosition] = L[currentLeftPosition] in Case 1.
Now if we consider centerPosition = 19, then centerLeftPosition = 12 and centerRightPosition = 26
If we take currentRightPosition = 23, it’s currentLeftPosition is 15. Case 2 applies here and so L[23] = 3. i-left palindrome at position 15 is “bab” which is completely contained in center palindrome at position 19 (which is “babdbab”). In Case 2, where i-left palindrome is prefix of center palindrome, i-right palindrome can’t expand more than length of i-left palindrome because center palindrome is suffix of input string so there are no more character left to compare and expand. This makes L[currentRightPosition] = L[currentLeftPosition] in Case 2.
Case 1:  L[currentRightPosition] = L[currentLeftPosition] applies when:

i-left palindrome is completely contained in center palindrome
i-left palindrome is NOT a prefix of center palindrome

Both above conditions are satisfied when
L[currentLeftPosition] < centerRightPosition – currentRightPosition
Case 2:  L[currentRightPosition] = L[currentLeftPosition] applies when:

i-left palindrome is prefix of center palindrome (means completely contained also)
center palindrome is suffix of input string

Above conditions are satisfied when
L[currentLeftPosition] = centerRightPosition – currentRightPosition (For 1st condition) AND
centerRightPosition = 2*N where N is input string length N (For 2nd condition).




Case 3:  L[currentRightPosition] > = L[currentLeftPosition] applies when:

i-left palindrome is prefix of center palindrome (and so i-left palindrome is completely contained in center palindrome)
center palindrome is NOT suffix of input string

Above conditions are satisfied when
L[currentLeftPosition] = centerRightPosition – currentRightPosition (For 1st condition) AND
centerRightPosition < 2*N where N is input string length N (For 2nd condition).
In this case, there is a possibility of i-right palindrome expansion and so length of i-right palindrome is at least as long as length of i-left palindrome.
Case 4:  L[currentRightPosition] > = centerRightPosition – currentRightPosition applies when:

i-left palindrome is NOT completely contained in center palindrome

Above condition is satisfied when
L[currentLeftPosition] > centerRightPosition – currentRightPosition
In this case, length of i-right palindrome is at least as long (centerRightPosition – currentRightPosition) and there is a possibility of i-right palindrome expansion.
In following figure, 
                          (click to see it clearly)
                    
If we take center position 7, then Case 3 applies at currentRightPosition 11 because i-left palindrome at currentLeftPosition 3 is a prefix of center palindrome and i-right palindrome is not suffix of input string, so here L[11] = 9, which is greater than i-left palindrome length L[3] = 3. In the case, it is guaranteed that L[11] will be at least 3, and so in implementation, we 1st set L[11] = 3 and then we try to expand it by comparing characters in left and right side starting from distance 4 (As up-to distance 3, it is already known that characters will match).
If we take center position 11, then Case 4 applies at currentRightPosition 15 because L[currentLeftPosition] = L[7] = 7 > centerRightPosition – currentRightPosition = 20 – 15 = 5. In the case, it is guaranteed that L[15] will be at least 5, and so in implementation, we 1st set L[15] = 5 and then we try to expand it by comparing characters in left and right side starting from distance 5 (As up-to distance 5, it is already known that characters will match).
Now one point left to discuss is, when we work at one center position and compute LPS lengths for different rightPositions, how to know that what would be next center position. We change centerPosition to currentRightPosition if palindrome centered at currentRightPosition expands beyond centerRightPosition.
Here we have seen four different cases on how LPS length of a position will depend on a previous position’s LPS length.
In Part 3, we have discussed code implementation of it and also we have looked at these four cases in a different way and implement that too.
This article is contributed by Anurag Singh. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 1Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 3Manacher's Algorithm - Linear Time Longest Palindromic Substring - Part 4Longest Palindromic Substring using Palindromic Tree | Set 3Longest Palindromic Substring | Set 1Longest Palindromic Substring | Set 2Longest Non-palindromic substringZ algorithm (Linear time pattern searching Algorithm)Suffix Tree Application 6 - Longest Palindromic SubstringFind the time which is palindromic and comes after the given timeMaximum length palindromic substring such that it starts and ends with given charLongest Palindromic Subsequence | DP-12Print Longest Palindromic SubsequenceLongest substring with count of 1s more than 0sLongest substring of vowels

Article Tags : Pattern SearchingStringspalindrome
Practice Tags : StringspalindromePattern Searching 

thumb_up
8



To-do

Done



4.5


Based on 65 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Manacher’s Algorithm – Linear Time Longest Palindromic Substring – Part 3


In Manacher’s Algorithm Part 1 and Part 2, we gone through some of the basics, understood LPS length array and how to calculate it efficiently based on four cases. Here we will implement the same.
We have seen that there are no new character comparison needed in case 1 and case 2. In case 3 and case 4, necessary new comparison are needed.
In following figure,

If at all we need a comparison, we will only compare actual characters, which are at “odd” positions like 1, 3, 5, 7, etc.
Even positions do not represent a character in string, so no comparison will be preformed for even positions.
If two characters at different odd positions match, then they will increase LPS length by 2.





There are many ways to implement this depending on how even and odd positions are handled. One way would be to create a new string 1st where we insert some unique character (say #, $ etc) in all even positions and then run algorithm on that (to avoid different way of even and odd position handling). Other way could be to work on given string itself but here even and odd positions should be handled appropriately.
Here we will start with given string itself. When there is a need of expansion and character comparison required, we will expand in left and right positions one by one. When odd position is found, comparison will be done and LPS Length will be incremented by ONE. When even position is found, no comparison done and LPS Length will be incremented by ONE (So overall, one odd and one even positions on both left and right side will increase LPS Length by TWO).

C/C++






filter_none

Manacher’s Algorithm – Linear Time Longest Palindromic Substring – Part 4


In Manacher’s Algorithm Part 1 and Part 2, we gone through some of the basics, understood LPS length array and how to calculate it efficiently based on four cases. In Part 3, we implemented the same.
Here we will review the four cases again and try to see it differently and implement the same.
All four cases depends on LPS length value at currentLeftPosition (L[iMirror]) and value of (centerRightPosition – currentRightPosition), i.e. (R – i). These two information are know before which helps us to reuse previous available information and avoid unnecessary character comparison.

If we look at all four cases, we will see that we 1st set minimum of L[iMirror] and R-i to L[i] and then we try to expand the palindrome in whichever case it can expand.
Above observation may look more intuitive, easier to understand and implement, given that one understands LPS length array, position, index, symmetry property etc.

C/C++












filter_none

Longest Even Length Substring such that Sum of First and Second Half is same


Given a string ‘str’ of digits, find the length of the longest substring of ‘str’, such that the length of the substring is 2k digits and sum of left k digits is equal to the sum of right k digits. 
Examples :
Input: str = "123123"
Output: 6
The complete string is of even length and sum of first and second
half digits is same

Input: str = "1538023"
Output: 4
The longest substring with same first and second half sum is "5380"


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Simple Solution [ O(n3) ]
A Simple Solution is to check every substring of even length.  The following is the implementation of simple approach.

C++












filter_none

Print all possible strings that can be made by placing spaces


Given a string you need to print all possible strings that can be made by placing spaces (zero or one) in between them. 
Input:  str[] = "ABC"
Output: ABC
        AB C
        A BC
        A B C
Source:  Amazon Interview Experience | Set 158, Round 1 ,Q 1.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Write a  program to print all permutations of a given string


A permutation, also called an “arrangement number” or “order,” is a rearrangement of the elements of an ordered list S into a one-to-one correspondence with S itself. A string of length n has n! permutation.
Source: Mathword(http://mathworld.wolfram.com/Permutation.html)
Below are the permutations of string ABC.
ABC ACB BAC BCA CBA CAB


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



The Knight’s tour problem | Backtracking-1


Backtracking is an algorithmic paradigm that tries different solutions until finds a solution that “works”. Problems which are typically solved using backtracking technique have following property in common.  These problems can only be solved by trying every possible configuration and each configuration is tried only once.  A Naive solution for these problems is to try all configurations and output a configuration that follows given problem constraints.  Backtracking works in incremental way and is an optimization over the Naive solution where all possible configurations are generated and tried.
For example, consider the following Knight’s Tour problem.
The knight is placed on the first block of an empty board and, moving according to the rules of chess, must visit each square exactly once. 
 Path followed by Knight to cover all the cells 





Following is chessboard with 8 x 8 cells. Numbers in cells indicate move number of Knight.

Let us first discuss the Naive algorithm for this problem and then the Backtracking algorithm.
Naive Algorithm for Knight’s tour
The Naive Algorithm is to generate all tours one by one and check if the generated tour satisfies the constraints. 
while there are untried tours
{ 
   generate the next tour 
   if this tour covers all squares 
   { 
      print this path;
   }
}

Backtracking works in an incremental way to attack problems.  Typically, we start from an empty solution vector and one by one add items  (Meaning of item varies from problem to problem. In context of Knight’s tour problem, an item is a Knight’s move). When we add an item, we check if adding the current item violates the problem constraint, if it does then we remove the item  and try other alternatives. If none of the alternatives work out then we go to previous stage and remove the item added in the previous stage. If we reach the initial stage back then we say that no solution exists. If adding an item doesn’t violate constraints then we recursively add items one by one. If the solution vector becomes complete then we print the solution.
Backtracking Algorithm for Knight’s tour
Following is the Backtracking algorithm for Knight’s tour problem. 
If all squares are visited 
    print the solution
Else
   a) Add one of the next moves to solution vector and recursively 
   check if this move leads to a solution. (A Knight can make maximum 
   eight moves. We choose one of the 8 moves in this step).
   b) If the move chosen in the above step doesn't lead to a solution
   then remove this move from the solution vector and try other 
   alternative moves.
   c) If none of the alternatives work then return false (Returning false 
   will remove the previously added item in recursion and if false is 
   returned by the initial call of recursion then "no solution exists" )

Following are implementations for Knight’s tour problem.  It prints one of the possible solutions in 2D matrix form.  Basically, the output is a 2D 8*8 matrix with numbers from 0 to 63 and these numbers show steps made by Knight.

C







filter_none

Rat in a Maze | Backtracking-2


We have discussed Backtracking and Knight’s tour problem in Set 1.  Let us discuss Rat in a Maze as another example problem that can be solved using Backtracking.
A Maze is given as N*N binary matrix of blocks where source block is the upper left most block i.e., maze[0][0] and destination block is lower rightmost block i.e., maze[N-1][N-1].  A rat starts from source and has to reach the destination. The rat can move only in two directions: forward and down.
In the maze matrix, 0 means the block is a dead end and 1 means the block can be used in the path from source to destination. Note that this is a simple version of the typical Maze problem. For example, a more complex version can be that the rat can move in 4 directions and a more complex version can be with a limited number of moves.
Following is an example maze.





 Gray blocks are dead ends (value = 0). 

Following is binary matrix representation of the above maze.
                {1, 0, 0, 0}
                {1, 1, 0, 1}
                {0, 1, 0, 0}
                {1, 1, 1, 1}

Following is a maze with highlighted solution path.

Following is the solution matrix (output of program) for the above input matrx.
                {1, 0, 0, 0}
                {1, 1, 0, 0}
                {0, 1, 0, 0}
                {0, 1, 1, 1}
 All enteries in solution path are marked as 1.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Naive Algorithm
The Naive Algorithm is to generate all paths from source to destination and one by one check if the generated path satisfies the constraints.
while there are untried paths
{
   generate the next path
   if this path has all blocks as 1
   {
      print this path;
   }
}
Backtracking Algorithm
If destination is reached
    print the solution matrix
Else
   a) Mark current cell in solution matrix as 1. 
   b) Move forward in the horizontal direction and recursively check if this 
       move leads to a solution. 
   c) If the move chosen in the above step doesn't lead to a solution
       then move down and check if this move leads to a solution. 
   d) If none of the above solutions works then unmark this cell as 0 
       (BACKTRACK) and return false.

Implementation of Backtracking solution

C/C++







filter_none

N Queen Problem | Backtracking-3


We have discussed Knight’s tour and Rat in a Maze problems in Set 1 and Set 2 respectively.  Let us discuss N Queen as another example problem that can be solved using Backtracking. 
The N Queen is the problem of placing N chess queens on an N×N chessboard so that no two queens attack each other.  For example, following is a solution for 4 Queen problem.






The expected output is a binary matrix which has 1s for the blocks where queens are placed.  For example, following is the output matrix for above 4 queen solution.
              { 0,  1,  0,  0}
              { 0,  0,  0,  1}
              { 1,  0,  0,  0}
              { 0,  0,  1,  0}


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Subset Sum | Backtracking-4


Subset sum problem is to find subset of elements that are selected from a given set whose sum adds up to a given number K. We are considering the set contains non-negative values. It is assumed that the input set is unique (no duplicates are presented).


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



m Coloring Problem | Backtracking-5


Given an undirected graph and a number m, determine if the graph can be colored with at most m colors such that no two adjacent vertices of the graph are colored with the same color. Here coloring of a graph means the assignment of colors to all vertices. 
Input:
1) A 2D array graph[V][V] where V is the number of vertices in graph and graph[V][V] is adjacency matrix representation of the graph. A value graph[i][j] is 1 if there is a direct edge from i to j, otherwise graph[i][j] is 0.
2) An integer m which is the maximum number of colors that can be used.
Output:
An array color[V] that should have numbers from 1 to m. color[i] should represent the color assigned to the ith vertex. The code should also return false if the graph cannot be colored with m colors.





Following is an example of graph that can be colored with 3 different colors.

We strongly recommend that you click here and practice it, before moving on to the solution.
Naive Algorithm
Generate all possible configurations of colors and print a configuration that satisfies the given constraints.
while there are untried configurations
{
   generate the next configuration
   if no adjacent vertices are colored with same color
   {
      print this configuration;
   }
}

There will be V^m configurations of colors.
Backtracking Algorithm
The idea is to assign colors one by one to different vertices, starting from the vertex 0. Before assigning a color, we check for safety by considering already assigned colors to the adjacent vertices. If we find a color assignment which is safe, we mark the color assignment as part of solution. If we do not a find color due to clashes then we backtrack and return false.
Implementation of Backtracking solution

C/C++







filter_none

Hamiltonian Cycle | Backtracking-6


Hamiltonian Path in an undirected graph is a path that visits each vertex exactly once. A Hamiltonian cycle (or Hamiltonian circuit) is a Hamiltonian Path such that there is an edge (in the graph) from the last vertex to the first vertex of the Hamiltonian Path. Determine whether a given graph contains Hamiltonian Cycle or not. If it contains, then prints the path.  Following are the input and output of the required function.
Input:
A 2D array graph[V][V] where V is the number of vertices in graph and graph[V][V] is adjacency matrix representation of the graph. A value graph[i][j] is 1 if there is a direct edge from i to j, otherwise graph[i][j] is 0.
Output:
An array path[V] that should contain the Hamiltonian Path. path[i] should represent the ith vertex in the Hamiltonian Path. The code should also return false if there is no Hamiltonian Cycle in the graph.





For example, a Hamiltonian Cycle in the following graph is {0, 1, 2, 4, 3, 0}.
(0)--(1)--(2)
 |   / \   |
 |  /   \  | 
 | /     \ |
(3)-------(4)

And the following graph doesn’t contain any Hamiltonian Cycle.
(0)--(1)--(2)
 |   / \   |
 |  /   \  | 
 | /     \ |
(3)      (4) 


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Naive Algorithm
Generate all possible configurations of vertices and print a configuration that satisfies the given constraints. There will be n! (n factorial) configurations.
while there are untried conflagrations
{
   generate the next configuration
   if ( there are edges between two consecutive vertices of this
      configuration and there is an edge from the last vertex to 
      the first ).
   {
      print this configuration;
      break;
   }
}

Backtracking Algorithm
Create an empty path array and add vertex 0 to it. Add other vertices, starting from the vertex 1. Before adding a vertex, check for whether it is adjacent to the previously added vertex and not already added. If we find such a vertex, we add the vertex as part of the solution. If we do not find a vertex then we return false.
Implementation of Backtracking solution
Following are implementations of the Backtracking solution.

C++







filter_none

Sudoku | Backtracking-7



Given a partially filled 9×9 2D array ‘grid[9][9]’, the goal is to assign digits (from 1 to 9) to the empty cells so that every row, column, and subgrid of size 3×3 contains exactly one instance of the digits from 1 to 9.  



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Tug of War


Given a set of n integers, divide the set in two subsets of n/2 sizes each such that the difference of the sum of two subsets is as minimum as possible.  If n is even, then sizes of two subsets must be strictly n/2 and if n is odd, then size of one subset must be (n-1)/2 and size of other subset must be (n+1)/2.
For example, let given set be {3, 4, 5, -3, 100, 1, 89, 54, 23, 20}, the size of set is 10. Output for this set should be {4, 100, 1, 23, 20} and {3, 5, -3, 89, 54}.  Both output subsets are of size 5 and sum of elements in both subsets is same (148 and 148).
Let us consider another example where n is odd.  Let given set be {23, 45, -34, 12, 0, 98, -99, 4, 189, -1, 4}. The output subsets should be {45, -34, 12, 98, -1} and {23, 0, -99, 4, 189, 4}. The sums of elements in two subsets are 120 and 121 respectively.
The following solution tries every possible subset of half size.  If one subset of half size is formed, the remaining elements form the other subset. We initialize current set as empty and one by one build it. There are two possibilities for every element, either it is part of current set, or it is part of the remaining elements (other subset).  We consider both possibilities for every element.  When the size of current set becomes n/2, we check whether this solutions is better than the best solution available so far.  If it is, then we update the best solution.





Following is the implementation for Tug of War problem. It prints the required arrays.

C++







filter_none

Solving Cryptarithmetic Puzzles | Backtracking-8


Newspapers and magazines often have crypt-arithmetic puzzles of the form: 
  SEND
+ MORE
--------
 MONEY
-------- 
 
The goal here is to assign each letter a digit from 0 to 9 so that the arithmetic works out correctly. The rules are that all occurrences of a letter must be assigned the same digit, and no digit can be assigned to more than one letter.

First, create a list of all the characters that need assigning to pass to Solve 
If all characters are assigned, return true if puzzle is solved, false otherwise
Otherwise, consider the first unassigned character 
for (every possible choice among the digits not in use) 
        make that choice and then recursively try to assign the rest of the characters
        if recursion successful, return true
    if !successful, unmake assignment and try another digit 

Divide and Conquer Algorithm | Introduction



Like Greedy and Dynamic Programming, Divide and Conquer is an algorithmic paradigm. A typical Divide and Conquer algorithm solves a problem using following three steps. 
1. Divide: Break the given problem into subproblems of same type.
2. Conquer: Recursively solve these subproblems
3. Combine: Appropriately combine the answers
Following are some standard algorithms that are Divide and Conquer algorithms.
1) Binary Search is a searching algorithm. In each step, the algorithm compares the input element x with the value of the middle element in array. If the values match, return the index of middle. Otherwise, if x is less than the middle element, then the algorithm recurs for left side of middle element, else recurs for right side of middle element.
2) Quicksort is a sorting algorithm. The algorithm picks a pivot element, rearranges the array elements in such a way that all elements smaller than the picked pivot element move to left side of pivot, and all greater elements move to right side. Finally, the algorithm recursively sorts the subarrays on left and right of pivot element.
3) Merge Sort is also a sorting algorithm. The algorithm divides the array in two halves, recursively sorts them and finally merges the two sorted halves.
4) Closest Pair of Points The problem is to find the closest pair of points in a set of points in x-y plane. The problem can be solved in O(n^2) time by calculating distances of every pair of points and comparing the distances to find the minimum. The Divide and Conquer algorithm solves the problem in O(nLogn) time.
5) Strassen’s Algorithm is an efficient algorithm to multiply two matrices. A simple method to multiply two matrices need 3 nested loops and is O(n^3). Strassen’s algorithm multiplies two matrices in O(n^2.8974) time.
6)  Cooley–Tukey Fast Fourier Transform (FFT) algorithm is the most common algorithm for FFT. It is a divide and conquer algorithm which works in O(nlogn) time.
7) Karatsuba algorithm for fast multiplication  it does multiplication of two n-digit numbers in at most single-digit multiplications in general (and exactly  when n is a power of 2). It is therefore faster than the classical algorithm, which requires n2 single-digit products. If n = 210 = 1024, in particular, the exact counts are 310 = 59,049 and (210)2 = 1,048,576, respectively.
We will publishing above algorithms in separate posts.
Divide and Conquer (D & C) vs Dynamic Programming (DP)
Both paradigms (D & C and DP) divide the given problem into subproblems and solve subproblems. How to choose one of them for a given problem? Divide and Conquer should be used when same subproblems are not evaluated many times. Otherwise Dynamic Programming or Memoization should be used. For example, Binary Search is a Divide and Conquer algorithm, we never evaluate the same subproblems again. On the other hand, for calculating nth Fibonacci number, Dynamic Programming should be preferred (See this for details).
References
Algorithms by Sanjoy Dasgupta, Christos Papadimitriou, Umesh Vazirani
Introduction to Algorithms by Clifford Stein, Thomas H. Cormen, Charles E. Leiserson, Ronald L. 
http://en.wikipedia.org/wiki/Karatsuba_algorithm
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Karatsuba algorithm for fast multiplication using Divide and Conquer algorithmClosest Pair of Points using Divide and Conquer algorithmMaximum Subarray Sum using Divide and Conquer algorithmDivide and Conquer | Set 5 (Strassen's Matrix Multiplication)Search in a Row-wise and Column-wise Sorted 2D Array using Divide and Conquer algorithmTiling Problem using Divide and Conquer algorithmThe Skyline Problem using Divide and Conquer algorithmLongest Common Prefix using Divide and Conquer AlgorithmQuickhull Algorithm for Convex HullConvex Hull using Divide and Conquer AlgorithmRandomized Binary Search AlgorithmAdvanced master theorem for divide and conquer recurrencesDecrease and ConquerDistinct elements in subarray using Mo's AlgorithmDynamic Programming vs Divide-and-Conquer

Article Tags : Divide and Conquer
Practice Tags : Divide and Conquer 

thumb_up
30



To-do

Done



2.1


Based on 77 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Write a program to calculate pow(x,n)



Given two integers x and n, write a function to compute xn.  We may assume that x and n are small and overflow doesn’t happen.

Examples :
Input : x = 2, n = 3
Output : 8

Input : x = 7, n = 2
Output : 49



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Median of two sorted arrays of same size



There are 2 sorted arrays A and B of size n each. Write an algorithm to find the median of the array obtained after merging the above 2 arrays(i.e. array of length 2n). The complexity should be O(log(n)).  



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count Inversions in an array | Set 1 (Using Merge Sort)



Inversion Count for an array indicates – how far (or close) the array is from being sorted. If array is already sorted then inversion count is 0. If array is sorted in reverse order that inversion count is the maximum. 
Formally speaking, two elements a[i] and a[j] form an inversion if a[i] > a[j] and i < j 
 Example:
The sequence 2, 4, 1, 3, 5 has three inversions (2, 1), (4, 1), (4, 3).

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

 
METHOD 1 (Simple)
For each element, count number of elements which are on right side of it and are smaller than it.

C++












filter_none

Closest Pair of Points using Divide and Conquer algorithm


We are given an array of n points in the plane, and the problem is to find out the closest pair of points in the array.  This problem arises in a number of applications. For example, in air-traffic control, you may want to monitor planes that come too close together, since this may indicate a possible collision. Recall the following formula for distance between two points p and q.

The Brute force solution is O(n^2), compute the distance between each pair and return the smallest. We can calculate the smallest distance in O(nLogn) time using Divide and Conquer strategy.  In this post, a O(n x (Logn)^2) approach is discussed.  We will be discussing a O(nLogn) approach in a separate post.





Algorithm
Following are the detailed steps of a O(n (Logn)^2) algortihm.
Input: An array of n points P[]
Output: The smallest distance between two points in the given array.
As a pre-processing step, the input array is sorted according to x coordinates.
1) Find the middle point in the sorted array, we can take P[n/2] as middle point. 
2) Divide the given array in two halves. The first subarray contains points from P[0] to P[n/2]. The second subarray contains points from P[n/2+1] to P[n-1].
3) Recursively find the smallest distances in both subarrays. Let the distances be dl and dr.  Find the minimum of dl and dr. Let the minimum be d.


Divide and Conquer | Set 5 (Strassen’s Matrix Multiplication)



Given two square matrices A and B of size n x n each, find their multiplication matrix.   
Naive Method
Following is a simple way to multiply two matrices. 





filter_none

Quick Sort vs Merge Sort



Prerequisite :Merge Sort and Quick Sort

Quick sort is an internal algorithm which is based on divide and conquer strategy. In this:

The array of elements is divided into parts repeatedly until it is not possible to divide it further.
It is also known as “partition exchange sort”.
It uses a key element (pivot) for partitioning the elements.
One left partition contains all those elements that are smaller than the pivot and one right partition contains all those elements which  are greater than the key element.


Merge sort is an external algorithm and based on divide and conquer strategy. In this:






The elements are split into two sub-arrays (n/2) again and again until only one element is left.
Merge sort uses additional storage for sorting the auxiliary array.
Merge sort uses three arrays where two are used for storing each half, and the third external one is used to store the final sorted list by merging other two and each array is then sorted recursively.
At last, the all sub arrays are merged to make it ‘n’ element size of the array.


Quick Sort vs Merge Sort

Partition of elements in the array :
In the merge sort, the array is parted into just 2 halves (i.e. n/2).
whereas
In case of quick sort, the array is parted into any ratio. There is no compulsion of dividing the array of elements into equal parts in quick sort.
Worst case complexity :
The worst case complexity of quick sort is O(n2) as there is need of lot of comparisons in the worst condition.
whereas
In merge sort, worst case and average case has same complexities O(n log n).
Usage with datasets :
Merge sort can work well on any type of data sets irrespective of its size (either large or small).
whereas
The quick sort cannot work well with large datasets.
Additional storage space requirement :
Merge sort is not in place because it requires additional memory space to store the auxiliary arrays.
whereas
The quick sort is in place as it doesn’t require any additional storage.
Efficiency :
Merge sort is more efficient and works faster than quick sort in case of larger array size or datasets.
whereas
Quick sort is more efficient and works faster than merge sort in case of smaller array size or datasets.
Sorting method :
The quick sort is internal sorting method where the data is sorted in main memory.
whereas
The merge sort is external sorting method in which the data that is to be sorted cannot be accommodated in the memory and needed auxiliary memory for sorting.
Stability :
Merge sort is stable as two elements with equal value appear in the same order in sorted output as they were in the input unsorted array.
whereas
Quick sort is unstable in this scenario. But it can be made stable using some changes in code.
Preferred for :
Quick sort is preferred for arrays.
whereas
Merge sort is preferred for linked lists.
Locality of reference :
Quicksort exhibits good cache locality and this makes quicksort faster than merge sort (in many cases like in virtual memory environment).




Basis for comparison
Quick Sort
Merge Sort





The partition of elements in the array

The splitting of a array of elements is in any ratio, not necessarily divided into half. 
The splitting of a array of elements is in any ratio, not necessarily divided into half. 



Worst case complexity 

O(n2) 
O(nlogn) 



Works well on

It works well on smaller array 
It operates fine on any size of array 



Speed of execution

It work faster than other sorting algorithms for small data set like Selection sort etc 
It has a consistent speed on any size of data 



Additional storage space requirement

Less(In-place)
More(not In-place) 



Efficiency 

Inefficient for larger arrays
More efficient 



Sorting method 

Internal 
External 



Stability

Not Stable     
Stable 



 Preferred for

for Arrays  
 for Linked Lists



Locality of reference

 good
 poor










My Personal Notes
arrow_drop_up





Save


Recommended Posts:Why Quick Sort preferred for Arrays and Merge Sort for Linked Lists?p5.js | Quick SortIterative Quick SortC Program for Iterative Quick SortJava Program for Iterative Quick SortMerge Sort with O(1) extra space merge and O(n lg n) timeComparison among Bubble Sort, Selection Sort and Insertion Sort3-way Merge SortMerge SortIterative Merge SortIn-Place Merge SortC Program for Merge SortMerge Sort for Linked ListsPython Program for Merge SortJava Program for Merge SortAnkit_BishtCheck out this Author's contributed articles.If you like GeeksforGeeks and would like to contribute, you can also write an article using contribute.geeksforgeeks.org or mail your article to contribute@geeksforgeeks.org. See your article appearing on the GeeksforGeeks main page and help other Geeks.Please Improve this article if you find anything incorrect by clicking on  the "Improve Article" button below.Improved By :  VIJESH1996

Article Tags : AlgorithmsDivide and ConquerJava ProgramsSortingLinked-List-SortingMerge SortQuick Sort
Practice Tags : Divide and ConquerSortingMerge SortAlgorithms 

thumb_up
13



To-do

Done



1.7


Based on 4 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Closest Pair of Points |  O(nlogn) Implementation


We are given an array of n points in the plane, and the problem is to find out the closest pair of points in the array.  This problem arises in a number of applications. For example, in air-traffic control, you may want to monitor planes that come too close together, since this may indicate a possible collision. Recall the following formula for distance between two points p and q.

We have discussed a divide and conquer solution for this problem.  The time complexity of the implementation provided in the previous post is O(n (Logn)^2).  In this post, we discuss implementation with time complexity as O(nLogn).  
Following is a recap of the algorithm discussed in the previous post.
1) We sort all points according to x coordinates.





2) Divide all points in two halves.
3) Recursively find the smallest distances in both subarrays.
4) Take the minimum of two smallest distances.  Let the minimum be d. 
5) Create an array strip[] that stores all points which are at most d distance away from the middle line dividing the two sets.
6) Find the smallest distance in strip[]. 
7) Return the minimum of d and the smallest distance calculated in above step 6.
The great thing about the above approach is, if the array strip[] is sorted according to y coordinate, then we can find the smallest distance in strip[] in O(n) time.  In the implementation discussed in the previous post, strip[] was explicitly sorted in every recursive call that made the time complexity O(n (Logn)^2), assuming that the sorting step takes O(nLogn) time.
In this post, we discuss an implementation where the time complexity is O(nLogn). The idea is to presort all points according to y coordinates. Let the sorted array be Py[].  When we make recursive calls, we need to divide points of Py[] also according to the vertical line.  We can do that by simply processing every point and comparing its x coordinate with x coordinate of the middle line.
Following is C++ implementation of O(nLogn) approach.





filter_none

How to check if two given line segments intersect?


Given two line segments (p1, q1) and (p2, q2), find if the given line segments intersect with each other.
Before we discuss solution, let us define notion of orientation. Orientation of an ordered triplet of points in the plane can be
–counterclockwise
–clockwise
–colinear
The following diagram shows different possible orientations of (a, b, c)







Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

How is Orientation useful here?
Two segments (p1,q1) and (p2,q2) intersect if and only if one of the following two conditions is verified
1. General Case:
– (p1, q1, p2) and (p1, q1, q2) have different orientations and
– (p2, q2, p1) and (p2, q2, q1) have different orientations.
Examples:



How to check if a given point lies inside or outside a polygon?


Given a polygon and a point ‘p’, find if ‘p’ lies inside the polygon or not. The points lying on the border are considered inside.

We strongly recommend to see the following post first.
How to check if two given line segments intersect?





Following is a simple idea to check whether a point is inside or outside.
1) Draw a horizontal line to the right of each point and extend it to infinity

1) Count the number of times the line intersects with polygon edges.

2) A point is inside the polygon if either count of intersections is odd or
   point lies on an edge of polygon.  If none of the conditions is true, then 
   point lies outside.

How to handle point ‘g’ in the above figure?
Note that we should return true if the point lies on the line or same as one of the vertices of the given polygon.  To handle this, after checking if the line from ‘p’ to extreme intersects, we check whether ‘p’ is colinear with vertices of current line of polygon.  If it is coliear, then we check if the point ‘p’ lies on current side of polygon, if it lies, we return true, else false.
Following is the implementation of the above idea.

C++







filter_none

Convex Hull | Set 1 (Jarvis’s Algorithm or Wrapping)


Given a set of points in the plane. the convex hull of the set is the smallest convex polygon that contains all the points of it.

We strongly recommend to see the following post first.
How to check if two given line segments intersect?





The idea of Jarvis’s Algorithm is simple, we start from the leftmost point (or point with minimum x coordinate value) and we keep wrapping points in counterclockwise direction. The big question is, given a point p as current point, how to find the next point in output? The idea is to use orientation() here. Next point is selected as the point that beats all other points at counterclockwise orientation, i.e., next point is q if for any other point r, we have “orientation(p, q, r) = counterclockwise”. Following is the detailed algorithm.
1) Initialize p as leftmost point.
2) Do following while we don’t come back to the first (or leftmost) point.
…..a) The next point q is the point such that the triplet (p, q, r) is counterclockwise for any other point r.
…..b) next[p] = q (Store q as next of p in the output convex hull).
…..c) p = q (Set p as q for next iteration).


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Below is the implementation of above algorithm.

C++







filter_none

Convex Hull | Set 2 (Graham Scan)


Given a set of points in the plane. the convex hull of the set is the smallest convex polygon that contains all the points of it.

We strongly recommend to see the following post first.
How to check if two given line segments intersect?





We have discussed Jarvis’s Algorithm for Convex Hull. The worst case time complexity of Jarvis’s Algorithm is O(n^2).  Using Graham’s scan algorithm, we can find Convex Hull in O(nLogn) time.  Following is Graham’s algorithm 
Let points[0..n-1] be the input array.
1) Find the bottom-most point by comparing y coordinate of all points.  If there are two points with the same y value, then the point with smaller x coordinate value is considered. Let the bottom-most point be P0. Put P0 at first position in output hull.
2) Consider the remaining n-1 points and sort them by polar angle in counterclockwise order around points[0]. If the polar angle of two points is the same, then put the nearest point first.  
3 After sorting, check if two or more points have the same angle.  If two more points have the same angle, then remove all same angle points except the point farthest from P0.  Let the size of the new array be m.
4) If m is less than 3, return (Convex Hull not possible)
5) Create an empty stack ‘S’ and push points[0], points[1] and points[2] to S.
6) Process remaining m-3 points one by one. Do following for every point ‘points[i]’
        4.1) Keep removing points from stack while orientation of following 3 points is not counterclockwise (or they don’t make a left turn).
            a) Point next to top in stack
            b) Point at the top of stack
            c) points[i]
         4.2) Push points[i] to S
5) Print contents of S
The above algorithm can be divided into two phases.




Phase 1 (Sort points): We first find the bottom-most point. The idea is to pre-process points be sorting them with respect to the bottom-most point.  Once the points are sorted, they form a simple closed path (See the following diagram).

What should be the sorting criteria? computation of actual angles would be inefficient since trigonometric functions are not simple to evaluate.  The idea is to use the orientation to compare angles without actually computing them (See the compare() function below)
Phase 2 (Accept or Reject Points): Once we have the closed path, the next step is to traverse the path and remove concave points on this path. How to decide which point to remove and which to keep? Again, orientation helps here. The first two points in sorted array are always part of Convex Hull.  For remaining points, we keep track of recent three points, and find the angle formed by them.  Let the three points be prev(p), curr(c) and next(n).  If orientation of these points (considering them in same order) is not counterclockwise, we discard c, otherwise we keep it.  Following diagram shows step by step process of this phase


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Following is C++ implementation of the above algorithm.





filter_none

Given n line segments, find if any two segments intersect


We have discussed the problem to detect if two given line segments intersect or not. In this post, we extend the problem.  Here we are given n line segments and we need to find out if any two line segments intersect or not.
Naive Algorithm A naive solution to solve this problem is to check every pair of lines and check if the pair intersects or not. We can check two line segments in O(1) time. Therefore, this approach takes O(n2).
Sweep Line Algorithm: We can solve this problem in O(nLogn) time using Sweep Line Algorithm. The algorithm first sorts the end points along the x axis from left to right, then it passes a vertical line through all points from left to right and checks for intersections. Following are detailed steps.





1) Let there be n given lines. There must be 2n end points to represent the n lines. Sort all points according to x coordinates. While sorting maintain a flag to indicate whether this point is left point of its line or right point.
2) Start from the leftmost point. Do following for every point
…..a) If the current point is a left point of its line segment, check for intersection of its line segment with the segments just above and below it. And add its line to active line segments (line segments for which left end point is seen, but right end point is not seen yet).  Note that we consider only those neighbors which are still active.
….b) If the current point is a right point, remove its line segment from active list and check whether its two active neighbors (points just above and below) intersect with each other.
The step 2 is like passing a vertical line from all points starting from the leftmost point to the rightmost point. That is why this algorithm is called Sweep Line Algorithm. The Sweep Line technique is useful in many other geometric algorithms like calculating the 2D Voronoi diagram
What data structures should be used for efficient implementation?
In step 2, we need to store all active line segments. We need to do following operations efficiently:
a) Insert a new line segment
b) Delete a line segment
c) Find predecessor and successor according to y coordinate values
The obvious choice for above operations is Self-Balancing Binary Search Tree like AVL Tree, Red Black Tree. With a Self-Balancing BST, we can do all of the above operations in O(Logn) time.
Also, in step 1, instead of sorting, we can use min heap data structure. Building a min heap takes O(n) time and every extract min operation takes O(Logn) time (See this).
PseudoCode:
The following pseudocode doesn’t use heap. It simply sort the array.
sweepLineIntersection(Points[0..2n-1]):
1. Sort Points[] from left to right (according to x coordinate)

2. Create an empty Self-Balancing BST T. It will contain all active line 
   Segments ordered by y coordinate.

// Process all 2n points 
3. for i = 0 to 2n-1

    // If this point is left end of its line  
    if (Points[i].isLeft) 
       T.insert(Points[i].line())  // Insert into the tree

       // Check if this points intersects with its predecessor and successor
       if ( doIntersect(Points[i].line(), T.pred(Points[i].line()) )
         return true
       if ( doIntersect(Points[i].line(), T.succ(Points[i].line()) )
         return true

    else  // If it's a right end of its line
       // Check if its predecessor and successor intersect with each other
       if ( doIntersect(T.pred(Points[i].line(), T.succ(Points[i].line()))
         return true
       T.delete(Points[i].line())  // Delete from tree

4. return False
Example:
Let us consider the following example taken from here.  There are 5 line segments 1, 2, 3, 4 and 5.  The dotted green lines show sweep lines.


Check whether a given point lies inside a triangle or not


Given three corner points of a triangle, and one more point P. Write a function to check whether P lies within the triangle or not.
For example, consider the following program, the function should return true for P(10, 15) and false for P'(30, 15)
              B(10,30)
                / \
               /   \
              /     \
             /   P   \      P'
            /         \
     A(0,0) ----------- C(20,0) 

Solution:
Let the coordinates of three corners be (x1, y1), (x2, y2) and (x3, y3). And coordinates of the given point P be (x, y)





1) Calculate area of the given triangle, i.e., area of the triangle ABC in the above diagram. Area A = [ x1(y2 – y3) + x2(y3 – y1) + x3(y1-y2)]/2
2) Calculate area of the triangle PAB. We can use the same formula for this. Let this area be A1.
3) Calculate area of the triangle PBC. Let this area be A2.
4) Calculate area of the triangle PAC. Let this area be A3.
5) If P lies inside the triangle, then A1 + A2 + A3 must be equal to A.

C++







filter_none

How to check if given four points form a square


Given coordinates of four points in a plane, find if the four points form a square or not.
To check for square, we need to check for following.
a) All fours sides formed by points are the same.
b) The angle between any two sides is 90 degree. (This condition is required as Quadrilateral also has same sides.
c) Check both the diagonals have the same distance



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Write an Efficient Method to Check if a Number is Multiple of 3


The very first solution that comes to our mind is the one that we learned in school.  If sum of digits in a number is multiple of 3 then number is multiple of 3 e.g., for 612 sum of digits is 9 so it’s a multiple of 3. But this solution is not efficient.  You have to get all decimal digits one by one, add them and then check if sum is multiple of 3.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

There is a pattern in binary representation of the number that can be used to find if number is a multiple of 3. If difference between count of odd set bits (Bits set at odd positions) and even set bits is multiple of 3 then is the number.
Example : 23 (00..10111)
1) Get count of all set bits at odd positions (For 23 it’s 3).
2) Get count of all set bits at even positions (For 23 it’s 1).
3) If difference of above two counts is a multiple of 3 then number is also a multiple of 3. 





(For 23 it’s 2 so 23 is not a multiple of 3)
Take some more examples like 21, 15, etc…
Algorithm: isMutlipleOf3(n)
1) Make n positive if n is negative.
2) If number is 0 then return 1
3) If number is 1 then return 0
4) Initialize: odd_count = 0, even_count = 0
5) Loop while n != 0
    a) If rightmost bit is set then increment odd count.
    b) Right-shift n by 1 bit
    c) If rightmost bit is set then increment even count.
    d) Right-shift n by 1 bit
6) return isMutlipleOf3(odd_count - even_count)

Proof:
Above can be proved by taking the example of 11 in decimal numbers. (In this context 11 in decimal numbers is same as 3 in binary numbers)
If difference between sum of odd digits and even digits is multiple of 11 then decimal number is multiple of 11. Let’s see how.
Let’s take the example of 2 digit numbers in decimal
AB = 11A -A + B = 11A + (B – A)
So if (B – A) is a multiple of 11 then is AB.
Let us take 3 digit numbers.
ABC = 99A + A + 11B – B + C = (99A + 11B) + (A + C – B)
So if (A + C – B) is a multiple of 11 then is (ABC)
Let us take 4 digit numbers now.
ABCD = 1001A + D + 11C – C + 999B + B – A
= (1001A – 999B + 11C) + (D + B – A -C )
So, if (B + D – A – C) is a multiple of 11 then is ABCD.
This can be continued for all decimal numbers.
Above concept can be proved for 3 in binary numbers in the same way.

Time Complexity:  O(logn)
Program:

C++







filter_none

Efficient way to multiply with 7


We can multiply a number by 7 using bitwise operator.  First left shift the number by 3 bits (you will get 8n) then subtract the original numberfrom the shifted number and return the difference (8n – n).


Program:

CPP






filter_none

Write a  program to print all permutations of a given string


A permutation, also called an “arrangement number” or “order,” is a rearrangement of the elements of an ordered list S into a one-to-one correspondence with S itself. A string of length n has n! permutation.
Source: Mathword(http://mathworld.wolfram.com/Permutation.html)
Below are the permutations of string ABC.
ABC ACB BAC BCA CBA CAB


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Lucky Numbers


Lucky numbers are subset of integers.  Rather than going into much theory, let us see the process of arriving at lucky numbers,

Take the set of integers
     1,2,3,4,5,6,7,8,9,10,11,12,14,15,16,17,18,19,……
First, delete every second number, we get following reduced set.
     1,3,5,7,9,11,13,15,17,19,…………
Now, delete every third number, we get
     1, 3, 7, 9, 13, 15, 19,….….





Continue this process indefinitely……
Any number that does NOT get deleted due to above process is called “lucky”.
Therefore, set of lucky numbers is 1, 3, 7, 13,………
Now, given an integer ‘n’, write a function to say whether this number is lucky or not. 
    bool isLucky(int n)



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Write a program to add two numbers in base 14


Asked by Anshya.
Below are the different ways to add base 14 numbers.

Method 1
Thanks to Raj for suggesting this method.





  1. Convert both i/p base 14 numbers to base 10.
  2. Add numbers.
  3. Convert the result back to base 14.

Method 2
Just add the numbers in base 14 in same way we add in base 10.  Add numerals of both numbers one by one from right to left.  If there is a carry while adding two numerals, consider the carry for adding next numerals.
Let us consider the presentation of base 14 numbers same as hexadecimal numbers
   A --> 10
   B --> 11
   C --> 12
   D --> 13

Example:
   num1 =       1  2  A
   num2 =       C  D  3   

   1. Add A and 3, we get 13(D). Since 13 is smaller than 
14, carry becomes 0 and resultant numeral becomes D         

  2. Add 2, D and carry(0). we get 15. Since 15 is greater 
than 13, carry becomes 1 and resultant numeral is 15 - 14 = 1

  3. Add 1, C and carry(1). we get 14. Since 14 is greater 
than 13, carry becomes 1 and resultant numeral is 14 - 14 = 0

Finally, there is a carry, so 1 is added as leftmost numeral and the result becomes 
101D 

Implementation of Method 2

C++







filter_none

Babylonian method for square root


Algorithm:
This method can be derived from (but predates) Newton–Raphson method. 

1 Start with an arbitrary positive start value x (the closer to the 
   root, the better).
2 Initialize y = 1.
3. Do following until desired approximation is achieved.
  a) Get the next approximation for root using average of x and y
  b) Set y = n/x

Implementation:

C++







filter_none

Multiply two integers without using multiplication, division and bitwise operators, and no loops


By making use of recursion, we can multiply two integers with the given constraints. 
To multiply x and y,  recursively add x y times.

C++







filter_none

Print all combinations of points that can compose a given number


You can win three kinds of basketball points, 1 point, 2 points, and 3 points. Given a total score n, print out all the combination to compose n. 
Examples:
For n = 1, the program should print following:
1

For n = 2, the program should print following:
1 1
2

For n = 3, the program should print following:
1 1 1
1 2
2 1 
3

For n = 4, the program should print following:
1 1 1 1
1 1 2
1 2 1
1 3
2 1 1
2 2
3 1

and so on ...
Algorithm:






At first position we can have three numbers 1 or 2 or 3.  
First put 1 at first position and recursively call for n-1.
Then put 2 at first position and recursively call for n-2.
Then put 3 at first position and recursively call for n-3.
If n becomes 0 then we have formed a combination that compose n, so print the current combination.

Below is a generalized implementation. In the below implementation, we can change MAX_POINT if there are higher points (more than 3) in the basketball game.

C++







filter_none

Write you own Power without using multiplication(*) and division(/) operators


Method 1 (Using Nested Loops)
We can calculate power by using repeated addition.  
For example to calculate 5^6.
1) First 5 times add 5, we get 25. (5^2)
2) Then 5 times add 25, we get 125. (5^3)
3) Then 5 time add 125, we get 625 (5^4)
4) Then 5 times add 625, we get 3125 (5^5)
5) Then 5 times add 3125, we get 15625 (5^6)

C++












filter_none

Program for Fibonacci numbers


The Fibonacci numbers are the numbers in the following integer sequence.
0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, ……..
In mathematical terms, the sequence Fn of Fibonacci numbers is defined by the recurrence relation





    Fn = Fn-1 + Fn-2
with seed values
   F0 = 0 and F1 = 1.

Given a number n, print n-th Fibonacci Number.
Examples:
Input  : n = 2
Output : 1

Input  : n = 9
Output : 34



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Average of a stream of numbers


Difficulty Level:  Rookie
Given a stream of numbers, print average (or mean) of the stream at every point.  For example, let us consider the stream as 10, 20, 30, 40, 50, 60, …
  Average of 1 numbers is 10.00
  Average of 2 numbers is 15.00
  Average of 3 numbers is 20.00
  Average of 4 numbers is 25.00
  Average of 5 numbers is 30.00
  Average of 6 numbers is 35.00
  ..................



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count numbers that don’t contain 3


Given a number n, write a function that returns count of numbers from 1 to n that don’t contain digit 3 in their decimal representation.  
Examples:
Input: n = 10
Output: 9 

Input: n = 45
Output: 31 
// Numbers 3, 13, 23, 30, 31, 32, 33, 34, 
// 35, 36, 37, 38, 39, 43 contain digit 3. 

Input: n = 578
Output: 385







We strongly recommend that you click here and practice it, before moving on to the solution.


Magic Square


A magic square of order n is an arrangement of n^2 numbers, usually distinct integers, in a square, such that the n numbers in all rows, all columns, and both diagonals sum to the same constant. A magic square contains the integers from 1 to n^2. 
The constant sum in every row, column and diagonal is called the magic constant or magic sum, M. The magic constant of a normal magic square depends only on n and has the following value:
M =  n(n^2+1)/2
For normal magic squares of order n = 3, 4, 5, ...,
 the magic constants are: 15, 34, 65, 111, 175, 260, ... 
In this post, we will discuss how programmatically we can generate a magic square of size n.  Before we go further, consider the below examples:





Magic Square of size 3
-----------------------
  2   7   6
  9   5   1
  4   3   8
Sum in each row & each column = 3*(3^2+1)/2 = 15


Magic Square of size 5
----------------------
  9   3  22  16  15
  2  21  20  14   8
 25  19  13   7   1
 18  12   6   5  24
 11  10   4  23  17
Sum in each row & each column = 5*(5^2+1)/2 = 65


Magic Square of size 7
----------------------
 20  12   4  45  37  29  28
 11   3  44  36  35  27  19
  2  43  42  34  26  18  10
 49  41  33  25  17   9   1
 40  32  24  16   8   7  48
 31  23  15  14   6  47  39
 22  21  13   5  46  38  30
Sum in each row & each column = 7*(7^2+1)/2 = 175

Did you find any pattern in which the numbers are stored?
In any magic square, the first number i.e. 1 is stored at position (n/2, n-1). Let this position be (i,j). The next number is stored at position (i-1, j+1) where we can consider each row & column as circular array i.e. they wrap around.
Three conditions hold:
1. The position of next number is calculated by decrementing row number of previous number by 1, and incrementing the column number of previous number by 1. At any time, if the calculated row position becomes -1, it will wrap around to n-1. Similarly, if the calculated column position becomes n, it will wrap around to 0.
2. If the magic square already contains a number at the calculated position, calculated column position will be decremented by 2, and calculated row position will be incremented by 1.
3. If the calculated row position is -1 & calculated column position is n, the new position would be: (0, n-2). 
Example:
Magic Square of size 3
----------------------
 2  7  6
 9  5  1
 4  3  8 

Steps:
1. position of number 1 = (3/2, 3-1) = (1, 2)
2. position of number 2 = (1-1, 2+1) = (0, 0)
3. position of number 3 = (0-1, 0+1) = (3-1, 1) = (2, 1)
4. position of number 4 = (2-1, 1+1) = (1, 2)
   Since, at this position, 1 is there. So, apply condition 2.
   new position=(1+1,2-2)=(2,0)
5. position of number 5=(2-1,0+1)=(1,1)
6. position of number 6=(1-1,1+1)=(0,2)
7. position of number 7 = (0-1, 2+1) = (-1,3) // this is tricky, see condition 3 
   new position = (0, 3-2) = (0,1)
8. position of number 8=(0-1,1+1)=(-1,2)=(2,2) //wrap around
9. position of number 9=(2-1,2+1)=(1,3)=(1,0) //wrap around

Based on the above approach, following is the working code:

C++







filter_none

Sieve of Eratosthenes



Given a number n, print all primes smaller than or equal to n. It is also given that n is a small number. 
Example:
Input : n =10
Output : 2 3 5 7 

Input : n = 20 
Output: 2 3 5 7 11 13 17 19

The sieve of Eratosthenes is one of the most efficient ways to find all primes smaller than n when n is smaller than 10 million or so (Ref Wiki).

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.


Following is the algorithm to find all the prime numbers less than or equal to a given integer n by Eratosthenes’ method:

Create a list of consecutive integers from 2 to n: (2, 3, 4, …, n).
Initially, let p equal 2, the first prime number.
Starting from p2, count up in increments of p and mark each of these numbers greater than or equal to p2 itself in the list. These numbers will be p(p+1), p(p+2), p(p+3), etc..
Find the first number greater than p in the list that is not marked. If there was no such number, stop. Otherwise, let p now equal this number (which is the next prime), and repeat from step 3.







When the algorithm terminates, all the numbers in the list that are not marked are prime.

Explanation with Example:
Let us take an example when n = 50.  So we need to print all print numbers smaller than or equal to 50. 
We create a list of all numbers from 2 to 50.

According to the algorithm we will mark all the numbers which are divisible by 2 and are greater than or equal to the square of it.

Now we move to our next unmarked number 3 and mark all the numbers which are multiples of 3 and are greater than or equal to the square of it.

We move to our next unmarked number 5 and mark all multiples of 5 and are greater than or equal to the square of it.

We continue this process and our final table will look like below:

So the prime numbers are the unmarked ones: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47.
Thanks to Krishan Kumar for providing above explanation.

Implementation:
Following is the implementation of the above algorithm. In the following implementation, a boolean array arr[] of size n is used to mark multiples of prime numbers.

C/C++







filter_none

Number which has the maximum number of distinct  prime factors in the range M to N



Given two numbers M and N. The task is to print the number which has the maximum number of distinct prime factors of numbers in range M and N. If there exist multiple numbers, print the smallest one.
Examples:
Input: a=4, b=10
Output: 6
Number of distinct Prime Factors of 4 is 1
Number of distinct Prime Factors of 5 is 1
Number of distinct Prime Factors of 6 is 2
Number of distinct Prime Factors of 7 is 1
Number of distinct Prime Factors of 8 is 1
Number of distinct Prime Factors of 9 is 1
Number of distinct Prime Factors of 10 is 2





Input: a=100, b=150
Output: 102

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

The approach is to use  Sieve of Erathosthenes. Create a factorCount[] array to store the number of distinct prime factors of a number. While marking the number as prime, increment the count of prime factors in its multiples. In the end, get the maximum number stored in the factorCount[] array which will be the answer. 
Below is the implementation of the above approach:

C++







filter_none

Find day of the week for a given date


Write a function that calculates the day of the week for any particular date in the past or future. A typical application is to calculate the day of the week on which someone was born or some other special event occurred. 

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Following is a simple function suggested by Sakamoto, Lachman, Keith and Craver to calculate day. The following function returns 0 for Sunday, 1 for Monday, etc.

C++







filter_none

DFA based division


Deterministic Finite Automaton (DFA) can be used to check whether a number “num” is divisible by “k” or not. If the number is not divisible, remainder can also be obtained using DFA.
We consider the binary representation of ‘num’ and build a DFA with k states. The DFA has transition function for both 0 and 1. Once the DFA is built, we process ‘num’ over the DFA to get remainder.
Let us walk through an example. Suppose we want to check whether a given number ‘num’ is divisible by 3 or not. Any number can be written in the form: num = 3*a + b where ‘a’ is the quotient and ‘b’ is the remainder.
For 3, there can be 3 states in DFA, each corresponding to remainder 0, 1 and 2. And each state can have two transitions corresponding 0 and 1 (considering the binary representation of given ‘num’).
The transition function F(p, x) = q tells that on reading alphabet x, we move from state p to state q. Let us name the states as 0, 1 and 2. The initial state will always be 0. The final state indicates the remainder. If the final state is 0, the number is divisible.






In the above diagram, double circled state is final state.
1. When we are at state 0 and read 0, we remain at state 0.
2. When we are at state 0 and read 1, we move to state 1, why? The number so formed(1) in decimal gives remainder 1.
3. When we are at state 1 and read 0, we move to state 2, why? The number so formed(10) in decimal gives remainder 2.
4. When we are at state 1 and read 1, we move to state 0, why? The number so formed(11) in decimal gives remainder 0.
5. When we are at state 2 and read 0, we move to state 1, why? The number so formed(100) in decimal gives remainder 1.
6. When we are at state 2 and read 1, we remain at state 2, why? The number so formed(101) in decimal gves remainder 2.
The transition table looks like following:
state   0   1
_____________
 0      0   1
 1      2   0
 2      1   2
Let us check whether 6 is divisible by 3?
Binary representation of 6 is 110
state = 0
1. state=0, we read 1, new state=1
2. state=1, we read 1, new state=0
3. state=0, we read 0, new state=0
Since the final state is 0, the number is divisible by 3.
Let us take another example number as 4
state=0
1. state=0, we read 1, new state=1
2. state=1, we read 0, new state=2
3. state=2, we read 0, new state=1
Since, the final state is not 0, the number is not divisible by 3. The remainder is 1.
Note that the final state gives the remainder. 
We can extend the above solution for any value of k. For a value k, the states would be 0, 1, …. , k-1. How to calculate the transition if the decimal equivalent of the binary bits seen so far, crosses the range k? If we are at state p, we have read p (in decimal). Now we read 0, new read number becomes 2*p. If we read 1, new read number becomes 2*p+1. The new state can be obtained by subtracting k from these values (2p or 2p+1) where 0 <= p < k.
Based on the above approach, following is the working code:

C++







filter_none

Generate integer from 1 to 7 with equal probability


Given a function foo() that returns integers from 1 to 5 with equal probability, write a function that returns integers from 1 to 7 with equal probability using foo() only. Minimize the number of calls to foo() method. Also, use of any other library function is not allowed and no floating point arithmetic allowed.
Solution :
We know foo() returns integers from 1 to 5.  How we can ensure that integers from 1 to 7 occur with equal probability?
If we somehow generate integers from 1 to a-multiple-of-7 (like 7, 14, 21, …) with equal probability, we can use modulo division by 7 followed by adding 1 to get the numbers from 1 to 7 with equal probability.
We can generate from 1 to 21 with equal probability using the following expression.





 5*foo() + foo() -5 
Let us see how above expression can be used.
1. For each value of first foo(), there can be 5 possible combinations for values of second foo(). So, there are total 25 combinations possible.
2. The range of values returned by the above equation is 1 to 25, each integer occurring exactly once.
3. If the value of the equation comes out to be less than 22, return modulo division by 7 followed by adding 1. Else, again call the method recursively. The probability of returning each integer thus becomes 1/7.
The below program shows that the expression returns each integer from 1 to 25 exactly once.

C++







filter_none

Given a number, find the next smallest palindrome


Given a number, find the next smallest palindrome larger than this number.  For example, if the input number is “2 3 5 4 5”,  the output should be “2 3 6 3 2”.  And if the input number is “9 9 9”, the output should be “1 0 0 1”. 
The input is assumed to be an array. Every entry in array represents a digit in input number. Let the array be ‘num[]’ and size of array be ‘n’
There can be three different types of inputs that need to be handled separately.
1) The input number is palindrome and has all 9s.  For example “9 9 9”. Output should be “1 0 0 1”
2) The input number is not palindrome. For example “1 2 3 4”.  Output should be “1 3 3 1”
3) The input number is palindrome and doesn’t have all 9s.  For example “1 2 2 1”. Output should be “1 3 3 1”.







Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Make a fair coin from a biased coin


You are given a function foo() that represents a biased coin. When foo() is called, it returns 0 with 60% probability, and 1 with 40% probability. Write a new function that returns 0 and 1 with 50% probability each.  Your function should use only foo(), no other library method.
Solution:
We know foo() returns 0 with 60% probability. How can we ensure that 0 and 1 are returned with 50% probability?
The solution is similar to this post. If we can somehow get two cases with equal probability, then we are done. We  call foo() two times.  Both calls will return 0 with 60% probability.  So the two pairs (0, 1) and (1, 0) will be generated with equal probability from two calls of foo(). Let us see how.
(0, 1): The probability to get 0 followed by 1 from two calls of foo() = 0.6 * 0.4 = 0.24
(1, 0):  The probability to get 1 followed by 0 from two calls of foo() = 0.4 * 0.6 = 0.24





So the two cases appear with equal probability.  The idea is to return consider only the above two cases, return 0 in one case, return 1 in other case. For other cases [(0, 0) and (1, 1)], recur until you end up in any of the above two cases. 
The below program depicts how we can use foo() to return 0 and 1 with equal probability.

C++







filter_none

Check divisibility by 7


Given a number, check if it is divisible by 7. You are not allowed to use modulo operator, floating point arithmetic is also not allowed. 
A simple method is repeated subtraction. Following is another interesting method.
Divisibility by 7 can be checked by a recursive method. A number of the form 10a + b is divisible by 7 if and only if a – 2b is divisible by 7. In other words, subtract twice the last digit from the number formed by the remaining digits. Continue to do this until a small number.  





Example: the number 371: 37 – (2×1) = 37 – 2 = 35; 3 – (2 × 5) = 3 – 10 = -7; thus, since -7 is divisible by 7, 371 is divisible by 7. 
Following is the implementation of the above method

C++







filter_none

Find the largest multiple of 3 | Set 1 (Using Queue)


Given an array of non-negative integers. Find the largest multiple of 3 that can be formed from array elements.  
For example, if the input array is {8, 1, 9}, the output should be “9 8 1”, and if the input array is {8, 1, 7, 6, 0}, output should be “8 7 6 0”.
Method 1 (Brute Force)
The simple & straight forward approach is to generate all the combinations of the elements and keep track of the largest number formed which is divisible by 3. 





Time Complexity: O(n x 2^n).  There will be 2^n combinations of array elements. To compare each combination with the largest number so far may take O(n) time.
Auxiliary Space: O(n) // to avoid integer overflow, the largest number is assumed to be stored in the form of array.
Method 2 (Tricky)
This problem can be solved efficiently with the help of O(n) extra space. This method is based on the following facts about numbers which are multiple of 3.
1) A number is multiple of 3 if and only if the sum of digits of number is multiple of 3.  For example, let us consider 8760, it is a multiple of 3 because sum of digits is 8 + 7+ 6+ 0 = 21, which is a multiple of 3.  
2) If a number is multiple of 3, then all permutations of it are also multiple of 3.  For example, since 6078 is a multiple of 3, the numbers 8760, 7608, 7068, ….. are also multiples of 3. 
3) We get the same remainder when we divide the number and sum of digits of the number.  For example, if divide number 151 and sum of it digits 7, by 3, we get the same remainder 1.
What is the idea behind above facts?
The value of 10%3 and 100%3 is 1. The same is true for all the higher powers of 10, because 3 divides 9, 99, 999, … etc.
Let us consider a 3 digit number n to prove above facts. Let the first, second and third digits of n be ‘a’, ‘b’ and ‘c’ respectively. n can be written as 
n = 100.a + 10.b + c 
Since (10^x)%3 is 1 for any x, the above expression gives the same remainder as following expression
 1.a + 1.b + c 
So the remainder obtained by sum of digits and ‘n’ is same.
Following is a solution based on the above observation.
1. Sort the array in non-decreasing order.




2. Take three queues. One for storing elements which on dividing by 3 gives remainder as 0.The second queue stores digits which on dividing by 3 gives     remainder as 1. The third queue stores digits which on dividing by 3 gives remainder as 2. Call them as queue0, queue1 and queue2
3. Find the sum of all the digits.
4. Three cases arise:
……4.1  The sum of digits is divisible by 3. Dequeue all the digits from the three queues. Sort them in non-increasing order. Output the array.
……4.2  The sum of digits produces remainder 1 when divided by 3.
         Remove one item from queue1. If queue1 is empty, remove two items from queue2. If queue2 contains less than two items, the number is not possible.
……4.3  The sum of digits produces remainder 2 when divided by 3.
         Remove one item from queue2. If queue2 is empty, remove two items from queue1. If queue1 contains less than two items, the number is not possible.
5. Finally empty all the queues into an auxiliary array. Sort the auxiliary array in non-increasing order. Output the auxiliary array.
The below code works only if the input arrays has numbers from 0 to 9.  It can be easily extended for any positive integer array.  We just have to modify the part where we sort the array in decreasing order, at the end of code.

C++







filter_none

Lexicographic rank of a string


Given a string, find its rank among all its permutations sorted lexicographically.  For example, rank of “abc” is 1, rank of “acb” is 2, and rank of “cba” is 6. 
Examples:
Input : str[] = "acb"
Output : Rank = 2

Input : str[] = "string"
Output : Rank = 598

Input : str[] = "cba"
Output : Rank = 6



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Print all permutations in sorted (lexicographic) order


Given a string, print all permutations of it in sorted order.  For example, if the input string is “ABC”, then output should be “ABC, ACB, BAC, BCA, CAB, CBA”.
We have discussed a program to print all permutations in this post, but here we must print the permutations in increasing order.
Following are the steps to print the permutations lexicographic-ally





1. Sort the given string in non-decreasing order and print it. The first permutation is always the string sorted in non-decreasing order.
2. Start generating next higher permutation. Do it until next higher permutation is not possible. If we reach a permutation where all characters are sorted in non-increasing order, then that permutation is the last permutation.
Steps to generate the next higher permutation:
1. Take the previously printed permutation and find the rightmost character in it, which is smaller than its next character. Let us call this character as ‘first character’.
2. Now find the ceiling of the ‘first character’. Ceiling is the smallest character on right of ‘first character’, which is greater than ‘first character’. Let us call the ceil character as ‘second character’.
3. Swap the two characters found in above 2 steps.
4. Sort the substring (in non-decreasing order) after the original index of ‘first character’.
Let us consider the string “ABCDEF”. Let previously printed permutation be “DCFEBA”.  The next permutation in sorted order should be “DEABCF”.  Let us understand above steps to find next permutation. The ‘first character’ will be ‘C’. The ‘second character’ will be ‘E’.  After swapping these two, we get “DEFCBA”.  The final step is to sort the substring after the character original index of ‘first character’.  Finally, we get “DEABCF”.
Following is the implementation of the algorithm.

C++







filter_none

Shuffle a given array using Fisher–Yates shuffle Algorithm


Given an array, write a program to generate a random permutation of array elements. This question is also asked as “shuffle a deck of cards” or “randomize a given array”. Here shuffle means that every permutation of array element should equally likely.

Let the given array be arr[]. A simple solution is to create an auxiliary array temp[] which is initially a copy of arr[].  Randomly select an element from temp[], copy the randomly selected element to arr[0] and remove the selected element from temp[].  Repeat the same process n times and keep copying elements to arr[1], arr[2], … .  The time complexity of this solution will be O(n^2).
 Fisher–Yates shuffle Algorithm works in O(n) time complexity.  The assumption here is, we are given a function rand() that generates random number in O(1) time.
The idea is to start from the last element, swap it with a randomly selected element from the whole array (including last). Now consider the array from 0 to n-2 (size reduced by 1), and repeat the process till we hit the first element. 





Following is the detailed algorithm
To shuffle an array a of n elements (indices 0..n-1):
  for i from n - 1 downto 1 do
       j = random integer with 0 <= j <= i
       exchange a[j] and a[i]

Following is implementation of this algorithm.

C++






filter_none

Space and time efficient Binomial Coefficient


Write a function that takes two parameters n and k and returns the value of Binomial Coefficient C(n, k). For example, your function should return 6 for n = 4 and k = 2, and it should return 10 for n = 5 and k = 2.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

We have discussed a O(n*k) time and O(k) extra space algorithm in this post.  The value of C(n, k) can be calculated in O(k) time and O(1) extra space.  
C(n, k) = n! / (n-k)! * k!
        = [n * (n-1) *....* 1]  / [ ( (n-k) * (n-k-1) * .... * 1) * 
                                    ( k * (k-1) * .... * 1 ) ]
After simplifying, we get
C(n, k) = [n * (n-1) * .... * (n-k+1)] / [k * (k-1) * .... * 1]

Also, C(n, k) = C(n, n-k)  // we can change r to n-r if r > n-r 
Following implementation uses above formula to calculate C(n, k)

C++












filter_none

Reservoir Sampling


Reservoir sampling is a family of randomized algorithms for randomly choosing k samples from a list of n items, where n is either a very large or unknown number. Typically n is large enough that the list doesn’t fit into main memory.  For example, a list of search queries in Google and Facebook.
So we are given a big array (or stream) of numbers (to simplify), and we need to write an efficient function to randomly select k numbers where 1 <= k <= n.  Let the input array be stream[]. 
A simple solution is to create an array reservoir[] of maximum size k.  One by one randomly select an item from stream[0..n-1]. If the selected item is not previously selected, then put it in reservoir[].   To check if an item is previously selected or not, we need to search the item in reservoir[].   The time complexity of this algorithm will be O(k^2).  This can be costly if k is big.  Also, this is not efficient if the input is in the form of a stream.  





It can be solved in O(n) time.  The solution also suits well for input in the form of stream. The idea is similar to this post.  Following are the steps.
1) Create an array reservoir[0..k-1] and copy first k items of stream[] to it.
2) Now one by one consider all items from (k+1)th item to nth item.
…a) Generate a random number from 0 to i where i is index of current item in stream[]. Let the generated random number is j.
…b) If j is in range 0 to k-1, replace reservoir[j] with arr[i]
Following is implementation of the above algorithm.

C++







filter_none

Pascal’s Triangle


Pascal’s triangle is a triangular array of the binomial coefficients. Write a function that takes an integer value n as input and prints first n lines of the Pascal’s triangle. Following are the first 6 rows of Pascal’s Triangle.
1  
1 1 
1 2 1 
1 3 3 1 
1 4 6 4 1 
1 5 10 10 5 1 


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Select a random number from stream, with O(1) space


Given a stream of numbers, generate a random number from the stream.  You are allowed to use only O(1) space and the input is in the form of a stream, so can’t store the previously seen numbers. 
So how do we generate a random number from the whole stream such that the probability of picking any number is 1/n. with O(1) extra space? This problem is a variation of Reservoir Sampling.   Here the value of k is 1.
1) Initialize ‘count’ as 0, ‘count’ is used to store count of numbers seen so far in stream.
2) For each number ‘x’ from stream, do following
…..a) Increment ‘count’ by 1.
…..b) If count is 1, set result as x, and return result.
…..c) Generate a random number from 0 to ‘count-1’.  Let the generated random number be i.
…..d) If i is equal to ‘count – 1’,  update the result as x.

C++












filter_none

Find the largest multiple of 2, 3 and 5


An array of size n is given. The array contains digits from 0 to 9. Generate the largest number using the digits in the array such that the number is divisible by 2, 3 and 5.
For example, if the arrays is {1, 8, 7, 6, 0}, output must be: 8760.  And if the arrays is {7, 7, 7, 6}, output must be: “no number can be formed”.
Source: Amazon Interview | Set 7
This problem is a variation of “Find the largest multiple of 3“.





Since the number has to be divisible by 2 and 5, it has to have last digit as 0. So if the given array doesn’t contain any zero, then no solution exists.
Once a 0 is available, extract 0 from the given array. Only thing left is, the number should be is divisible by 3 and the largest of all. Which has been discussed here. 


Efficient program to calculate e^x


The value of Exponential Function e^x can be expressed using following Taylor Series.
e^x = 1 + x/1! + x^2/2! + x^3/3! + ...... 

How to efficiently calculate the sum of above series?
The series can be re-written as 





e^x = 1 + (x/1) (1 + (x/2) (1 + (x/3) (........) ) ) 
Let the sum needs to be calculated for n terms, we can calculate sum using following loop.
for (i = n - 1, sum = 1; i > 0; --i )
    sum = 1 + x * sum / i; 
Following is implementation of the above idea.

C++







filter_none

Measure one litre using two vessels and infinite water supply


There are two vessels of capacities ‘a’ and ‘b’ respectively. We have infinite water supply. Give an efficient algorithm to make exactly 1 litre of water in one of the vessels. You can throw all the water from any vessel any point of time. Assume that ‘a’ and ‘b’ are Coprimes.
Following are the steps:
Let V1 be the vessel of capacity ‘a’ and V2 be the vessel of capacity ‘b’ and ‘a’ is smaller than ‘b’.
1) Do following while the amount of water in V1 is not 1.
….a) If V1 is empty, then completely fill V1
….b) Transfer water from V1 to V2.  If V2 becomes full, then keep the remaining water in V1 and empty V2
2) V1 will have 1 litre after termination of loop in step 1. Return.
Following is C++ implementation of the above algorithm.










filter_none

Efficient program to print all prime factors of a given number


Given a number n, write an efficient function to print all prime factors of n. For example, if the input number is 12, then output should be “2 2 3”. And if the input number is 315, then output should be “3 3 5 7”.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Print all possible combinations of r elements in a given array of size n



Given an array of size n, generate and print all possible combinations of r elements in array.  For example, if input array is {1, 2, 3, 4} and r is 2, then output should be {1, 2}, {1, 3}, {1, 4}, {2, 3}, {2, 4} and {3, 4}.
Following are two methods to do this. 
Method 1 (Fix Elements and Recur)
We create a temporary array ‘data[]’ which stores all outputs one by one. The idea is to start from first index (index = 0) in data[], one by one fix elements at this index and recur for remaining indexes.  Let the input array be {1, 2, 3, 4, 5} and r be 3.  We first fix 1 at index 0 in data[], then recur for remaining indexes, then we fix 2 at index 0 and recur.  Finally, we fix 3 and recur for remaining indexes.  When number of elements in data[] becomes equal to r (size of a combination), we print data[].
Following diagram shows recursion tree for same input.







Following is implementation of above approach.

C++







filter_none

Random number generator in arbitrary probability distribution fashion


Given n numbers, each with some frequency of occurrence.  Return a random number with probability proportional to its frequency of occurrence.
Example: 
Let following be the given numbers.
  arr[] = {10, 30, 20, 40}  

Let following be the frequencies of given numbers.
  freq[] = {1, 6, 2, 1}  

The output should be
  10 with probability 1/10
  30 with probability 6/10
  20 with probability 2/10
  40 with probability 1/10 
It is quite clear that the simple random number generator won’t work here as it doesn’t keep track of the frequency of occurrence. 





We need to somehow transform the problem into a problem whose solution is known to us.
One simple method is to take an auxiliary array (say aux[]) and duplicate the numbers according to their frequency of occurrence. Generate a random number(say r) between 0 to Sum-1(including both), where Sum represents summation of frequency array (freq[] in above example). Return the random number aux[r] (Implementation of this method is left as an exercise to the readers).
The limitation of the above method discussed above is huge memory consumption when frequency of occurrence is high. If the input is 997, 8761 and 1, this method is clearly not efficient.
How can we reduce the memory consumption?  Following is detailed algorithm that uses O(n) extra space where n is number of elements in input arrays.
1.    Take an auxiliary array (say prefix[]) of size n.
2.    Populate it with prefix sum, such that prefix[i] represents sum of numbers from 0 to i.
3.    Generate a random number(say r) between 1 to Sum(including both), where Sum represents summation of input frequency array.
4.    Find index of Ceil of random number generated in step #3 in the prefix array. Let the index be indexc.
5.    Return the random number arr[indexc], where arr[] contains the input n numbers.
  Before we go to the implementation part, let us have quick look at the algorithm with an example:
      arr[]:    {10, 20, 30}
      freq[]:   {2, 3, 1}
      Prefix[]: {2, 5, 6}
  Since last entry in prefix is 6, all possible values of r are [1, 2, 3, 4, 5, 6]
          1: Ceil is 2. Random number generated is 10.
          2: Ceil is 2. Random number generated is 10.
          3: Ceil is 5. Random number generated is 20.
          4: Ceil is 5. Random number generated is 20.
          5: Ceil is 5. Random number generated is 20.
          6. Ceil is 6. Random number generated is 30.
  In the above example
      10 is generated with probability 2/6.
      20 is generated with probability 3/6.
      30 is generated with probability 1/6.
How does this work?
Any number input[i] is generated as many times as its frequency of occurrence because there exists count of integers in range(prefix[i – 1], prefix[i]] is input[i]. Like in the above example 3 is generated thrice, as there exists 3 integers 3, 4 and 5 whose ceil is 5.

C++







filter_none

How to check if a given number is Fibonacci number?


Given a number ‘n’, how to check if n is a Fibonacci number. First few Fibonacci numbers are 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 141, .. 
Examples :
Input : 8
Output : Yes

Input : 34
Output : Yes

Input : 41
Output : No



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Russian Peasant  (Multiply two numbers using bitwise operators)


Given two integers, write a function to multiply them without using multiplication operator.
There are many other ways to multiply two numbers (For example, see this). One interesting method is the Russian peasant algorithm. The idea is to double the first number and halve the second number repeatedly till the second number doesn’t become 1. In the process, whenever the second number become odd, we add the first number to result (result is initialized as 0)
The following is simple algorithm. 
Let the two given numbers be 'a' and 'b'
1) Initialize result 'res' as 0.
2) Do following while 'b' is greater than 0
   a) If 'b' is odd, add 'a' to 'res'
   b) Double 'a' and halve 'b'
3) Return 'res'. 

C/C++






filter_none

Count all possible groups of size 2 or 3 that have sum as multiple of 3


Given an unsorted integer (positive values only) array of size ‘n’, we can form a group of two or three, the group should be such that the sum of all elements in that group is a multiple of 3. Count all possible number of groups that can be generated in this way.
Examples:
Input: arr[] = {3, 6, 7, 2, 9}
Output: 8
// Groups are {3,6}, {3,9}, {9,6}, {7,2}, {3,6,9},
//            {3,7,2}, {7,2,6}, {7,2,9}


Input: arr[] = {2, 1, 3, 4}
Output: 4
// Groups are {2,1}, {2,4}, {2,1,3}, {2,4,3}


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

The idea is to see remainder of every element when divided by 3. A set of elements can form a group only if sun of their remainders is multiple of 3.
For example : 8, 4, 12. Now, the remainders are 2, 1, and 0 respectively. This means 8 is 2 distance away from 3s multiple (6), 4 is 1 distance away from 3s multiple(3), and 12 is 0 distance away. So, we can write the sum as 8 (can be written as 6+2), 4 (can be written as 3+1), and 12 (can be written as 12+0). Now the sum of 8, 4 and 12 can be written as 6+2+3+1+12+0. Now, 6+3+12 will always be divisible by 3 as all the terms are multiple of three. Now, we only need to check if 2+1+0 (remainders) is divisible by 3 or not which makes the complete sum divisible by 3.
Since the task is to enumerate groups, we count all elements with different remainders.
1. Hash all elements in a count array based on remainder, i.e, 
   for all elements a[i], do c[a[i]%3]++;
2. Now c[0] contains the number of elements which when divided
   by 3 leave remainder 0 and similarly c[1] for remainder 1 
   and c[2] for 2.
3. Now for group of 2, we have 2 possibilities
   a. 2 elements of remainder 0 group. Such possibilities are 
      c[0]*(c[0]-1)/2
   b. 1 element of remainder 1 and 1 from remainder 2 group
      Such groups are c[1]*c[2].
4. Now for group of 3,we have 4 possibilities
   a. 3 elements from remainder group 0.
      No. of such groups are c[0]C3
   b. 3 elements from remainder group 1.
      No. of such groups are c[1]C3
   c. 3 elements from remainder group 2.
      No. of such groups are c[2]C3
   d. 1 element from each of 3 groups. 
      No. of such groups are c[0]*c[1]*c[2].
5. Add all the groups in steps 3 and 4 to obtain the result.


C++






filter_none

Program for Tower of Hanoi



Tower of Hanoi is a mathematical puzzle where we have three rods and n disks. The objective of the puzzle is to move the entire stack to another rod, obeying the following simple rules:
1) Only one disk can be moved at a time.
2) Each move consists of taking the upper disk from one of the stacks and placing it on top of another stack i.e. a disk can only be moved if it is the uppermost disk on a stack.
3) No disk may be placed on top of a smaller disk.






Approach : 
Take an example for 2 disks :
Let rod 1 = 'A', rod 2 = 'B', rod 3 = 'C'.

Step 1 : Shift first disk from 'A' to 'B'.
Step 2 : Shift second disk from 'A' to 'C'.
Step 3 : Shift first disk from 'B' to 'C'.

The pattern here is :
Shift 'n-1' disks from 'A' to 'B'.
Shift last disk from 'A' to 'C'.
Shift 'n-1' disks from 'B' to 'C'.

Image illustration for 3 disks :


Examples:
Input : 2
Output : Disk 1 moved from A to B
         Disk 2 moved from A to C
         Disk 1 moved from B to C

Input : 3
Output : Disk 1 moved from A to C
         Disk 2 moved from A to B
         Disk 1 moved from C to B
         Disk 3 moved from A to C
         Disk 1 moved from B to A
         Disk 2 moved from B to C
         Disk 1 moved from A to C



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Horner’s Method for Polynomial Evaluation


Given a polynomial of the form cnxn + cn-1xn-1 + cn-2xn-2 + … + c1x + c0 and a value of x, find the value of polynomial for a given value of x.  Here cn, cn-1, .. are integers (may be negative) and n is a positive integer.
Input is in the form of an array say poly[] where poly[0] represents coefficient for xn and poly[1] represents coefficient for xn-1 and so on.
Examples: 





// Evaluate value of 2x3 - 6x2 + 2x - 1 for x = 3
Input: poly[] = {2, -6, 2, -1}, x = 3
Output: 5

// Evaluate value of 2x3 + 3x + 1 for x = 2
Input: poly[] = {2, 0, 3, 1}, x = 2
Output: 23



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count trailing zeroes in factorial of a number


Given an integer n, write a function that returns count of trailing zeroes in n!. 
Examples :
Input: n = 5
Output: 1 
Factorial of 5 is 120 which has one trailing 0.

Input: n = 20
Output: 4
Factorial of 20 is 2432902008176640000 which has
4 trailing zeroes.

Input: n = 100
Output: 24







We strongly recommend that you click here and practice it, before moving on to the solution.


Program for nth Catalan Number


Catalan numbers are a sequence of natural numbers that occurs in many interesting counting problems like following.
1) Count the number of expressions containing n pairs of parentheses which are correctly matched. For n = 3, possible expressions are ((())), ()(()), ()()(),  (())(), (()()).
2) Count the number of possible Binary Search Trees with n keys (See this)





3) Count the number of full binary trees (A rooted binary tree is full if every vertex has either two children or no children)  with n+1 leaves.
See this for more applications. 
The first few Catalan numbers for n = 0, 1, 2, 3, … are 1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862, …


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Write a function that generates one of 3 numbers according to given probabilities


You are given a function rand(a, b) which generates equiprobable random numbers between [a, b] inclusive. Generate 3 numbers x, y, z with probability P(x), P(y), P(z) such that P(x) + P(y) + P(z) = 1 using the given rand(a,b) function.
The idea is to utilize the equiprobable feature of the rand(a,b) provided. Let the given probabilities be in percentage form, for example P(x)=40%, P(y)=25%, P(z)=35%..
Following are the detailed steps.
1) Generate a random number between 1 and 100. Since they are equiprobable, the probability of each number appearing is 1/100.
2) Following are some important points to note about generated random number ‘r’.
a) ‘r’ is smaller than or equal to P(x) with probability P(x)/100.
b) ‘r’ is greater than P(x) and smaller than or equal P(x) + P(y) with P(y)/100.
c) ‘r’ is greater than P(x) + P(y) and smaller than or equal 100 (or P(x) + P(y) + P(z)) with probability P(z)/100.










filter_none

Find Excel column name from a given column number


MS Excel columns has a pattern like A, B, C, … ,Z, AA, AB, AC,…. ,AZ, BA, BB, … ZZ, AAA, AAB …..  etc.  In other words, column 1 is named as “A”, column 2 as “B”, column 27 as “AA”.
Given a column number, find its corresponding Excel column name.  Following are more examples.
Input          Output
 26             Z
 51             AY
 52             AZ
 80             CB
 676            YZ
 702            ZZ
 705            AAC



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Find next greater number with same set of digits


Given a number n, find the smallest number that has same set of digits as n and is greater than n.  If n is the greatest possible number with its set of digits, then print “not possible”.
Examples:
For simplicity of implementation, we have considered input number as a string.  
Input:  n = "218765"
Output: "251678"

Input:  n = "1234"
Output: "1243"

Input: n = "4321"
Output: "Not Possible"

Input: n = "534976"
Output: "536479"



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count Possible Decodings of a given Digit Sequence


Let 1 represent ‘A’, 2 represents ‘B’, etc.  Given a digit sequence, count the number of possible decodings of the given digit sequence.  
Examples:
Input:  digits[] = "121"
Output: 3
// The possible decodings are "ABA", "AU", "LA"

Input: digits[] = "1234"
Output: 3
// The possible decodings are "ABCD", "LCD", "AWD"
An empty digit sequence is considered to have one decoding.  It may be assumed that the input contains valid digits from 0 to 9 and there are no leading 0’s, no extra trailing 0’s and no two or more consecutive 0’s.







Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Calculate the angle between hour hand and minute hand


This problem is know as Clock angle problem where we need to find angle between hands of an analog clock at a given time.
Examples: 
Input:  h = 12:00, m = 30.00
Output: 165 degree

Input:  h = 3.00, m = 30.00
Output: 75 degree



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count number of binary strings without consecutive 1’s


Given a positive integer N, count all possible distinct binary strings of length N such that there are no consecutive 1’s.
Examples:
Input:  N = 2
Output: 3
// The 3 strings are 00, 01, 10

Input: N = 3
Output: 5
// The 5 strings are 000, 001, 010, 100, 101


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Find the smallest number whose digits multiply to a given number n


Given a number ‘n’, find the smallest number ‘p’ such that if we multiply all digits of ‘p’, we get ‘n’.  The result ‘p’ should have minimum two digits.
Examples:
Input:  n = 36
Output: p = 49 
// Note that 4*9 = 36 and 49 is the smallest such number

Input:  n = 100
Output: p = 455
// Note that 4*5*5 = 100 and 455 is the smallest such number

Input: n = 1
Output:p = 11
// Note that 1*1 = 1

Input: n = 13
Output: Not Possible


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

For a given n, following are the two cases to be considered.
Case 1: n < 10  When n is smaller than 10, the output is always n+10.  For example for n = 7, the output is 17. For n = 9, output is 19.





Case 2: n >= 10 Find all factors of n which are between 2 and 9 (both inclusive).  The idea is to start searching from 9 so that the number of digits in the result is minimized. For example, 9 is preferred over 33 and 8 is preferred over 24.
Store all found factors in an array.  The array would contain digits in non-increasing order, so finally print the array in reverse order.
Following is the implementation of above concept.

C/C++







filter_none

Draw a circle without floating point arithmetic


Given a radius of a circle, draw the circle without using floating point arithmetic.
Following program uses a simple concept. Let the radius of the circle be r. Consider a square of size (2r+1)*(2r+1) around the circle to be drawn. Now walk through every point inside the square. For every every point (x,y), if (x, y) lies inside the circle (or x^2+ y^2 < r^2), then print it, otherwise print space.

C++






filter_none

How to check if an instance of 8 puzzle is solvable?


What is 8 puzzle?
Given a 3×3 board with 8 tiles (every tile has one number from 1 to 8) and one empty space. The objective is to place the numbers on tiles in order using the empty space. We can slide four adjacent (left, right, above and below) tiles into the empty space.

How to find if given state is solvable?
Following are two examples, the first example can reach goal state by a series of slides.  The second example cannot.






Following is simple rule to check if a 8 puzzle is solvable.
It is not possible to solve an instance of 8 puzzle if number of inversions is odd in the input state.  In the examples given in above figure, the first example has 10 inversions, therefore solvable.  The second example has 11 inversions, therefore unsolvable.
What is inversion?
A pair of tiles form an inversion if the values on tiles are in reverse order of their appearance in goal state.  For example, the following instance of 8 puzzle has two inversions, (8, 6) and (8, 7). 
   1   2   3
   4   _   5
   8   6   7      
Following are the implementations to check whether a given instance of 8 puzzle is solvable or not.  The idea is simple, we count inversions in the given 8 puzzle. 

C++






filter_none

Birthday Paradox


How many people must be there in a room to make the probability 100% that at-least two people in the room have same birthday?
Answer: 367 (since there are 366 possible birthdays, including February 29).
The above question was simple.  Try the below question yourself.
How many people must be there in a room to make the probability 50% that at-least  two people in the room have same birthday?
Answer: 23
The number is surprisingly very low.  In fact, we need only 70 people to make the probability 99.9 %.
Let us discuss the generalized formula.





What is the probability that two persons among n have same birthday?
Let the probability that two people in a room with n have same birthday be P(same).  P(Same) can be easily evaluated in terms of P(different) where P(different) is the probability that all of them have different birthday.
P(same) = 1 – P(different)
P(different) can be written as  1  x (364/365) x (363/365) x (362/365) x …. x (1 – (n-1)/365)
How did we get the above expression?
Persons from first to last can get birthdays in following order for all birthdays to be distinct:
The first person can have any birthday among 365
The second person should have a birthday which is not same as first person
The third person should have a birthday which is not same as first two persons.
…………….
……………
The n’th person should have a birthday which is not same as any of the earlier considered (n-1) persons.
Approximation of above expression
The above expression can be approximated using Taylor’s Series.

provides a first-order approximation for ex for x << 1:

To apply this approximation to the first expression derived for p(different), set x = -a / 365. Thus,

The above expression derived for p(different) can be written as
   1 x (1 – 1/365) x (1 – 2/365) x (1 – 3/365) x …. x (1 – (n-1)/365)




By putting the value of  1 – a/365 as  e-a/365, we get following.



Therefore,
p(same) = 1- p(different)

An even coarser approximation is given by
p(same)

By taking Log on both sides, we get the reverse formula.

Using the above approximate formula, we can approximate number of people for a given probability. For example the following C++ function find() returns the smallest n for which the probability is greater than the given p.
 Implementation of approximate formula.
The following is program to approximate number of people for a given probability.

C++







filter_none

Multiply two polynomials


Given two polynomials represented by two arrays, write a function that multiplies given two polynomials. 
Example: 
Input:  A[] = {5, 0, 10, 6} 
        B[] = {1, 2, 4} 
Output: prod[] = {5, 10, 30, 26, 52, 24}

The first input array represents "5 + 0x^1 + 10x^2 + 6x^3"
The second array represents "1 + 2x^1 + 4x^2" 
And Output is "5 + 10x^1 + 30x^2 + 26x^3 + 52x^4 + 24x^5"



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count Distinct Non-Negative Integer Pairs (x, y) that Satisfy the Inequality x*x + y*y < n


Given a positive number n, count all distinct Non-Negative Integer pairs (x, y) that satisfy the inequality x*x + y*y < n. 
Examples:
Input:  n = 5
Output: 6
The pairs are (0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (0, 2)

Input: n = 6
Output: 8
The pairs are (0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (0, 2),
              (1, 2), (2, 1)

A Simple Solution is to run two loops.  The outer loop goes for all possible values of x (from 0 to √n).  The inner loops picks all possible values of y for current value of x (picked by outer loop).  Following is  implementation of simple solution.

C++












filter_none

Count ways to reach the n’th stair


There are n stairs, a person standing at the bottom wants to reach the top. The person can climb either 1 stair or 2 stairs at a time. Count the number of ways, the person can reach the top.

Consider the example shown in diagram.   The value of n is 3. There are 3 ways to reach the top. The diagram is taken from Easier Fibonacci puzzles





 
 
 
 
 
 
 
More Examples: 
Input: n = 1
Output: 1
There is only one way to climb 1 stair

Input: n = 2
Output: 2
There are two ways: (1, 1) and (2)

Input: n = 4
Output: 5
(1, 1, 1, 1), (1, 1, 2), (2, 1, 1), (1, 2, 1), (2, 2)



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Replace all ‘0’ with ‘5’ in an input Integer


Given a integer as a input and replace all the ‘0’ with ‘5’ in the integer.
Examples: 
    102 - 152
    1020 - 1525 
Use of array to store all digits is not allowed.
Source: Amazon interview Experience | Set 136 (For SDE-T)






Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

The idea is simple, we get the last digit using mod operator ‘%’. If the digit is 0, we replace it with 5, otherwise keep it as it is.  Then we recur for remaining digits. 
Following is the implementation of the above idea.

C++







filter_none

Program to add two polynomials


Given two polynomials represented by two arrays, write a function that adds given two polynomials. 
Example:
Input:  A[] = {5, 0, 10, 6} 
        B[] = {1, 2, 4} 
Output: sum[] = {6, 2, 14, 6}

The first input array represents "5 + 0x^1 + 10x^2 + 6x^3"
The second array represents "1 + 2x^1 + 4x^2" 
And Output is "6 + 2x^1 + 14x^2 + 6x^3"

We strongly recommend to minimize your browser and try this yourself first.
Addition is simpler than multiplication of polynomials.  We initialize result as one of the two polynomials, then we traverse the other polynomial and add all terms to the result.





add(A[0..m-1], B[0..n01])
1) Create a sum array sum[] of size equal to maximum of 'm' and 'n'
2) Copy A[] to sum[].
3) Traverse array B[] and do following for every element B[i]
          sum[i] = sum[i] + B[i]
4) Return sum[].
The following is implementation of above algorithm.

C++







filter_none

Print first k digits of 1/n where n is a positive integer


Given a positive integer n, print first k digits after point in value of 1/n.  Your program should avoid overflow and floating point arithmetic.
Examples :
Input:   n = 3, k = 3
Output:  333

Input:   n = 50, k = 4
Output:  0200

We strongly recommend to minimize the browser and try this yourself first.





Let us consider an example n = 7, k = 3.  The first digit of 1/7 is ‘1’, it can be obtained by doing integer value of 10/7.  Remainder of 10/7 is  3.  Next digit is 4 which can be obtained by taking integer value of 30/7.  Remainder of 30/7 is 2.  Next digits is 2 which can be obtained by taking integer value of 20/7

C++







filter_none

Given a number as a string, find the number of contiguous subsequences which recursively add up to 9


Given a number as a string, write a function to find the number of substrings (or  contiguous subsequences) of the given string which recursively add up to 9.
For example digits of 729 recursively add to 9,
7 + 2 + 9 = 18
Recur for 18
1 + 8 = 9 
Examples: 





 
Input: 4189
Output: 3
There are three substrings which recursively add to 9.
The substrings are 18, 9 and 189.

Input: 999
Output: 6
There are 6 substrings which recursively add to 9.
9, 99, 999, 9, 99, 9
All digits of a number recursively add up to 9, if only if the number is multiple of 9. We basically need to check for s%9 for all substrings s.  One trick used in below program is to do modular arithmetic to avoid overflow for big strings. 
Following is a simple implementation based on this approach.  The implementation assumes that there are no leading 0’s in input number.

C++







filter_none

Program for Bisection Method


Given a function f(x) on floating number x and two numbers ‘a’ and ‘b’ such that f(a)*f(b) < 0 and f(x) is continuous in [a, b].  Here f(x) represents algebraic or transcendental equation. Find root of function in interval [a, b] (Or find a value of x such that f(x) is 0).
Example:
Input: A function of x, for example x3 - x2 + 2.     
       And two values: a = -200 and b = 300 such that
       f(a)*f(b) < 0, i.e., f(a) and f(b) have
       opposite signs.
Output: The value of root is : -1.0025
        OR any other value with allowed
        deviation from root.

What are Algebraic and Transcendental functions?
Algebraic function are the one which can be represented in the form of polynomials like f(x) = a1x3 + a2x2 + ….. + e where aa1, a2, … are constants and x is a variable.
Transcendental function are non algebraic functions, for example f(x) = sin(x)*x – 3 or f(x) = ex + x2 or f(x) = ln(x) + x …. 
What is Bisection Method?
The method is also called the interval halving method, the binary search method or the dichotomy method. This method is used to find root of an equation in a given interval that is value of ‘x’ for which f(x) = 0 . 





The method is based on The Intermediate Value Theorem which states that if f(x) is a continuous function and there are two real numbers a and b such that f(a)*f(b)  0 and f(b) < 0), then it is guaranteed that it has at least one root between them.
Assumptions:

 f(x) is a continuous function in interval [a, b] 
 f(a) * f(b) < 0

Steps:

 Find middle point c= (a + b)/2 . 
 If f(c) == 0, then c is the root of the solution. 
 Else  f(c) != 0

 If value f(a)*f(c) < 0 then root lies between a and c. So we recur for a and c 
 Else If f(b)*f(c) < 0 then root lies between b and c. So we recur b and c. 
 Else given function doesn’t follow one of assumptions.  



Since root may be a floating point number, we repeat above steps while difference between a and b is less than a value ? (A very small value). 

Below is implementation of above steps.

C++







filter_none

Program for Method Of False Position


Given a function f(x) on floating number x and two numbers ‘a’ and ‘b’ such that f(a)*f(b) < 0 and f(x) is continuous in [a, b].  Here f(x) represents algebraic or transcendental equation. Find root of function in interval [a, b] (Or find a value of x such that f(x) is 0).


Input: A function of x, for example x3 – x2 + 2.     
       And two values: a = -200 and b = 300 such that
       f(a)*f(b) < 0, i.e., f(a) and f(b) have
       opposite signs.
Output: The value of root is : -1.00
        OR any other value close to root.

We strongly recommend to refer below post as a prerequisite of this post.
Solution of Algebraic and Transcendental Equations | Set 1 (The Bisection Method)
In this post The Method Of False Position is discussed.  This method is also known as Regula Falsi or The Method of Chords. 





Similarities with Bisection Method:

 Same Assumptions: This method also assumes that function is continuous in [a, b] and given two numbers 'a' and 'b' are such that f(a) * f(b) < 0. 
Always Converges: like Bisection, it always converges, usually considerably faster than Bisection--but sometimes very much more slowly than Bisection. 

Differences with Bisection Method:
It differs in the fact that we make a chord joining the two points [a, f(a)] and [b, f(b)]. We consider the point at which the chord touches the x axis and named it as c. 
Steps:

 Write equation of the line connecting the two points.
y – f(a) =  ( (f(b)-f(a))/(b-a) )*(x-a)

Now we have to find the point which touches x axis. 
For that we put y = 0.

so x = a - (f(a)/(f(b)-f(a))) * (b-a)
   x = (a*f(b) - b*f(a)) / (f(b)-f(a)) 

This will be our c that is c = x. 

 If f(c) == 0, then c is the root of the solution. 
 Else  f(c) != 0

 If value f(a)*f(c) < 0 then root lies between a and c. So we recur for a and c 
 Else If f(b)*f(c) < 0 then root lies between b and c. So we recur b and c. 
 Else given function doesn't follow one of assumptions.  



Since root may be a floating point number and may converge very slow in worst case, we iterate for a very large number of times such that the answer becomes closer to the root.

Following is the implementation.

C++







filter_none

Program for Newton Raphson Method


Given a function f(x) on floating number x and an initial guess for root, find root of function in interval. Here f(x) represents algebraic or transcendental equation. 
For simplicity, we have assumed that derivative of function is also provided as input.
Example:





Input: A function of x (for example x3 – x2 + 2),
       derivative function of x (3x2 – 2x for above example)
       and an initial guess x0 = -20
Output: The value of root is : -1.00
        OR any other value close to root.
We have discussed below methods to find root in set 1 and set 2
Set 1: The Bisection Method
Set 2: The Method Of False Position
Comparison with above two methods:

In previous methods, we were given an interval. Here we are required an initial guess value of root.
The previous two methods are guaranteed to converge, Newton Rahhson may not converge in some cases.
Newton Raphson method requires derivative. Some functions may be difficult to
impossible to differentiate.
For many problems, Newton Raphson method converges faster than the above two methods.
Also, it can identify repeated roots, since it does not look for changes in the sign of f(x) explicitly

The formula:
Starting from initial guess x1, the Newton Raphson method uses below formula to find next value of x, i.e., xn+1 from previous value xn.


Algorithm:
Input:  initial x, func(x), derivFunc(x)
Output: Root of Func()

Compute values of func(x) and derivFunc(x) for given initial x
Compute h: h = func(x) / derivFunc(x) 
While h is greater than allowed error ε

h = func(x) / derivFunc(x)
x = x – h



Below is the implementation of above algorithm.

C++







filter_none

Find the element that appears once



Given an array where every element occurs three times, except one element which occurs only once.  Find the element that occurs once.  Expected time complexity is O(n) and O(1) extra space.
Examples :

Input: arr[] = {12, 1, 12, 3, 12, 1, 1, 2, 3, 3}
Output: 2
In the given array all element appear three times except 2 which appears once.
Input: arr[] = {10, 20, 10, 30, 10, 30, 30}
Output: 20
In the given array all element appear three times except 20 which appears once.









Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.

We can use sorting to do it in O(nLogn) time.  We can also use hashing, it has the worst case time complexity of O(n), but requires extra space.
The idea is to use bitwise operators for a solution that is O(n) time and uses O(1) extra space.   The solution is not easy like other XOR based solutions, because all elements appear odd number of times here.  The idea is taken from here.
Run a loop for all elements in array.  At the end of every iteration, maintain following two values.
ones:  The bits that have appeared 1st time or 4th time or 7th time .. etc.
twos:   The bits that have appeared 2nd time or 5th time or 8th time .. etc.
Finally, we return the value of ‘ones’
How to maintain the values of ‘ones’ and ‘twos’?
‘ones’ and ‘twos’ are initialized as 0. For every new element in array, find out the common set bits in the new element and previous value of ‘ones’.  These common set bits are actually the bits that should be added to ‘twos’. So do bitwise OR of the common set bits with ‘twos’.  ‘twos’ also gets some extra bits that appear third time.  These  extra bits are removed later.
Update ‘ones’ by doing XOR of new element with previous value of ‘ones’. There may be some bits which appear 3rd time.  These extra bits are also removed later.
Both ‘ones’ and ‘twos’ contain those extra bits which appear 3rd time.  Remove these extra bits by finding out common set bits in ‘ones’ and ‘twos’.






Below is the implementation of above approach:

C++







filter_none

Detect if two integers have opposite signs


Given two signed integers, write a function that returns true if the signs of given integers are different, otherwise false.  For example, the function should return true -1 and +100, and should return false for -100 and -200.  The function should not use any of the arithmetic operators. 
Let the given integers be x and y.  The sign bit is 1 in negative numbers, and 0 in positive numbers.  The XOR of x and y will have the sign bit as 1 iff they have opposite sign. In other words, XOR of x and y will be negative number number iff x and y have opposite signs.  The following code use this logic.

C++







filter_none

Count total set bits in all numbers from 1 to n


Given a positive integer n, count the total number of set bits in binary representation of all numbers from 1 to n.  
Examples:
Input: n = 3
Output:  4

Input: n = 6
Output: 9

Input: n = 7
Output: 12

Input: n = 8
Output: 13


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Source: Amazon Interview Question 





Method 1 (Simple)
A simple solution is to run a loop from 1 to n and sum the count of set bits in all numbers from 1 to n.

C++







filter_none

Swap bits in a given number


Given a number x and two positions (from the right side) in the binary representation of x, write a function that swaps n bits at given two positions and returns the result. It is also given that the two sets of bits do not overlap.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Let p1 and p2 be the two given positions.
Example 1
Input:
x = 47 (00101111)
p1 = 1 (Start from the second bit from the right side)
p2 = 5 (Start from the 6th bit from the right side)
n = 3 (No of bits to be swapped)
Output:
227 (11100011)
The 3 bits starting from the second bit (from the right side) are
swapped with 3 bits starting from 6th position (from the right side) 





Example 2
Input:
x = 28 (11100)
p1 = 0 (Start from first bit from right side)
p2 = 3 (Start from 4th bit from right side)
n = 2 (No of bits to be swapped)
Output:
7 (00111)
The 2 bits starting from 0th position (from right side) are
swapped with 2 bits starting from 4th position (from right side) 
Solution
We need to swap two sets of bits. XOR can be used in a similar way as it is used to swap 2 numbers.  Following is the algorithm.
1) Move all bits of the first set to the rightmost side
   set1 =  (x >> p1) & ((1U << n) - 1)
Here the expression (1U << n) - 1 gives a number that 
contains last n bits set and other bits as 0. We do & 
with this expression so that bits other than the last 
n bits become 0.
2) Move all bits of second set to rightmost side
   set2 =  (x >> p2) & ((1U << n) - 1)
3) XOR the two sets of bits
   xor = (set1 ^ set2) 
4) Put the xor bits back to their original positions. 
   xor = (xor << p1) | (xor << p2)
5) Finally, XOR the xor with original number so 
   that the two sets are swapped.
   result = x ^ xor

Implementation:

C++







filter_none

Add two numbers without using arithmetic operators


Write a function Add() that returns sum of two integers. The function should not use any of the arithmetic operators (+, ++, –, -, .. etc).
Sum of two bits can be obtained by performing XOR (^) of the two bits. Carry bit can be obtained by performing AND (&) of two bits.
Above is simple Half Adder logic that can be used to add 2 single bits.  We can extend this logic for integers. If x and y don’t have set bits at same position(s), then bitwise XOR (^) of x and y gives the sum of x and y. To incorporate common set bits also, bitwise AND (&) is used. Bitwise AND of x and y gives all carry bits. We calculate (x & y) << 1 and add it to x ^ y to get the required result.

C++







filter_none

Smallest of three integers without comparison operators


Write a program to find the smallest of three integers, without using any of the comparison operators. 
Let 3 input numbers be x, y and z.
Method 1 (Repeated Subtraction)
Take a counter variable c and initialize it with 0.  In a loop, repeatedly subtract x, y and z by 1 and increment c.  The number which becomes 0 first is the smallest.  After the loop terminates, c will hold the minimum of 3.

C++












filter_none

A Boolean Array Puzzle


Input: A array arr[] of two elements having value 0 and 1
Output:  Make both elements 0. 
Specifications: Following are the specifications to follow.
1) It is guaranteed that one element is 0 but we do not know its position.
2) We can’t say about another element it can be 0 or 1.
3) We can only complement array elements, no other operation like and, or, multi, division, …. etc.
4) We can’t use if, else and loop constructs.
5) Obviously, we can’t directly assign 0 to array elements.





There are several ways we can do it as we are sure that always one Zero is there.  Thanks to devendraiiit for suggesting following 3 methods.
Method 1

C++







filter_none

Program to count number of set bits in an (big) array


Given an integer array of length N (an arbitrarily large number). How to count number of set bits in the array?
The simple approach would be, create an efficient method to count set bits in a word (most prominent size, usually equal to bit length of processor), and add bits from individual elements of array.
Various methods of counting set bits of an integer exists, see this for example. These methods run at best O(logN) where N is number of bits. Note that on a processor N is fixed, count can be done in O(1) time on 32 bit machine irrespective of total set bits. Overall, the bits in array can be computed in O(n) time, where ‘n’ is array size.





However, a table look up will be more efficient method when array size is large. Storing table look up that can handle 232 integers will be impractical.
The following code illustrates simple program to count set bits in a randomly generated 64 K integer array. The idea is to generate a look up for first 256 numbers (one byte), and break every element of array at byte boundary. A meta program using C/C++ preprocessor generates the look up table for counting set bits in a byte.
The mathematical derivation behind meta program is evident from the following table (Add the column and row indices to get the number, then look into the table to get set bits in that number. For example, to get set bits in 10, it can be extracted from row named as 8 and column named as 2),
   0, 1, 2, 3
 0 - 0, 1, 1, 2 -------- GROUP_A(0)
 4 - 1, 2, 2, 3 -------- GROUP_A(1)
 8 - 1, 2, 2, 3 -------- GROUP_A(1)
12 - 2, 3, 3, 4 -------- GROUP_A(2)
16 - 1, 2, 2, 3 -------- GROUP_A(1)
20 - 2, 3, 3, 4 -------- GROUP_A(2)
24 - 2, 3, 3, 4 -------- GROUP_A(2)
28 - 3, 4, 4, 5 -------- GROUP_A(3) ... so on
From the table, there is a pattern emerging in multiples of 4, both in the table as well as in the group parameter. The sequence can be generalized as shown in the code.
Complexity:
All the operations takes O(1) except iterating over the array. The time complexity is O(n) where ‘n’ is size of array. Space complexity depends on the meta program that generates look up.
Code:

C++







filter_none

Next higher number with same number of set bits


Given a number x, find next number with same number of 1 bits in it’s binary representation.
For example, consider x = 12, whose binary representation is 1100 (excluding leading zeros on 32 bit machine). It contains two logic 1 bits. The next higher number with two logic 1 bits is 17 (100012).
Algorithm:





When we observe the binary sequence from 0 to 2n – 1 (n is # of bits), right most bits (least significant) vary rapidly than left most bits. The idea is to find right most string of 1’s in x, and shift the pattern to right extreme, except the left most bit in the pattern. Shift the left most bit in the pattern (omitted bit) to left part of x by one position. An example makes it more clear,
x = 156
10
x = 10011100
(2)
10011100
00011100 - right most string of 1's in x
00000011 - right shifted pattern except left most bit ------> [A]
00010000 - isolated left most bit of right most 1's pattern
00100000 - shiftleft-ed the isolated bit by one position ------> [B]
10000000 - left part of x, excluding right most 1's pattern ------> [C]
10100000 - add B and C (OR operation) ------> [D]
10100011 - add A and D which is required number 163
(10)
After practicing with few examples, it easy to understand. Use the below given program for generating more sets.
Program Design:
We need to note few facts of binary numbers. The expression x & -x will isolate right most set bit in x (ensuring x will use 2’s complement form for negative numbers). If we add the result to x, right most string of 1’s in x will be reset, and the immediate ‘0’ left to this pattern of 1’s will be set, which is part [B] of above explanation. For example if x = 156, x & -x will result in 00000100, adding this result to x yields 10100000 (see part D). We left with the right shifting part of pattern of 1’s (part A of above explanation).
There are different ways to achieve part A. Right shifting is essentially a division operation. What should be our divisor? Clearly, it should be multiple of 2 (avoids 0.5 error in right shifting), and it should shift the right most 1’s pattern to right extreme. The expression (x & -x) will serve the purpose of divisor. An EX-OR operation between the number X and expression which is used to reset right most bits, will isolate the rightmost 1’s pattern.
A Correction Factor:
Note that we are adding right most set bit to the bit pattern. The addition operation causes a shift in the bit positions. The weight of binary system is 2, one shift causes an increase by a factor of 2. Since the increased number (rightOnesPattern in the code) being used twice, the error propagates twice. The error needs to be corrected. A right shift by 2 positions will correct the result.




The popular name for this program is same number of one bits.

C++







filter_none

Optimization Techniques | Set 1 (Modulus)


Modulus operator is costly.
The modulus operator (%) in various languages is costly operation. Ultimately every operator/operation must result in processor instructions. Some processors won’t have modulus instruction at hardware level, in such case the compilers will insert stubs (predefined functions) to perform modulus. It impacts performance.
There is simple technique to extract remainder when a number is divided by another number (divisor) that is power of 2? A number that is an exact power of 2 will have only one bit set in it’s binary representation. Consider the following powers of 2 and their binary representations





2 – 10
4 – 100
8 – 1000
16  – 10000
Note those zeros in red color, they contribute to remainder in division operation. We can get mask for those zeros by decrementing the divisor by 1.
Generalizing the above pattern, a number that can be written in 2n form will have only one bit set followed by n zeros on the right side of 1. When a number (N) divided by (2n), the bit positions corresponding to the above mentioned zeros will contribute to the remainder of division operation. An example can make it clear,

N = 87 (1010111 – binary form)

N%2 = N & (2-1) = 1010111 & 1 = 1 = 1
N%4 = N & (4-1) = 1010111 & 11 = 11 = 3

N%8 = N & (8-1) = 1010111 & 111 = 111 = 7

N%16 = N & (16-1) = 1010111 & 1111 = 111 = 7
N%32 = N & (32-1) = 1010111 & 11111 = 10111 = 23

Modulus operation over exact powers of 2 is simple and faster bitwise ANDing. This is the reason, programmers usually make buffer length as powers of 2.
Note that the technique will work only for divisors that are powers of 2.




An Example:
Implementation of circular queue (ring buffer) using an array. Omitting one position in the circular buffer implementation can make it easy to distinguish between full and empty conditions. When the buffer reaches SIZE-1, it needs to wrap back to initial position. The wrap back operation can be simple AND operation if the buffer size is power of 2. If we use any other size, we would need to use modulus operation.
Note:
Per experts comments, premature optimization is an evil. The optimization techniques provided are to fine tune your code after finalizing design strategy, algorithm, data structures and implementation. We recommend to avoid them at the start of code development. Code readability is key for maintenance.
Thanks to Venki for writing the above article. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Compute modulus division by a power-of-2-numberSpace optimization using bit manipulationsCheck a number is odd or even without modulus operatorAppend two elements to make the array satisfy the given conditionFind the number obtained after concatenation of binary representation of M and NInvert the Kth most significant bit of NMaximize the number by flipping at most K bitsMinimum count of Full Binary Trees such that the count of leaves is NWinner in the Rock-Paper-Scissor game using Bit manipulationFind the value of N XOR'ed to itself K timesFind the minimum spanning tree with alternating colored edgesFind the count of distinct numbers in a rangeConvert Decimal To Hexa-Decimal including negative numbersFind a number X such that (X XOR A) is minimum and the count of set bits in X and B are equal

Article Tags : Bit Magic
Practice Tags : Bit Magic 

thumb_up
2



To-do

Done



2.6


Based on 19 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Add 1 to a given number


Write a program to add one to a given number. The use of operators like ‘+’,  ‘-‘,  ‘*’,  ‘/’, ‘++’, ‘–‘ …etc are not allowed.
Examples:
Input:  12
Output: 13

Input:  6
Output: 7

This question can be approached by using some bit magic. Following are different methods to achieve the same using bitwise operators.
Method 1
To add 1 to a number x (say 0011000111), flip all the bits after the rightmost 0 bit (we get 0011000000).  Finally, flip the rightmost 0 bit also (we get 0011001000) to get the answer.

C++












filter_none

Multiply a given Integer with 3.5


Given a integer x, write a function that multiplies x with 3.5 and returns the integer result.  You are not allowed to use %, /, *. 
Examples :
Input: 2
Output: 7

Input: 5
Output: 17 (Ignore the digits after decimal point)

Solution:
1. We can get x*3.5 by adding 2*x, x and x/2.  To calculate 2*x, left shift x by 1 and to calculate x/2, right shift x by 2.

C++







filter_none

Turn off the rightmost set bit


Write a program that unsets the rightmost set bit of an integer. 
Examples :
Input:  12 (00...01100)
Output: 8 (00...01000)

Input:  7 (00...00111)
Output: 6 (00...00110)


Recommended: Please try your approach on {IDE} first, before moving on to the solution.

Let the input number be n.   n-1 would have all the bits flipped after the rightmost set bit (including the set bit).  So, doing n&(n-1) would give us the required result.

C++












filter_none

Find whether a given number is a power of 4 or not


Given an integer n, find whether it is a power of 4 or not.
Example :
Input : 16
Output : 16 is a power of 4

Input : 20
Output : 20 is not a power of 4

We strongly recommend that you click here and practice it, before moving on to the solution.
1. A simple method is to take log of the given number on base 4, and if we get an integer then number is power of 4. 





2. Another solution is to keep dividing the number by 4, i.e, do n = n/4 iteratively. In any iteration, if n%4 becomes non-zero and n is not 1 then n is not a power of 4, otherwise n is a power of 4.

C++







filter_none

Compute the integer absolute value (abs) without branching


We need not to do anything if a number is positive. We want to change only negative numbers. Since  negative numbers are stored in 2’s complement form, to get the absolute value of a negative number we have to toggle bits of the number and add 1 to the result.
For example -2 in a 8 bit system is stored as follows  1 1 1 1 1 1 1 0 where leftmost bit is the sign bit.  To get the absolute value of a negative number, we have to toggle all bits and add 1 to the toggled number  i.e, 0 0 0 0 0 0 0 1 + 1 will give the absolute value of  1 1 1 1 1 1 1 0.  Also remember, we need to do these operations only if the number is negative (sign bit is set).
Method 1
1) Set the mask as right shift of integer by 31 (assuming integers are stored using 32 bits). 





 mask = n>>31 
2) For negative numbers, above step sets mask as 1 1 1 1 1 1 1 1 and 0 0 0 0 0 0 0 0 for positive numbers. Add the mask to the given number.
 mask + n 
3) XOR of mask +n and mask gives the absolute value.       
 (mask + n)^mask 
Implementation:

C++







filter_none

Compute modulus division by a power-of-2-number


Compute n modulo d without division(/) and modulo(%) operators, where d is a power of 2 number. 
Let ith bit from right is set in d. For getting n modulus d, we just need to return 0 to i-1 (from right) bits of n as they are and other bits as 0.
For example if n = 6 (00..110) and d = 4(00..100).  Last set bit in d is at position 3 (from right side). So we need to return last two bits of n as they are and other bits as 0, i.e., 00..010. 





Now doing it is so easy, guess it….
Yes, you have guessing it right. See the below program.

C++







filter_none

Compute the minimum or maximum of two integers without branching


On some rare machines where branching is expensive, the below obvious approach to find minimum can be slow as it uses branching.





filter_none

Rotate bits of a number


Bit Rotation: A rotation (or circular shift) is an operation similar to shift except that the bits that fall off at one end are put back to the other end. 
In left rotation, the bits that fall off at left end are put back at right end. 
In right rotation, the bits that fall off at right end are put back at left end.






Recommended: Please try your approach on PRACTICE first, before moving on to the solution.

Example:
Let n is stored using 8 bits. Left rotation of n = 11100101 by 3 makes n = 00101111 (Left shifted by 3 and first 3 bits are put back in last ).  If n is stored using 16 bits or 32 bits then left rotation of n (000…11100101)  becomes 00..0011100101000.
Right rotation of n = 11100101 by 3 makes n = 10111100 (Right shifted by 3 and last 3 bits are put back in first ) if n is stored using 8 bits. If n is stored using 16 bits or 32 bits then right rotation of n (000…11100101) by 3 becomes 101000..0011100.

C++







filter_none

Find the two non-repeating elements in an array of repeating elements


Asked by SG
Given an array in which all numbers except two are repeated once. (i.e. we have 2n+2 numbers and n numbers are occurring twice and remaining two have occurred once). Find those two numbers in the most efficient way.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Find the Number Occurring Odd Number of Times


Given an array of positive integers. All numbers occur even number of times except one number which occurs odd number of times. Find the number in O(n) time & constant space.
Examples :
Input : arr = {1, 2, 3, 2, 3, 1, 3}
Output : 3

Input : arr = {5, 7, 2, 7, 5, 2, 5}
Output : 5



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Check for Integer Overflow


Write a “C” function,  int addOvf(int* result, int a, int b) If there is no overflow, the function places the resultant = sum a+b in “result” and returns 0. Otherwise it returns -1.   The solution of casting to long and adding to find detecting the overflow is not allowed.

Method 1
There can be overflow only if signs of two numbers are same, and sign of sum is opposite to the signs of numbers.





1)  Calculate sum
2)  If both numbers are positive and sum is negative then return -1
     Else 
        If both numbers are negative and sum is positive then return -1
        Else return 0


C++






filter_none

Little and Big Endian Mystery



What are these?
Little and big endian are two ways of storing multibyte data-types ( int, float, etc). In little endian machines, last byte of binary representation of the multibyte data-type is stored first. On the other hand, in big endian machines, first byte of binary representation of the multibyte data-type is stored first.

Suppose integer is stored as 4 bytes (For those who are using DOS based compilers such as C++ 3.0 , integer is 2 bytes) then a variable x with value 0x01234567 will be stored as following.


Memory representation of integer ox01234567 inside Big and little endian machines






How to see memory representation of multibyte data types on your machine?
Here is a sample C code that shows the byte representation of int, float and pointer. 










filter_none

Write an Efficient C Program to Reverse Bits of a Number


Given an unsigned integer, reverse all bits of it and return the number with reversed bits.
Input : n = 1
Output : 2147483648  
On a machine with size of unsigned
bit as 32. Reverse of 0....001 is
100....0.

Input : n = 2147483648
Output : 1                          



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count set bits in an integer



Write an efficient program to count number of 1s in binary representation of an integer.
Examples :
Input : n = 6
Output : 2
Binary representation of 6 is 110 and has 2 set bits

Input : n = 13
Output : 3
Binary representation of 13 is 1101 and has 3 set bits




Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Count number of bits to be flipped to convert A to B


Given two numbers ‘a’ and b’. Write a program to count number of bits needed to be flipped to convert ‘a’ to ‘b’. 
Example : 
Input : a = 10, b = 20
Output : 4
Binary representation of a is 00001010
Binary representation of b is 00010100
We need to flip highlighted four bits in a
to make it b.

Input : a = 7, b = 10
Output : 3
Binary representation of a is 00000111
Binary representation of b is 00001010
We need to flip highlighted three bits in a
to make it b.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

  1. Calculate XOR of A and B.      
        a_xor_b = A ^ B
  2. Count the set bits in the above 
     calculated XOR result.
        countSetBits(a_xor_b)

XOR of two number will have set bits only at those places where A differs from B.

C++












filter_none

Smallest power of 2 greater than or equal to n


Write a function that, for a given no n, finds a number p which is greater than or equal to n and is a smallest power of 2.    
Examples :
    Input : n = 5
    Output: 8     

    Input  : n = 17
    Output : 32     

    Input  : n = 32
    Output : 32     



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Write an Efficient Method to Check if a Number is Multiple of 3


The very first solution that comes to our mind is the one that we learned in school.  If sum of digits in a number is multiple of 3 then number is multiple of 3 e.g., for 612 sum of digits is 9 so it’s a multiple of 3. But this solution is not efficient.  You have to get all decimal digits one by one, add them and then check if sum is multiple of 3.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

There is a pattern in binary representation of the number that can be used to find if number is a multiple of 3. If difference between count of odd set bits (Bits set at odd positions) and even set bits is multiple of 3 then is the number.
Example : 23 (00..10111)
1) Get count of all set bits at odd positions (For 23 it’s 3).
2) Get count of all set bits at even positions (For 23 it’s 1).
3) If difference of above two counts is a multiple of 3 then number is also a multiple of 3. 





(For 23 it’s 2 so 23 is not a multiple of 3)
Take some more examples like 21, 15, etc…
Algorithm: isMutlipleOf3(n)
1) Make n positive if n is negative.
2) If number is 0 then return 1
3) If number is 1 then return 0
4) Initialize: odd_count = 0, even_count = 0
5) Loop while n != 0
    a) If rightmost bit is set then increment odd count.
    b) Right-shift n by 1 bit
    c) If rightmost bit is set then increment even count.
    d) Right-shift n by 1 bit
6) return isMutlipleOf3(odd_count - even_count)

Proof:
Above can be proved by taking the example of 11 in decimal numbers. (In this context 11 in decimal numbers is same as 3 in binary numbers)
If difference between sum of odd digits and even digits is multiple of 11 then decimal number is multiple of 11. Let’s see how.
Let’s take the example of 2 digit numbers in decimal
AB = 11A -A + B = 11A + (B – A)
So if (B – A) is a multiple of 11 then is AB.
Let us take 3 digit numbers.
ABC = 99A + A + 11B – B + C = (99A + 11B) + (A + C – B)
So if (A + C – B) is a multiple of 11 then is (ABC)
Let us take 4 digit numbers now.
ABCD = 1001A + D + 11C – C + 999B + B – A
= (1001A – 999B + 11C) + (D + B – A -C )
So, if (B + D – A – C) is a multiple of 11 then is ABCD.
This can be continued for all decimal numbers.
Above concept can be proved for 3 in binary numbers in the same way.

Time Complexity:  O(logn)
Program:

C++







filter_none

Program to find parity


Parity:  Parity of a number refers to whether it contains an odd or even number of 1-bits. The number has “odd parity”, if it contains odd number of 1-bits and is “even parity” if it contains even number of 1-bits.
Main idea of the below solution is – Loop while n is not 0 and in loop unset one of the set bits and invert parity.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Algorithm: getParity(n)
1. Initialize parity = 0
2. Loop while n != 0      
      a. Invert parity 
             parity = !parity
      b. Unset rightmost set bit
             n = n & (n-1)
3. return parity

Example:
 Initialize: n = 13 (1101)   parity = 0

n = 13 & 12  = 12 (1100)   parity = 1
n = 12 & 11 = 8  (1000)   parity = 0
n = 8 & 7 = 0  (0000)    parity = 1

Program:

C++







filter_none

Efficient way to multiply with 7


We can multiply a number by 7 using bitwise operator.  First left shift the number by 3 bits (you will get 8n) then subtract the original numberfrom the shifted number and return the difference (8n – n).


Program:

CPP






filter_none

Program to find whether a no is power of two


Given a positive integer, write a function to find if it is a power of two or not.
Examples :
Input : n = 4
Output : Yes
22 = 4

Input : n = 7
Output : No

Input : n = 32
Output : Yes
25 = 32


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

1. A simple method for this is to simply take the log of the number on base 2 and if you get an integer then number is power of 2.

C++












filter_none

Position of rightmost set bit


Write a one line function to return position of first 1 from right to left, in binary  representation of an Integer.
I/P    18,   Binary Representation 010010
O/P   2
I/P    19,   Binary Representation 010011
O/P   1




Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Binary representation of a given number


Write a program to print Binary representation of a given number. 

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Source: Microsoft Interview Set-3 
Method 1: Iterative
For any number, we can check whether its ‘i’th bit is 0(OFF) or 1(ON) by bitwise ANDing it with “2^i” (2 raise to i).





1) Let us take number 'NUM' and we want to check whether it's 0th bit is ON or OFF    
    bit = 2 ^ 0 (0th bit)
    if  NUM & bit == 1 means 0th bit is ON else 0th bit is OFF

2) Similarly if we want to check whether 5th bit is ON or OFF    
    bit = 2 ^ 5 (5th bit)
    if NUM & bit == 1 means its 5th bit is ON else 5th bit is OFF.
Let us take unsigned integer (32 bit), which consist of 0-31 bits. To print binary representation of unsigned integer, start from 31th bit, check whether 31th bit is ON or OFF, if it is ON print “1” else print “0”. Now check whether 30th bit is ON or OFF, if it is ON print “1” else print “0”, do this for all bits from 31 to 0, finally we will get binary representation of number.





filter_none

Swap all odd and even bits


Given an unsigned integer, swap all odd bits with even bits. For example, if the given number is 23 (00010111), it should be converted to 43 (00101011). Every even position bit is swapped with adjacent bit on right side (even position bits are highlighted in binary representation of 23), and every odd position bit is swapped with adjacent on left side.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

If we take a closer look at the example, we can observe that we basically need to right shift (>>) all even bits (In the above example, even bits of 23 are highlighted) by 1 so that they become odd bits (highlighted in 43), and left shift (<<) all odd bits by 1 so that they become even bits.  The following solution is based on this observation. The solution assumes that input number is stored using 32 bits.
Let the input number be x
1) Get all even bits of x by doing bitwise and of x with  0xAAAAAAAA.  The number  0xAAAAAAAA is a 32 bit number with all even bits set as 1 and all odd bits as 0.
2) Get all odd bits of x by doing bitwise and of x with  0x55555555.  The number  0x55555555 is a 32 bit number with all odd bits set as 1 and all even bits as 0.
3) Right shift all even bits.
4) Left shift all odd bits.
5) Combine new even and odd bits and return.

C++












filter_none

Find position of the only set bit


Given a number having only one ‘1’ and all other ’0’s in its binary representation, find position of the only set bit.  Source: Microsoft Interview | 18


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Karatsuba algorithm for fast multiplication using Divide and Conquer algorithm


Given two binary strings that represent value of two integers, find the product of two strings. For example, if the first bit string is “1100” and second bit string is “1010”, output should be 120.
For simplicity, let the length of two strings be same and be n.
A Naive Approach is to follow the process we study in school. One by one take all bits of second number and multiply it with all bits of first number. Finally add all multiplications. This algorithm takes O(n^2) time.






Using Divide and Conquer, we can multiply two integers in less time complexity. We divide the given numbers in two halves. Let the given numbers be X and Y.
For simplicity let us assume that n is even
X =  Xl*2n/2 + Xr    [Xl and Xr contain leftmost and rightmost n/2 bits of X]
Y =  Yl*2n/2 + Yr    [Yl and Yr contain leftmost and rightmost n/2 bits of Y]
The product XY can be written as following.
XY = (Xl*2n/2 + Xr)(Yl*2n/2 + Yr)
   = 2n XlYl + 2n/2(XlYr + XrYl) + XrYr
If we take a look at the above formula, there are four multiplications of size n/2, so we basically divided the problem of size n into four sub-problems of size n/2. But that doesn’t help because solution of recurrence T(n) = 4T(n/2) + O(n) is O(n^2). The tricky part of this algorithm is to change the middle two terms to some other form so that only one extra multiplication would be sufficient. The following is tricky expression for middle two terms.
XlYr + XrYl = (Xl + Xr)(Yl + Yr) - XlYl- XrYr
So the final value of XY becomes
XY = 2n XlYl + 2n/2 * [(Xl + Xr)(Yl + Yr) - XlYl - XrYr] + XrYr
With above trick, the recurrence becomes T(n) = 3T(n/2) + O(n) and solution of this recurrence is O(n1.59).
What if the lengths of input strings are different and are not even?  To handle the different length case, we append 0’s in the beginning. To handle odd length, we put floor(n/2) bits in left half and ceil(n/2) bits in right half. So the expression for XY changes to following.
XY = 22ceil(n/2) XlYl + 2ceil(n/2) * [(Xl + Xr)(Yl + Yr) - XlYl - XrYr] + XrYr
The above algorithm is called Karatsuba algorithm and it can be used for any base.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Following is C++ implementation of above algorithm.









filter_none

How to swap two numbers without using a temporary variable?



Given two variables, x and y, swap two variables without using a third variable.

Method 1 (Using Arithmetic Operators)
The idea is to get sum in one of the two given numbers.  The numbers can then be swapped using the sum and subtraction from sum.

C++







filter_none

Check if a number is multiple of 9 using bitwise operators


Given a number n, write a function that returns true if n is divisible by 9, else false. The most simple way to check for n’s divisibility by 9 is to do n%9.  
Another method is to sum the digits of n.  If sum of digits is multiple of 9, then n is multiple of 9.
The above methods are not bitwise operators based methods and require use of % and /.
The bitwise operators are generally faster than modulo and division operators. Following is a bitwise operator based method to check divisibility by 9.

C++







filter_none

Swap two nibbles in a byte


A nibble is a four-bit aggregation, or half an octet. There are two nibbles in a byte.
Given a byte, swap the two nibbles in it. For example 100 is be represented as 01100100 in a byte (or 8 bits).  The two nibbles are (0110) and (0100). If we swap the two nibbles, we get 01000110 which is 70 in decimal.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

To swap the nibbles, we can use bitwise &, bitwise ” operators. A byte can be represented using a unsigned char in C as size of char is 1 byte in a typical C compiler.
Below is the implementation of above idea.

C++







filter_none

How to turn off a particular bit in a number?


Difficulty Level: Rookie
Given a number n and a value k, turn of the k’th bit in n. 
Examples:





Input:  n = 15, k = 1
Output: 14

Input:  n = 15, k = 2
Output: 13

Input:  n = 15, k = 3
Output: 11

Input:  n = 15, k = 4
Output: 7

Input:  n = 15, k >= 5
Output: 15 
The idea is to use bitwise <<, & and ~ operators.  Using expression "~(1 << (k – 1))“,  we get a number which has all bits set, except the k’th bit.  If we do bitwise & of this expression with n, we get a number which has all bits same as n except the k’th bit which is 0.  
Below is the implementation of above idea.

C++







filter_none

Check if binary representation of a number is palindrome


Given an integer ‘x’, write a C function that returns true if binary representation of x is palindrome else return false.
For example a numbers with binary representation as 10..01 is palindrome and number with binary representation as 10..00 is not palindrome.
The idea is similar to checking a string is palindrome or not.  We start from leftmost and rightmost bits and compare bits one by one. If we find a mismatch, then return false. 







Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Graph and its representations


Graph is a data structure that consists of following two components:
1. A finite set of vertices also called as nodes.
2. A finite set of ordered pair of the form (u, v) called as edge. The pair is ordered because (u, v) is not same as (v, u) in case of a directed graph(di-graph). The pair of the form (u, v) indicates that there is an edge from vertex u to vertex v. The edges may contain weight/value/cost.
Graphs are used to represent many real-life applications: Graphs are used to represent networks. The networks may include paths in a city or telephone network or circuit network. Graphs are also used in social networks like linkedIn, Facebook. For example, in Facebook, each person is represented with a vertex(or node). Each node is a structure and contains information like person id, name, gender and locale.  See this for more applications of graph. 
Following is an example of an undirected graph with 5 vertices.


Breadth First Search or BFS for a Graph



Breadth First Traversal (or Search) for a graph is similar to Breadth First Traversal of a tree (See method 2 of this post). The only catch here is, unlike trees, graphs may contain cycles, so we may come to the same node again. To avoid processing a node more than once, we use a boolean visited array.  For simplicity, it is assumed that all vertices are reachable from the starting vertex.
For example, in the following graph, we start traversal from vertex 2. When we come to vertex 0, we look for all adjacent vertices of it. 2 is also an adjacent vertex of 0. If we don’t mark visited vertices, then 2 will be processed again and it will become a non-terminating process. A Breadth First Traversal of the following graph is 2, 0, 3, 1.



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Depth First Search or DFS for a Graph



Depth First Traversal (or Search) for a graph is similar to Depth First Traversal of a tree.  The only catch here is, unlike trees, graphs may contain cycles, so we may come to the same node again. To avoid processing a node more than once, we use a boolean visited array. 
For example, in the following graph, we start traversal from vertex 2. When we come to vertex 0, we look for all adjacent vertices of it. 2 is also an adjacent vertex of 0. If we don’t mark visited vertices, then 2 will be processed again and it will become a non-terminating process. A Depth First Traversal of the following graph is 2, 0, 1, 3.  

See this post for all applications of Depth First Traversal.
Following are  implementations of simple Depth First Traversal. The C++ implementation uses adjacency list representation of graphs. STL‘s list container is used to store lists of adjacent nodes.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Applications of Depth First Search



Depth-first search (DFS) is an algorithm (or technique) for traversing a graph. 
Following are the problems that use DFS as a building block.
1) For a weighted graph, DFS traversal of the graph produces the minimum spanning tree and all pair shortest path tree.





2) Detecting cycle in a graph 
A graph has cycle if and only if we see a back edge during DFS.  So we can run DFS for the graph and check for back edges.  (See this  for details)
3) Path Finding
We can specialize the DFS algorithm to find a path between two given vertices u and z.
i) Call DFS(G, u) with u as the start vertex.
ii) Use a stack S to keep track of the path between the start vertex and the current vertex.
iii) As soon as destination vertex z is encountered, return the path as the
contents of the stack
See this for details.
4) Topological Sorting
Topological Sorting is mainly used for scheduling jobs from the given dependencies among jobs. In computer science, applications of this type arise in instruction scheduling, ordering of formula cell evaluation when recomputing formula values in spreadsheets, logic synthesis, determining the order of compilation tasks to perform in makefiles, data serialization, and resolving symbol dependencies in linkers [2].
5) To test if a graph is bipartite
We can augment either BFS or DFS when we first discover a new vertex, color it opposited its parents, and for each other edge, check it doesn’t link two vertices of the same color. The first vertex in any connected component can be red or black!  See this for details.
6) Finding Strongly Connected Components

Detect Cycle in a Directed Graph



Given a directed graph, check whether the graph contains a cycle or not.  Your function should return true if the given graph contains at least one cycle, else return false.  For example, the following graph contains three cycles 0->2->0,  0->1->2->0 and  3->3, so your function must return true.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Depth First Traversal can be used to detect a cycle in a Graph. DFS for a connected graph produces a tree. There is a cycle in a graph only if there is a back edge present in the graph. A back edge is an edge that is from a node to itself (self-loop) or one of its ancestor in the tree produced by DFS. In the following graph, there are 3 back edges, marked with a cross sign. We can observe that these 3 back edges indicate 3 cycles present in the graph.

For a disconnected graph, we get the DFS forest as output. To detect cycle, we can check for a cycle in individual trees by checking back edges.
To detect a back edge, we can keep track of vertices currently in recursion stack of function for DFS traversal.  If we reach a vertex that is already in the recursion stack, then there is a cycle in the tree. The edge that connects current vertex to the vertex in the recursion stack is a back edge.  We have used recStack[] array to keep track of vertices in the recursion stack.
Below image is a dry run of the above approach:

Below is the implementation of the above approach:







C++






filter_none

Disjoint Set (Or Union-Find) | Set 1 (Detect Cycle in an Undirected Graph)


A disjoint-set data structure is a data structure that keeps track of a set of elements partitioned into a number of disjoint (non-overlapping) subsets. A union-find algorithm is an algorithm that performs two useful operations on such a data structure:
Find: Determine which subset a particular element is in. This can be used for determining if two elements are in the same subset.
Union: Join two subsets into a single subset.





In this post, we will discuss the application of Disjoint Set Data Structure. The application is to check whether a given graph contains a cycle or not.
Union-Find Algorithm can be used to check whether an undirected graph contains cycle or not. Note that we have discussed an algorithm to detect cycle. This is another method based on Union-Find. This method assumes that the graph doesn’t contain any self-loops.
We can keep track of the subsets in a 1D array, let’s call it parent[].
Let us consider the following graph:

For each edge, make subsets using both the vertices of the edge. If both the vertices are in the same subset, a cycle is found.
Initially, all slots of parent array are initialized to -1 (means there is only one item in every subset).
0   1   2
-1 -1  -1 
Now process all edges one by one.
Edge 0-1: Find the subsets in which vertices 0 and 1 are. Since they are in different subsets, we take the union of them. For taking the union, either make node 0 as parent of node 1 or vice-versa. 
0   1   2    <----- 1 is made parent of 0 (1 is now representative of subset {0, 1})
1  -1  -1
Edge 1-2: 1 is in subset 1 and 2 is in subset 2. So, take union.
0   1   2    <----- 2 is made parent of 1 (2 is now representative of subset {0, 1, 2})
1   2  -1
Edge 0-2: 0 is in subset 2 and 2 is also in subset 2. Hence, including this edge forms a cycle.
How subset of 0 is same as 2?
0->1->2  // 1 is parent of 0 and 2 is parent of 1

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

Based on the above explanation, below are implementations:

C++











filter_none

Detect cycle in an undirected graph



.
Given an undirected graph, how to check if there is a cycle in the graph? For example, the following graph has a cycle 1-0-2-1.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







We have discussed cycle detection for directed graph. We have also discussed a union-find algorithm for cycle detection in undirected graphs.  The time complexity of the union-find algorithm is O(ELogV).  Like directed graphs, we can use DFS to detect cycle in an undirected graph in O(V+E) time.  We do a DFS traversal of the given graph.  For every visited vertex ‘v’, if there is an adjacent ‘u’ such that u is already visited and u is not parent of v, then there is a cycle in graph.  If we don’t find such an adjacent for any vertex, we say that there is no cycle.  The assumption of this approach is that there are no parallel edges between any two vertices.
Below image is a dry run of the above approach:

Below is the implementation of the above approach:

C++






filter_none

Longest Path in a Directed Acyclic Graph



Given a Weighted Directed Acyclic Graph (DAG) and a source vertex s in it, find the longest distances from s to all other vertices in the given graph.
The longest path problem for a general graph is not as easy as the shortest path problem because the longest path problem doesn’t have optimal substructure property. In fact, the Longest Path problem is NP-Hard for a general graph.  However, the longest path problem has a linear time solution for directed acyclic graphs.  The idea is similar to linear time solution for shortest path in a directed acyclic graph., we use Topological Sorting. 
We initialize distances to all vertices as minus infinite and distance to source as 0, then we find a topological sorting of the graph. Topological Sorting of a graph represents a linear ordering of the graph (See below, figure (b) is a linear representation of figure (a) ). Once we have topological order (or linear representation), we one by one process all vertices in topological order. For every vertex being processed, we update distances of its adjacent using distance of current vertex.





Following figure shows step by step process of finding longest paths.

Following is complete algorithm for finding longest distances.
1) Initialize dist[] = {NINF, NINF, ….} and dist[s] = 0 where s is the source vertex. Here NINF means negative infinite.
2) Create a toplogical order of all vertices.
3) Do following for every vertex u in topological order.
………..Do following for every adjacent vertex v of u
………………if (dist[v] < dist[u] + weight(u, v))
………………………dist[v] = dist[u] + weight(u, v)






Following is C++ implementation of the above algorithm.





filter_none

Topological Sorting



Topological sorting for Directed Acyclic Graph (DAG) is a linear ordering of vertices such that for every directed edge uv,  vertex u comes before v in the ordering.   Topological Sorting for a graph is not possible if the graph is not a DAG.
For example, a topological sorting of the following graph is “5 4 2 3 1 0”.  There can be more than one topological sorting for a graph.  For example, another topological sorting of the following graph is “4 5 2 3 1 0”.  The first vertex in topological sorting is always a vertex with in-degree as 0 (a vertex with no incoming edges).

Topological Sorting vs Depth First Traversal (DFS):
In DFS, we print a vertex and then recursively call DFS for its adjacent vertices. In topological sorting, we need to print a vertex before its adjacent vertices.  For example, in the given graph, the vertex ‘5’ should be printed before vertex ‘0’, but unlike DFS, the vertex ‘4’ should also be printed before vertex ‘0’.  So Topological sorting is different from DFS.  For example,  a DFS of the shown graph is “5 2 3 1 0 4”, but it is not a topological sorting

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







Algorithm to find Topological Sorting:
We recommend to first see implementation of DFS here.  We can modify DFS to find Topological Sorting of a graph.  In DFS, we start from a vertex, we first print it and then recursively call DFS for its adjacent vertices.  In topological sorting, we use a temporary stack.  We don’t print the vertex immediately, we first recursively call topological sorting for all its adjacent vertices, then push it to a stack. Finally, print contents of stack. Note that a vertex is pushed to stack only when all of its adjacent vertices (and their adjacent vertices and so on) are already in stack. 
Below image is an illustration of the above approach:

Following are the implementations of topological sorting.  Please see the code for Depth First Traversal for a disconnected Graph and note the differences between the second code given there and the below code.

C++






filter_none

Check whether a given graph is Bipartite or not


A Bipartite Graph is a graph whose vertices can be divided into two independent sets, U and V such that every edge (u, v) either connects a vertex from U to V or a vertex from V to U.  In other words, for every edge (u, v), either u belongs to U and v to V, or u belongs to V and v to U. We can also say that there is no edge that connects vertices of same set.

A bipartite graph is possible if the graph coloring is possible using two colors such that vertices in a set are colored with the same color. Note that it is possible to color a cycle graph with even cycle using two colors.  For example, see the following graph.






It is not possible to color a cycle graph with odd cycle using two colors.

Algorithm to check if a graph is Bipartite:
One approach is to check whether the graph is 2-colorable or not using backtracking algorithm m coloring problem.
Following is a simple algorithm to find out whether a given graph is Birpartite or not using Breadth First Search (BFS).
1.    Assign RED color to the source vertex (putting into set U).
2.    Color all the neighbors with BLUE color (putting into set V).
3.    Color all neighbor’s neighbor with RED color (putting into set U).
4.    This way, assign color to all vertices such that it satisfies all the constraints of m way coloring problem where m = 2.
5.      While assigning colors, if we find a neighbor which is colored with same color as current vertex, then the graph cannot be colored with 2 vertices (or graph is not Bipartite)  

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.


C++






filter_none

Snake and Ladder Problem


Given a snake and ladder board, find the minimum number of dice throws required to reach the destination or last cell from source or 1st cell. Basically, the player has total control over outcome of dice throw and wants to find out minimum number of throws required to reach last cell.
If the player reaches a cell which is base of a ladder, the player has to climb up that ladder and if reaches a cell is mouth of the snake, has to go down to the tail of snake without a dice throw.


Biconnected Components


A biconnected component is a maximal biconnected subgraph.
Biconnected Graph is already discussed here. In this article, we will see how to find biconnected component in a graph using algorithm by John Hopcroft and Robert Tarjan.






In above graph, following are the biconnected components:

4–2 3–4 3–1 2–3 1–2
8–9
8–5 7–8 5–7
6–0 5–6 1–5 0–1
10–11

Algorithm is based on Disc and Low Values discussed in Strongly Connected Components Article.
Idea is to store visited edges in a stack while DFS on a graph and keep looking for Articulation Points (highlighted in above figure). As soon as an Articulation Point u is found, all edges visited while DFS from node u onwards will form one biconnected component. When DFS completes for one connected component, all edges present in stack will form a biconnected component.
If there is no Articulation Point in graph, then graph is biconnected and so there will be one biconnected component which is the graph itself.

C++






filter_none

Check if a given graph is tree or not


Write a function that returns true if a given undirected graph is tree and false otherwise.  For example, the following graph is a tree.

But the following graph is not a tree.






An undirected graph is tree if it has following properties.
1) There is no cycle.
2) The graph is connected.
For an undirected graph we can either use BFS or DFS to detect above two properties.
How to detect cycle in an undirected graph?
We can either use BFS or DFS. For every visited vertex ‘v’, if there is an adjacent ‘u’ such that u is already visited and u is not parent of v, then there is a cycle in graph. If we don’t find such an adjacent for any vertex, we say that there is no cycle (See Detect cycle in an undirected graph for more details).
How to check for connectivity?
Since the graph is undirected, we can start BFS or DFS from any vertex and check if all vertices are reachable or not.  If all vertices are reachable, then graph is connected, otherwise not.

C++






filter_none

Prim’s Minimum Spanning Tree (MST) | Greedy Algo-5



We have discussed Kruskal’s algorithm for Minimum Spanning Tree. Like Kruskal’s algorithm, Prim’s algorithm is also a Greedy algorithm. It starts with an empty spanning tree. The idea is to maintain two sets of vertices. The first set contains the vertices already included in the MST, the other set contains the vertices not yet included. At every step, it considers all the edges that connect the two sets, and picks the minimum weight edge from these edges. After picking the edge, it moves the other endpoint of the edge to the set containing MST.
A group of edges that connects two set of vertices in a graph is called cut in graph theory. So, at every step of Prim’s algorithm, we find a cut (of two sets, one contains the vertices already included in MST and other contains rest of the verices), pick the minimum weight edge from the cut and include this vertex to MST Set (the set that contains already included vertices).
How does Prim’s Algorithm Work? The idea behind Prim’s algorithm is simple, a spanning tree means all vertices must be connected. So the two disjoint subsets (discussed above) of vertices must be connected to make a Spanning Tree. And they must be connected with the minimum weight edge to make it a Minimum Spanning Tree.
Algorithm
1) Create a set mstSet that keeps track of vertices already included in MST.
2) Assign a key value to all vertices in the input graph.  Initialize all key values as INFINITE. Assign key value as 0 for the first vertex so that it is picked first.
3) While mstSet doesn’t include all vertices
….a) Pick a vertex u which is not there in mstSet and has minimum key value.
….b) Include u to mstSet.
….c) Update key value of all adjacent vertices of u. To update the key values, iterate through all adjacent vertices. For every adjacent vertex v, if weight of edge u-v is less than the previous key value of v, update the key value as weight of u-v





The idea of using key values is to pick the minimum weight edge from cut. The key values are used only for vertices which are not yet included in MST, the key value for these vertices indicate the minimum weight edges connecting them to the set of vertices included in MST. 






Let us understand with the following example:

The set mstSet is initially empty and keys assigned to vertices are {0, INF, INF, INF, INF, INF, INF, INF} where INF indicates infinite.  Now pick the vertex with minimum key value.  The vertex 0 is picked, include it in mstSet. So mstSet becomes {0}.  After including to mstSet, update key values of adjacent vertices. Adjacent vertices of 0 are 1 and 7.  The key values of 1 and 7 are updated as 4 and 8.  Following subgraph shows vertices and their key values, only the vertices with finite key values are shown. The vertices included in MST are shown in green color.

Pick the vertex with minimum key value and not already included in MST (not in mstSET).  The vertex 1 is picked and added to mstSet.  So mstSet now becomes {0, 1}.  Update the key values of adjacent vertices of 1. The key value of vertex 2 becomes 8.

Pick the vertex with minimum key value and not already included in MST (not in mstSET).  We can either pick vertex 7 or vertex 2, let vertex 7 is picked.  So mstSet now becomes {0, 1, 7}.  Update the key values of adjacent vertices of 7. The key value of vertex 6 and 8 becomes finite (1 and 7 respectively).

Pick the vertex with minimum key value and not already included in MST (not in mstSET). Vertex 6 is picked. So mstSet now becomes {0, 1, 7, 6}. Update the key values of adjacent vertices of 6. The key value of vertex 5 and 8 are updated.

We repeat the above steps until mstSet  includes all vertices of given graph. Finally, we get the following graph.






Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

How to implement the above algorithm?
 We use a boolean array mstSet[] to represent the set of vertices included in MST.  If a value mstSet[v] is true, then vertex v is included in MST, otherwise not. Array key[] is used to store key values of all vertices. Another array parent[] to store indexes of parent nodes in MST. The parent array is the output array which is used to show the constructed MST.

C++







filter_none

Applications of Minimum Spanning Tree Problem


Minimum Spanning Tree (MST) problem: Given connected graph G with positive edge weights, find a min weight set of edges that connects all of the vertices.
MST is fundamental problem with diverse applications.
Network design.
– telephone, electrical, hydraulic, TV cable, computer, road
The standard application is to a problem like phone network design. You have a business with several offices; you want to lease phone lines to connect them up with each other; and the phone company charges different amounts of money to connect different pairs of cities. You want a set of lines that connects all your offices with a minimum total cost. It should be a spanning tree, since if a network isn’t a tree you can always remove some edges and save money.





Approximation algorithms for NP-hard problems.
– traveling salesperson problem, Steiner tree
A less obvious application is that the minimum spanning tree can be used to approximately solve the traveling salesman problem. A convenient formal way of defining this problem is to find the shortest path that visits each point at least once.
Note that if you have a path visiting all points exactly once, it’s a special kind of tree. For instance in the example above, twelve of sixteen spanning trees are actually paths. If you have a path visiting some vertices more than once, you can always drop some edges to get a tree. So in general the MST weight is less than the TSP weight, because it’s a minimization over a strictly larger set.
On the other hand, if you draw a path tracing around the minimum spanning tree, you trace each edge twice and visit all points, so the TSP weight is less than twice the MST weight. Therefore this tour is within a factor of two of optimal.
Indirect applications.
– max bottleneck paths
– LDPC codes for error correction
– image registration with Renyi entropy
– learning salient features for real-time face verification
– reducing data storage in sequencing amino acids in a protein
– model locality of particle interactions in turbulent fluid flows
– autoconfig protocol for Ethernet bridging to avoid cycles in a network
Cluster analysis
k clustering problem can be viewed as finding an MST and deleting the k-1 most
expensive edges. 

Sources:
http://www.cs.princeton.edu/courses/archive/spr07/cos226/lectures/mst.pdf
http://www.ics.uci.edu/~eppstein/161/960206.html







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Problem Solving for Minimum Spanning Trees (Kruskal’s and Prim’s)Kruskal's Minimum Spanning Tree using STL in C++Minimum Product Spanning TreeBoruvka's algorithm for Minimum Spanning TreeFind the weight of the minimum spanning treeMinimum spanning tree cost of given GraphsPrim’s Minimum Spanning Tree (MST) | Greedy Algo-5Reverse Delete Algorithm for Minimum Spanning TreeFind the minimum spanning tree with alternating colored edgesKruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2Types of Spanning Tree Protocol (STP)Spanning Tree With Maximum Degree (Using Kruskal's Algorithm)Maximum Possible Edge Disjoint Spanning Tree From a Complete GraphApplications of tree data structureKarger’s algorithm for Minimum Cut | Set 2 (Analysis and Applications)

Article Tags : GraphGreedyTreeMST
Practice Tags : GreedyGraphTree 

thumb_up
7



To-do

Done



2.1


Based on 57 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Prim’s MST for Adjacency List Representation | Greedy Algo-6


We recommend to read following two posts as a prerequisite of this post.
1. Greedy Algorithms | Set 5 (Prim’s Minimum Spanning Tree (MST))
2. Graph and its representations
We have discussed Prim’s algorithm and its implementation for adjacency matrix representation of graphs. The time complexity for the matrix representation is O(V^2). In this post, O(ELogV) algorithm for adjacency list representation is discussed.
As discussed in the previous post, in Prim’s algorithm, two sets are maintained, one set contains list of vertices already included in MST, other set contains vertices not yet included. With adjacency list representation, all vertices of a graph can be traversed in O(V+E) time using BFS. The idea is to traverse all vertices of graph using BFS and use a Min Heap to store the vertices not yet included in MST. Min Heap is used as a priority queue to get the minimum weight edge from the cut. Min Heap is used as time complexity of operations like extracting minimum element and decreasing key value is O(LogV) in Min Heap.





Following are the detailed steps.
1) Create a Min Heap of size V where V is the number of vertices in the given graph. Every node of min heap contains vertex number and key value of the vertex.
2) Initialize Min Heap with first vertex as root (the key value assigned to first vertex is 0). The key value assigned to all other vertices is INF (infinite).
3)  While Min Heap is not empty, do following
…..a) Extract the min value node from Min Heap. Let the extracted vertex be u.
…..b) For every adjacent vertex v of u, check if v is in Min Heap (not yet included in MST). If v is in Min Heap and its key value is more than weight of u-v, then update the key value of v as weight of u-v.
Let us understand the above algorithm with the following example:

Initially, key value of first vertex is 0 and INF (infinite) for all other vertices. So vertex 0 is extracted from Min Heap and key values of vertices adjacent to 0 (1 and 7) are updated. Min Heap contains all vertices except vertex 0.
The vertices in green color are the vertices included in MST.

Since key value of vertex 1 is minimum among all nodes in Min Heap, it is extracted from Min Heap and key values of vertices adjacent to 1 are updated (Key is updated if the a vertex is not in Min Heap and previous key value is greater than the weight of edge from 1 to the adjacent). Min Heap contains all vertices except vertex 0 and 1.

Since key value of vertex 7 is minimum among all nodes in Min Heap, it is extracted from Min Heap and key values of vertices adjacent to 7 are updated (Key is updated if the a vertex is not in Min Heap and previous key value is greater than the weight of edge from 7 to the adjacent). Min Heap contains all vertices except vertex 0, 1 and 7.

Since key value of vertex 6 is minimum among all nodes in Min Heap, it is extracted from Min Heap and key values of vertices adjacent to 6 are updated (Key is updated if the a vertex is not in Min Heap and previous key value is greater than the weight of edge from 6 to the adjacent). Min Heap contains all vertices except vertex 0, 1, 7 and 6.

The above steps are repeated for rest of the nodes in Min Heap till Min Heap becomes empty


C++






filter_none

Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2


What is Minimum Spanning Tree?
Given a connected and undirected graph, a spanning tree of that graph is a subgraph that is a tree and connects all the vertices together. A single graph can have many different spanning trees. A minimum spanning tree (MST) or minimum weight spanning tree for a weighted, connected and undirected graph is a spanning tree with weight less than or equal to the weight of every other spanning tree. The weight of a spanning tree is the sum of weights given to each edge of the spanning tree.
How many edges does a minimum spanning tree has?
A minimum spanning tree has (V – 1) edges where V is the number of vertices in the given  graph. 
What are the applications of Minimum Spanning Tree?
See this for applications of MST.





Below are the steps for finding MST using Kruskal’s algorithm

1. Sort all the edges in non-decreasing order of their weight.
2. Pick the smallest edge. Check if it forms a cycle with the spanning tree formed so far. If cycle is not formed, include this edge. Else, discard it.
3. Repeat step#2 until there are (V-1) edges in the spanning tree.
The step#2 uses Union-Find algorithm to detect cycle. So we recommend to read following post as a prerequisite.
Union-Find Algorithm | Set 1 (Detect Cycle in a Graph)
Union-Find Algorithm | Set 2 (Union By Rank and Path Compression)
The algorithm is a Greedy Algorithm. The Greedy Choice is to pick the smallest weight edge that does not cause a cycle in the MST constructed so far. Let us understand it with an example: Consider the below input graph. 

The graph contains 9 vertices and 14 edges. So, the minimum spanning tree formed will be having (9 – 1) = 8 edges. 
After sorting:
Weight   Src    Dest
1         7      6
2         8      2
2         6      5
4         0      1
4         2      5
6         8      6
7         2      3
7         7      8
8         0      7
8         1      2
9         3      4
10        5      4
11        1      7
14        3      5






Now pick all edges one by one from sorted list of edges
1. Pick edge 7-6: No cycle is formed, include it.

2. Pick edge 8-2: No cycle is formed, include it.

3. Pick edge 6-5: No cycle is formed, include it.

4. Pick edge 0-1: No cycle is formed, include it.





5. Pick edge 2-5: No cycle is formed, include it.

6. Pick edge 8-6: Since including this edge results in cycle, discard it.
7. Pick edge 2-3: No cycle is formed, include it.

8. Pick edge 7-8: Since including this edge results in cycle, discard it.
9. Pick edge 0-7: No cycle is formed, include it.

10. Pick edge 1-2: Since including this edge results in cycle, discard it.
11. Pick edge 3-4: No cycle is formed, include it.

Since the number of edges included equals (V – 1), the algorithm stops here.

Recommended: Please try your approach on {IDE} first, before moving on to the solution.


C++






filter_none

Boruvka’s algorithm | Greedy Algo-9


We have discussed following topics on Minimum Spanning Tree.
Applications of Minimum Spanning Tree Problem
Kruskal’s Minimum Spanning Tree Algorithm 
Prim’s Minimum Spanning Tree Algorithm
In this post, Boruvka’s algorithm is discussed. Like Prim’s and Kruskal’s, Boruvka’s algorithm is also a Greedy algorithm.  Below is complete algorithm.





1) Input is a connected, weighted and directed graph.
2) Initialize all vertices as individual components (or sets).
3) Initialize MST as empty.
4) While there are more than one components, do following
   for each component.
      a)  Find the closest weight edge that connects this 
          component to any other component.
      b)  Add this closest edge to MST if not already added.  
5) Return MST.

Below is the idea behind above algorithm  (The idea is same as Prim’s MST algorithm).  
A spanning tree means all vertices must be connected. So the two disjoint subsets (discussed above) of vertices must be connected to make a Spanning Tree. And they must be connected with the minimum weight edge to make it a Minimum Spanning Tree.
Let us understand the algorithm with below example. 

Initially MST is empty. Every vertex is singe component as highlighted in blue color in below diagram.

 
For every component, find the cheapest edge that connects it to some other component.  
Component                Cheapest Edge that connects 
                         it to some other component
  {0}                           0-1
  {1}                           0-1
  {2}                           2-8
  {3}                           2-3
  {4}                           3-4
  {5}                           5-6
  {6}                           6-7
  {7}                           6-7
  {8}                           2-8 
The cheapest edges are highlighted with green color. Now MST becomes {0-1, 2-8, 2-3, 3-4, 5-6, 6-7}.

After above step, components are {{0,1}, {2,3,4,8}, {5,6,7}}. The components are encircled with blue color.

 
We again repeat the step, i.e., for every component, find the cheapest edge that connects it to some other component.
Component                Cheapest Edge that connects 
                         it to some other component
  {0,1}                        1-2 (or 0-7)
  {2,3,4,8}                    2-5
  {5,6,7}                      2-5
The cheapest edges are highlighted with green color. Now MST becomes {0-1, 2-8, 2-3, 3-4, 5-6, 6-7, 1-2, 2-5}

At this stage, there is only one component {0, 1, 2, 3, 4, 5, 6, 7, 8} which has all edges.  Since there is only one component left, we stop and return MST.
Implementation:
Below is implementation of above algorithm.  The input graph is represented as a collection of edges and union-find data structure is used to keep track of components.

C/C++











filter_none

Dijkstra’s shortest path algorithm | Greedy Algo-7



Given a graph and a source vertex in the graph, find shortest paths from source to all vertices in the given graph.
Dijkstra’s algorithm is very similar to Prim’s algorithm for minimum spanning tree. Like Prim’s MST, we generate a SPT (shortest path tree) with given source as root. We maintain two sets, one set contains vertices included in shortest path tree, other set includes vertices not yet included in shortest path tree. At every step of the algorithm, we find a vertex which is in the other set (set of not yet included) and has a minimum distance from the source.
Below are the detailed steps used in Dijkstra’s algorithm to find the shortest path from a single source vertex to all other vertices in the given graph.
Algorithm
1) Create a set sptSet (shortest path tree set) that keeps track of vertices included in shortest path tree, i.e., whose minimum distance from source is calculated and finalized. Initially, this set is empty.
2) Assign a distance value to all vertices in the input graph. Initialize all distance values as INFINITE. Assign distance value as 0 for the source vertex so that it is picked first.
3) While sptSet doesn’t include all vertices
….a) Pick a vertex u which is not there in sptSet and has minimum distance value.
….b) Include u to sptSet.
….c) Update distance value of all adjacent vertices of u. To update the distance values, iterate through all adjacent vertices. For every adjacent vertex v, if sum of distance value of u (from source) and weight of edge u-v, is less than the distance value of v, then update the distance value of v.






Let us understand with the following example:

The set sptSet is initially empty and distances assigned to vertices are {0, INF, INF, INF, INF, INF, INF, INF} where INF indicates infinite. Now pick the vertex with minimum distance value. The vertex 0 is picked, include it in sptSet. So sptSet becomes {0}. After including 0 to sptSet, update distance values of its adjacent vertices. Adjacent vertices of 0 are 1 and 7. The distance values of 1 and 7 are updated as 4 and 8. Following subgraph shows vertices and their distance values, only the vertices with finite distance values are shown. The vertices included in SPT are shown in green colour.

Pick the vertex with minimum distance value and not already included in SPT (not in sptSET). The vertex 1 is picked and added to sptSet. So sptSet now becomes {0, 1}. Update the distance values of adjacent vertices of 1. The distance value of vertex 2 becomes 12.

Pick the vertex with minimum distance value and not already included in SPT (not in sptSET). Vertex 7 is picked. So sptSet now becomes {0, 1, 7}. Update the distance values of adjacent vertices of 7. The distance value of vertex 6 and 8 becomes finite (15 and 9 respectively).

Pick the vertex with minimum distance value and not already included in SPT (not in sptSET). Vertex 6 is picked. So sptSet now becomes {0, 1, 7, 6}. Update the distance values of adjacent vertices of 6. The distance value of vertex 5 and 8 are updated.

We repeat the above steps until sptSet  does include all vertices of given graph. Finally, we get the following Shortest Path Tree (SPT).

How to implement the above algorithm?


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Dijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8


We recommend reading the following two posts as a prerequisite of this post.
1. Greedy Algorithms | Set 7 (Dijkstra’s shortest path algorithm)
2. Graph and its representations
We have discussed Dijkstra’s algorithm and its implementation for adjacency matrix representation of graphs. The time complexity for the matrix representation is O(V^2). In this post, O(ELogV) algorithm for adjacency list representation is discussed.





As discussed in the previous post, in Dijkstra’s algorithm, two sets are maintained, one set contains list of vertices already included in SPT (Shortest Path Tree), other set contains vertices not yet included. With adjacency list representation, all vertices of a graph can be traversed in O(V+E) time using BFS. The idea is to traverse all vertices of graph using BFS and use a Min Heap to store the vertices not yet included in SPT (or the vertices for which shortest distance is not finalized yet).  Min Heap is used as a priority queue to get the minimum distance vertex from set of not yet included vertices. Time complexity of operations like extract-min and decrease-key value is O(LogV) for Min Heap.
Following are the detailed steps.
1) Create a Min Heap of size V where V is the number of vertices in the given graph. Every node of min heap contains vertex number and distance value of the vertex.
2) Initialize Min Heap with source vertex as root (the distance value assigned to source vertex is 0). The distance value assigned to all other vertices is INF (infinite).
3) While Min Heap is not empty, do following
…..a) Extract the vertex with minimum distance value node from Min Heap. Let the extracted vertex be u.
…..b) For every adjacent vertex v of u, check if v is in Min Heap. If v is in Min Heap and distance value is more than weight of u-v plus distance value of u, then update the distance value of v.
Let us understand with the following example. Let the given source vertex be 0

Initially, distance value of source vertex is 0 and INF (infinite) for all other vertices. So source vertex is extracted from Min Heap and distance values of vertices adjacent to 0 (1 and 7) are updated. Min Heap contains all vertices except vertex 0.
The vertices in green color are the vertices for which minimum distances are finalized and are not in Min Heap

Since distance value of vertex 1 is minimum among all nodes in Min Heap, it is extracted from Min Heap and distance values of vertices adjacent to 1 are updated (distance is updated if the a vertex is not in Min Heap and distance through 1 is shorter than the previous distance). Min Heap contains all vertices except vertex 0 and 1.

Pick the vertex with minimum distance value from min heap. Vertex 7 is picked. So min heap now contains all vertices except 0, 1 and 7. Update the distance values of adjacent vertices of 7. The distance value of vertex 6 and 8 becomes finite (15 and 9 respectively).

Pick the vertex with minimum distance from min heap. Vertex 6 is picked. So min heap now contains all vertices except 0, 1, 7 and 6. Update the distance values of adjacent vertices of 6. The distance value of vertex 5 and 8 are updated.





Above steps are repeated till min heap doesn’t become empty. Finally, we get the following shortest path tree.


C++






filter_none

Bellman–Ford Algorithm | DP-23


Given a graph and a source vertex src in graph, find shortest paths from src to all vertices in the given graph. The graph may contain negative weight edges.
We have discussed Dijkstra’s algorithm for this problem. Dijkstra’s algorithm is a Greedy algorithm and time complexity is O(VLogV) (with the use of Fibonacci heap). Dijkstra doesn’t work for Graphs with negative weight edges, Bellman-Ford works for such graphs. Bellman-Ford is also simpler than Dijkstra and suites well for distributed systems.  But time complexity of Bellman-Ford is O(VE), which is more than Dijkstra.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Floyd Warshall Algorithm | DP-16



The Floyd Warshall Algorithm is for solving the All Pairs Shortest Path problem. The problem is to find shortest distances between every pair of vertices in a given edge weighted directed Graph. 
Example:
Input:
       graph[][] = { {0,   5,  INF, 10},
                    {INF,  0,  3,  INF},
                    {INF, INF, 0,   1},
                    {INF, INF, INF, 0} }
which represents the following graph
             10
       (0)------->(3)
        |         /|\
      5 |          |
        |          | 1
       \|/         |
       (1)------->(2)
            3       
Note that the value of graph[i][j] is 0 if i is equal to j 
And graph[i][j] is INF (infinite) if there is no edge from vertex i to j.

Output:
Shortest distance matrix
      0      5      8      9
    INF      0      3      4
    INF    INF      0      1
    INF    INF    INF      0 


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







Floyd Warshall Algorithm
We initialize the solution matrix same as the input graph matrix as a first step. Then we update the solution matrix by considering all vertices as an intermediate vertex. The idea is to one by one pick all vertices and updates all shortest paths which include the picked vertex as an intermediate vertex in the shortest path. When we pick vertex number k as an intermediate vertex, we already have considered vertices {0, 1, 2, .. k-1} as intermediate vertices. For every pair (i, j) of the source and destination vertices respectively, there are two possible cases.
1) k is not an intermediate vertex in shortest path from i to j. We keep the value of dist[i][j] as it is.
2) k is an intermediate vertex in shortest path from i to j. We update the value of dist[i][j] as dist[i][k] + dist[k][j] if dist[i][j] > dist[i][k] + dist[k][j]
The following figure shows the above optimal substructure property in the all-pairs shortest path problem.

Following is implementations of the Floyd Warshall algorithm.

C++







filter_none

Johnson’s algorithm for All-pairs shortest paths


The problem is to find shortest paths between every pair of vertices in a given weighted directed Graph and weights may be negative. We have discussed Floyd Warshall Algorithm for this problem.  Time complexity of Floyd Warshall Algorithm is Θ(V3). Using Johnson’s algorithm, we can find all pair shortest paths in O(V2log V + VE) time. Johnson’s algorithm uses both Dijkstra and Bellman-Ford as subroutines.
If we apply Dijkstra’s Single Source shortest path algorithm for every vertex, considering every vertex as source, we can find all pair shortest paths in O(V*VLogV) time. So using Dijkstra’s single source shortest path seems to be a better option than Floyd Warshell, but the problem with Dijkstra’s algorithm is, it doesn’t work for negative weight edge.
The idea of Johnson’s algorithm is to re-weight all edges and make them all positive, then apply Dijkstra’s algorithm for every vertex.
How to transform a given graph to a graph with all non-negative weight edges?
One may think of a simple approach of finding the minimum weight edge and adding this weight to all edges.  Unfortunately, this doesn’t work as there may be different number of edges in different paths (See this for an example).  If there are multiple paths from a vertex u to v, then all paths must be increased by same amount, so that the shortest path remains the shortest in the transformed graph.
The idea of Johnson’s algorithm is to assign a weight to every vertex. Let the weight assigned to vertex u be h[u].  We reweight edges using vertex weights.  For example, for an edge (u, v) of weight w(u, v), the new weight becomes w(u, v) + h[u] – h[v]. The great thing about this reweighting is, all set of paths between any two vertices are increased by same amount and all negative weights become non-negative.  Consider any path between two vertices s and t, weight of every path is increased by h[s] – h[t], all h[] values of vertices on path from s to t cancel each other.





How do we calculate h[] values? Bellman-Ford algorithm is used for this purpose.  Following is the complete algorithm. A new vertex is added to the graph and connected to all existing vertices.  The shortest distance values from new vertex to all existing vertices are h[] values.
Algorithm:
1) Let the given graph be G. Add a new vertex s to the graph, add edges from new vertex to all vertices of G. Let the modified graph be G’.
2) Run Bellman-Ford algorithm on G’ with s as source.  Let the distances calculated by Bellman-Ford be h[0], h[1], .. h[V-1]. If we find a negative weight cycle, then return.  Note that the negative weight cycle cannot be created by new vertex s as there is no edge to s.  All edges are from s.
3) Reweight the edges of original graph.  For each edge (u, v), assign the new weight as “original weight + h[u] – h[v]”.
4) Remove the added vertex s and run Dijkstra’s algorithm for every vertex.
How does the transformation ensure nonnegative weight edges?
The following property is always true about h[] values as they are shortest distances. 
   h[v] <= h[u] + w(u, v) 
The property simply means, shortest distance from s to v must be smaller than or equal to shortest distance from s to u plus weight of edge (u, v).  The new weights are w(u, v) + h[u] - h[v].   The value of the new weights must be greater than or equal to zero because of the inequality "h[v] <= h[u] + w(u, v)".

Example:
Let us consider the following graph. 

We add a source s and add edges from s to all vertices of the original graph.  In the following diagram s is 4.





We calculate the shortest distances from 4 to all other vertices using Bellman-Ford algorithm.  The shortest distances from 4 to 0, 1, 2 and 3 are 0, -5, -1 and 0 respectively, i.e., h[] = {0, -5, -1, 0}.  Once we get these distances, we remove the source vertex 4 and reweight the edges using following  formula.  w(u, v) = w(u, v) + h[u] - h[v].

Since all weights are positive now, we can run Dijkstra's shortest path algorithm for every vertex as source.
Time Complexity:  The main steps in algorithm are Bellman Ford Algorithm called once and Dijkstra called V times.  Time complexity of Bellman Ford is O(VE) and time complexity of Dijkstra is O(VLogV).  So overall time complexity is O(V2log V + VE).
The time complexity of Johnson's algorithm becomes same as Floyd Warshell when the graphs is complete (For a complete graph E = O(V2).  But for sparse graphs, the algorithm performs much better than Floyd Warshell.
References:
Introduction to Algorithms 3rd Edition by Clifford Stein, Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest
http://www.youtube.com/watch?v=b6LOHvCzmkI
http://www.youtube.com/watch?v=TV2Z6nbo1ic
http://en.wikipedia.org/wiki/Johnson%27s_algorithm
http://www.youtube.com/watch?v=Sygq1e0xWnM
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Johnson’s algorithm for All-pairs shortest paths | ImplementationPrinting Paths in Dijkstra's Shortest Path AlgorithmShortest paths from all vertices to a destinationNumber of shortest paths in an unweighted and directed graphCheck if given path between two nodes of a graph represents a shortest pathsNumber of shortest paths to reach every cell from bottom-left cell in the gridDijkstra’s shortest path algorithm using set in STLDijkstra's Shortest Path Algorithm using priority_queue of STLDijkstra's shortest path algorithm in Java using PriorityQueueDijkstra's shortest path algorithm | Greedy Algo-7Probabilistic shortest path routing algorithm for optical networksCount all possible paths between two verticesPrint all paths from a given source to a destination using BFSPrint all paths from a given source to a destinationNumber of Unicolored Paths between two nodes

Article Tags : GraphShortest Path
Practice Tags : GraphShortest Path 

thumb_up
5



To-do

Done



4.1


Based on 26 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Shortest Path in Directed Acyclic Graph


Given a Weighted Directed Acyclic Graph and a source vertex in the graph, find the shortest paths from given source to all other vertices.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Some interesting shortest path questions | Set 1


Question 1: Given a directed weighted graph. You are also given the shortest path from a source vertex ‘s’ to a destination vertex ‘t’.  If weight of every edge is increased by 10 units, does the shortest path remain same in the modified graph?
The shortest path may change. The reason is, there may be different number of edges in different paths from s to t. For example, let shortest path be of weight 15 and has 5 edges. Let there be another path with 2 edges and total weight 25. The weight of the shortest path is increased by 5*10 and becomes 15 + 50. Weight of the other path is increased by 2*10 and becomes 25 + 20. So the shortest path changes to the other path with weight as 45.
Question 2: This is similar to above question. Does the shortest path change when weights of all edges are multiplied by 10?
If we multiply all edge weights by 10, the shortest path doesn’t change. The reason is simple, weights of all paths from s to t get multiplied by same amount. The number of edges on a path doesn’t matter. It is like changing unit of weights.
Question 3: Given a directed graph where every edge has weight as either 1 or 2, find the shortest path from a given source vertex ‘s’ to a given destination vertex ‘t’. Expected time complexity is O(V+E).
If we apply Dijkstra’s shortest path algorithm, we can get a shortest path in O(E + VLogV) time. How to do it in O(V+E) time? The idea is to use BFS . One important observation about BFS is, the path used in BFS always has least number of edges between any two vertices. So if all edges are of same weight, we can use BFS to find the shortest path. For this problem, we can modify the graph and split all edges of weight 2 into two edges of weight 1 each. In the modified graph, we can use BFS to find the shortest path. How is this approach O(V+E)? In worst case, all edges are of weight 2 and we need to do O(E) operations to split all edges, so the time complexity becomes O(E) + O(V+E) which is O(V+E).





Question 4: Given a directed acyclic weighted graph, how to find the shortest path from a source s to a destination t in O(V+E) time?
See: Shortest Path in Directed Acyclic Graph
More Questions See following links for more questions.
http://algs4.cs.princeton.edu/44sp/
https://www.geeksforgeeks.org/algorithms-gq/graph-shortest-paths-gq/
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Shortest path from source to destination such that edge weights along path are alternatively increasing and decreasingMultistage Graph (Shortest Path)Shortest path in an unweighted graphDijkstra’s shortest path algorithm using set in STLShortest Path using Meet In The MiddleShortest path in a Binary MazeDijkstra's Shortest Path Algorithm using priority_queue of STLDijkstra's shortest path with minimum edges0-1 BFS (Shortest Path in a Binary Weight Graph)Shortest Path in Directed Acyclic GraphDijkstra's shortest path algorithm in Java using PriorityQueueShortest Path in a weighted Graph where weight of an edge is 1 or 2Printing Paths in Dijkstra's Shortest Path AlgorithmShortest path with exactly k edges in a directed and weighted graphDijkstra's shortest path algorithm | Greedy Algo-7

Article Tags : GraphDijkstraShortest Path
Practice Tags : GraphShortest Path 

thumb_up
8



To-do

Done



3


Based on 23 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Shortest path with exactly k edges in a directed and weighted graph


Given a directed and two vertices ‘u’ and ‘v’ in it, find shortest path from ‘u’ to ‘v’ with exactly k edges on the path.
The graph is given as adjacency matrix representation where value of graph[i][j] indicates the weight of an edge from vertex i to vertex j and a value INF(infinite) indicates no edge from i to j.
For example consider the following graph. Let source ‘u’ be vertex 0, destination ‘v’ be 3 and k be 2. There are two walks of length 2, the walks are {0, 2, 3} and {0, 1, 3}.  The shortest among the two is {0, 2, 3} and weight of path is 3+6 = 9.






The idea is to browse through all paths of length k from u to v using the approach discussed in the previous post and return weight of the shortest path.  A simple solution is to start from u, go to all adjacent vertices and recur for adjacent vertices with k as k-1, source as adjacent vertex and destination as v. Following are C++ and Java implementations of this simple solution. 

C++






filter_none

Find if there is a path between two vertices in a directed graph


Given a Directed Graph and two vertices in it, check whether there is a path from the first given vertex to second.  For example, in the following graph, there is a path from vertex 1 to 3. As another example, there is no path from 3 to 0.

We can either use Breadth First Search (BFS) or Depth First Search (DFS) to find path between two vertices. Take the first vertex as source in BFS (or DFS), follow the standard BFS (or DFS). If we see the second vertex in our traversal, then return true.  Else return false.





Following are C++,Java and Python codes that use BFS for finding reachability of second vertex from first vertex.

C++






filter_none

Check if a graph is strongly connected | Set 1 (Kosaraju using DFS)


Given a directed graph, find out whether the graph is strongly connected or not.  A directed graph is strongly connected if there is a path between any two pair of vertices.  For example, following is a strongly connected graph.

It is easy for undirected graph, we can just do a BFS and DFS starting from any vertex.  If BFS or DFS visits all vertices, then the given undirected graph is connected. This approach won’t work for a directed graph.  For example, consider the following graph which is not strongly connected.  If we start DFS (or BFS) from vertex 0, we can reach all vertices, but if we start from any other vertex, we cannot reach all vertices.






How to do for directed graph?

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

A simple idea is to use a all pair shortest path algorithm like Floyd Warshall or find Transitive Closure of graph.  Time complexity of this method would be O(v3).
We can also do DFS V times starting from every vertex. If any DFS, doesn’t visit all vertices, then graph is not strongly connected.  This algorithm takes O(V*(V+E)) time which can be same as transitive closure for a dense graph.
A better idea can be Strongly Connected Components (SCC) algorithm.  We can find all SCCs in O(V+E) time.  If number of SCCs is one, then graph is strongly connected.  The algorithm for SCC does extra work as it finds all SCCs.  
Following is Kosaraju’s DFS based simple algorithm that does two DFS traversals of graph:
1) Initialize all vertices as not visited.
2) Do a DFS traversal of graph starting from any arbitrary vertex v.  If DFS traversal doesn’t visit all vertices, then return false.
3) Reverse all arcs (or find transpose or reverse of graph) 
4) Mark all vertices as not-visited in reversed graph.
5) Do a DFS traversal of reversed graph starting from same vertex v (Same as step 2). If DFS traversal doesn’t visit all vertices, then return false. Otherwise return true.




The idea is, if every node can be reached from a vertex v, and every node can reach v, then the graph is strongly connected. In step 2, we check if all vertices are reachable from v.  In step 4, we check if all vertices can reach v (In reversed graph, if all vertices are reachable from v, then all vertices can reach v in original graph).  
Following is the implementation of above algorithm.

C++






filter_none

Articulation Points (or Cut Vertices) in a Graph


A vertex in an undirected connected graph is an articulation point (or cut vertex) iff removing it (and edges through it) disconnects the graph.  Articulation points represent vulnerabilities in a connected network – single points whose failure would split the network into 2 or more disconnected components. They are useful for designing reliable networks.
For a disconnected undirected graph, an articulation point is a vertex removing which increases number of connected components.
Following are some example graphs with articulation points encircled with red color.





Biconnected graph


An undirected graph is called Biconnected if there are two vertex-disjoint paths between any two vertices.  In a Biconnected Graph, there is a simple cycle through any two vertices.
By convention, two nodes connected by an edge form a biconnected graph, but this does not verify the above properties. For a graph with more than two vertices, the above properties must be there for it to be Biconnected.
Following are some examples.











See this for more examples.


Bridges in a graph


An edge in an undirected connected graph is a bridge iff removing it disconnects the graph.  For a disconnected undirected graph, definition is similar, a bridge is an edge removing which increases number of disconnected components.
Like Articulation Points, bridges represent vulnerabilities in a connected network and are useful for designing reliable networks. For example, in a wired computer network, an articulation point indicates the critical computers and a bridge indicates the critical wires or connections.
Following are some example graphs with bridges highlighted with red color.
  





How to find all bridges in a given graph?
A simple approach is to one by one remove all edges and see if removal of an edge causes disconnected graph. Following are steps of simple approach for connected graph.
1) For every edge (u, v), do following
…..a) Remove (u, v) from graph
..…b) See if the graph remains connected (We can either use BFS or DFS)
…..c) Add (u, v) back to the graph.
Time complexity of above method is O(E*(V+E)) for a graph represented using adjacency list. Can we do better?
A O(V+E) algorithm to find all Bridges
The idea is similar to O(V+E) algorithm for Articulation Points. We do DFS traversal of the given graph. In DFS tree an edge (u, v) (u is parent of v in DFS tree) is bridge if there does not exist any other alternative to reach u or an ancestor of u from subtree rooted with v. As discussed in the previous post, the value low[v] indicates earliest visited vertex reachable from subtree rooted with v.  The condition for an edge (u, v) to be a bridge is, “low[v] > disc[u]”. 
Following are C++ and Java implementations of above approach.

C++






filter_none

Eulerian path and circuit for undirected graph


Eulerian Path  is a path in graph that visits every edge exactly once. Eulerian Circuit is an Eulerian Path which starts and ends on the same vertex.  
 
 






How to find whether a given graph is Eulerian or not?
The problem is same as following question. “Is it possible to draw a given graph without lifting pencil from the paper and without tracing any of the edges more than once”.
A graph is called Eulerian if it has an Eulerian Cycle and called Semi-Eulerian if it has an Eulerian Path. The problem seems similar to Hamiltonian Path which is NP complete problem for a general graph. Fortunately, we can find whether a given graph has a Eulerian Path or not in polynomial time. In fact, we can find it in O(V+E) time. 
Following are some interesting properties of undirected graphs with an Eulerian path and cycle. We can use these properties to find whether a graph is Eulerian or not.
Eulerian Cycle
An undirected graph has Eulerian cycle if following two conditions are true.
….a) All vertices with non-zero degree are connected.  We don’t care about vertices with zero degree because they don’t belong to Eulerian Cycle or Path (we only consider all edges).
….b) All vertices have even degree.
Eulerian Path
An undirected graph has Eulerian Path if following two conditions are true.
….a) Same as condition (a) for Eulerian Cycle
….b) If two vertices have odd degree and all other vertices have even degree.  Note that only one vertex with odd degree is not possible in an undirected graph (sum of all degrees is always even in an undirected graph)
Note that a graph with no edges is considered Eulerian because there are no edges to traverse.
How does this work?
In Eulerian path, each time we visit a vertex v, we walk through two unvisited edges with one end point as v.  Therefore, all middle vertices in Eulerian Path must have even degree.  For Eulerian Cycle, any vertex can be middle vertex, therefore all vertices must have even degree.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.


C++






filter_none

Fleury’s Algorithm for printing Eulerian Path or Circuit


Eulerian Path is a path in graph that visits every edge exactly once. Eulerian Circuit is an Eulerian Path which starts and ends on the same vertex.
We strongly recommend to first read the following post on Euler Path and Circuit.
https://www.geeksforgeeks.org/eulerian-path-and-circuit/
In the above mentioned post, we discussed the problem of finding out whether a given graph is Eulerian or not. In this post, an algorithm to print Eulerian trail or circuit is discussed.





Following is Fleury’s Algorithm for printing Eulerian trail or cycle (Source Ref1).
1. Make sure the graph has either 0 or 2 odd vertices.
2. If there are 0 odd vertices, start anywhere. If there are 2 odd vertices, start at one of them.
3. Follow edges one at a time. If you have a choice between a bridge and a non-bridge, always choose the non-bridge.
4. Stop when you run out of edges.
The idea is, “don’t burn bridges“ so that we can come back to a vertex and traverse remaining edges.  For example let us consider the following graph. 

There are two vertices with odd degree, ‘2’ and ‘3’, we can start path from any of them. Let us start tour from vertex ‘2’.

There are three edges going out from vertex ‘2’, which one to pick? We don’t pick the edge ‘2-3’ because that is a bridge (we won’t be able to come back to ‘3’).  We can pick any of the remaining two edge. Let us say we pick ‘2-0’. We remove this edge and move to vertex ‘0’.

There is only one edge from vertex ‘0’, so we pick it, remove it and move to vertex ‘1’. Euler tour becomes ‘2-0 0-1’.

There is only one edge from vertex ‘1’, so we pick it, remove it and move to vertex ‘2’. Euler tour becomes ‘2-0 0-1 1-2’

Again there is only one edge from vertex 2, so we pick it, remove it and move to vertex 3. Euler tour becomes ‘2-0 0-1 1-2 2-3’





There are no more edges left, so we stop here.  Final tour is ‘2-0 0-1 1-2 2-3’.
See this for and this fore more examples.
Following is C++ implementation of above algorithm.  In the following code, it is assumed that the given graph has an Eulerian trail or Circuit. The main focus is to print an Eulerian trail or circuit. We can use isEulerian() to first check whether there is an Eulerian Trail or Circuit in the given graph. 
We first find the starting point which must be an odd vertex (if there are odd vertices) and store it in variable ‘u’. If there are zero odd vertices, we start from vertex ‘0’. We call printEulerUtil() to print Euler tour starting with u. We traverse all adjacent vertices of u, if there is only one adjacent vertex, we immediately consider it. If there are more than one adjacent vertices, we consider an adjacent v only if edge u-v is not a bridge. How to find if a given is edge is bridge? We count number of vertices reachable from u. We remove edge u-v and again count number of reachable vertices from u. If number of reachable vertices are reduced, then edge u-v is a bridge. To count reachable vertices, we can either use BFS or DFS, we have used DFS in the above code. The function DFSCount(u) returns number of vertices reachable from u.
Once an edge is processed (included in Euler tour), we remove it from the graph.  To remove the edge, we replace the vertex entry with -1 in adjacency list.  Note that simply deleting the node may not work as the code is recursive and a parent call may be in middle of adjacency list.

C/C++






filter_none

Strongly Connected Components


A directed graph is strongly connected if there is a path between all pairs of vertices. A strongly connected component (SCC) of a directed graph is a maximal strongly connected subgraph.  For example, there are 3 SCCs in the following graph.

We can find all strongly connected components in O(V+E) time using Kosaraju’s algorithm.  Following is detailed Kosaraju’s algorithm.
1) Create an empty stack ‘S’ and do DFS traversal of a graph. In DFS traversal, after calling recursive DFS for adjacent vertices of a vertex, push the vertex to stack.  In the above graph, if we start DFS from vertex 0, we get vertices in stack as 1, 2, 4, 3, 0.
2) Reverse directions of all arcs to obtain the transpose graph.
3) One by one pop a vertex from S while S is not empty. Let the popped vertex be ‘v’. Take v as source and do DFS (call DFSUtil(v)).   The DFS starting from v prints strongly connected component of v.  In the above example, we process vertices in order 0, 3, 4, 2, 1 (One by one popped from stack).





How does this work?
The above algorithm is DFS based. It does DFS two times. DFS of a graph produces a single tree if all vertices are reachable from the DFS starting point.  Otherwise DFS produces a forest. So DFS of a graph with only one SCC always produces a tree.  The important point to note is DFS may produce a tree or a forest when there are more than one SCCs depending upon the chosen starting point.  For example, in the above diagram, if we start DFS from vertices 0 or 1 or 2, we get a tree as output.  And if we start from 3 or 4, we get a forest. To find and print all SCCs, we would want to start DFS from vertex 4 (which is a sink vertex), then move to 3 which is sink in the remaining set (set excluding 4) and finally any of the remaining vertices (0, 1, 2).   So how do we find this sequence of picking vertices as starting points of DFS?  Unfortunately, there is no direct way for getting this sequence. However, if we do a DFS of graph and store vertices according to their finish times, we make sure that the finish time of a vertex that connects to other SCCs (other that its own SCC), will always be greater than finish time of vertices in the other SCC (See this for proof).  For example, in DFS of above example graph, finish time of 0 is always greater than 3 and 4 (irrespective of the sequence of vertices considered for DFS).  And finish time of 3 is always greater than 4.  DFS doesn’t guarantee about other vertices, for example finish times of 1 and 2 may be smaller or greater than 3 and 4 depending upon the sequence of vertices considered for DFS. So to use this property, we do DFS traversal of complete graph and push every finished vertex to a stack. In stack, 3 always appears after 4, and 0 appear after both 3 and 4.
In the next step, we reverse the graph.  Consider the graph of SCCs.  In the reversed graph, the edges that connect two components are reversed.  So the SCC {0, 1, 2} becomes sink and the SCC {4} becomes source.  As discussed above, in stack, we always have 0 before 3 and 4.  So if we do a DFS of the reversed graph using sequence of vertices in stack, we process vertices from sink to source (in reversed graph). That is what we wanted to achieve and that is all needed to print SCCs one by one.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Following is C++ implementation of Kosaraju’s algorithm.

C++







filter_none

Transitive closure of a graph


Given a directed graph, find out if a vertex j is reachable from another vertex i for all vertex pairs (i, j) in the given graph.  Here reachable mean that there is a path from vertex i to j.  The reach-ability matrix is called transitive closure of a graph.
For example, consider below graph


Find the number of islands | Set 1 (Using DFS)



Given a boolean 2D matrix, find the number of islands.  A group of connected 1s forms an island. For example, the below matrix contains 5 islands
Example:
Input : mat[][] = {{1, 1, 0, 0, 0},
                   {0, 1, 0, 0, 1},
                   {1, 0, 0, 1, 1},
                   {0, 0, 0, 0, 0},
                   {1, 0, 1, 0, 1} 
Output : 5

This is a variation of the standard problem: “Counting the number of connected components in an undirected graph”.






Before we go to the problem, let us understand what is a connected component. A connected component of an undirected graph is a subgraph in which every two vertices are connected to each other by a path(s), and which is connected to no other vertices outside the subgraph.
For example, the graph shown below has three connected components. 


Count all possible walks from a source to a destination with exactly k edges


Given a directed graph and two vertices ‘u’ and ‘v’ in it, count all possible walks from ‘u’ to ‘v’ with exactly k  edges on the walk.  
The graph is given as adjacency matrix representation where  value of graph[i][j] as 1 indicates that there is an edge from vertex i to vertex j and a value 0 indicates no edge from i to j.
For example consider the following graph.  Let source ‘u’ be vertex 0, destination ‘v’ be 3  and k be 2.  The output should be 2 as there are two walk from 0 to 3 with exactly 2 edges. The walks are {0, 2, 3} and {0, 1, 3}







Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

A simple solution is to start from u, go to all adjacent vertices and recur for adjacent vertices with k as k-1, source as adjacent vertex and destination as v.  Following is the implementation of this simple solution.

C++







filter_none

Euler Circuit in a Directed Graph


Eulerian Path is a path in graph that visits every edge exactly once. Eulerian Circuit is an Eulerian Path which starts and ends on the same vertex. 
A graph is said to be eulerian if it has a eulerian cycle.  We have discussed eulerian circuit for an undirected graph.  In this post, the same is discussed for a directed graph.
For example, the following graph has eulerian cycle as {1, 0, 3, 4, 0, 2, 1}






How to check if a directed graph is eulerian?
A directed graph has an eulerian cycle if following conditions are true (Source: Wiki)
1) All vertices with nonzero degree belong to a single strongly connected component.
2) In degree is equal to the out degree for every vertex.
We can detect singly connected component using Kosaraju’s DFS based simple algorithm.
To compare in degree and out-degree, we need to store in degree and out-degree of every vertex.  Out degree can be obtained by the size of an adjacency list.  In degree can be stored by creating an array of size equal to the number of vertices. 


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Biconnected Components


A biconnected component is a maximal biconnected subgraph.
Biconnected Graph is already discussed here. In this article, we will see how to find biconnected component in a graph using algorithm by John Hopcroft and Robert Tarjan.






In above graph, following are the biconnected components:

4–2 3–4 3–1 2–3 1–2
8–9
8–5 7–8 5–7
6–0 5–6 1–5 0–1
10–11

Algorithm is based on Disc and Low Values discussed in Strongly Connected Components Article.
Idea is to store visited edges in a stack while DFS on a graph and keep looking for Articulation Points (highlighted in above figure). As soon as an Articulation Point u is found, all edges visited while DFS from node u onwards will form one biconnected component. When DFS completes for one connected component, all edges present in stack will form a biconnected component.
If there is no Articulation Point in graph, then graph is biconnected and so there will be one biconnected component which is the graph itself.

C++






filter_none

Tarjan’s Algorithm to find Strongly Connected Components


A directed graph is strongly connected if there is a path between all pairs of vertices. A strongly connected component (SCC) of a directed graph is a maximal strongly connected subgraph. For example, there are 3 SCCs in the following graph.

We have discussed Kosaraju’s algorithm for strongly connected components. The previously discussed algorithm requires two DFS traversals of a Graph. In this post, Tarjan’s algorithm is discussed that requires only one DFS traversal.





Tarjan Algorithm is based on following facts:
1. DFS search produces a DFS tree/forest
2. Strongly Connected Components form subtrees of the DFS tree.
3. If we can find the head of such subtrees, we can print/store all the nodes in that subtree (including head) and that will be one SCC.
4. There is no back edge from one SCC to another (There can be cross edges, but cross edges will not be used while processing the graph).
To find head of a SCC, we calculate disc and low array (as done for articulation point, bridge, biconnected component).  As discussed in the previous posts, low[u] indicates earliest visited vertex (the vertex with minimum discovery time) that can be reached from subtree rooted with u. A node u is head if disc[u] = low[u].
Below image is an illustration of the approach:
 
Strongly Connected Component relates to directed graph only, but Disc and Low values relate to both directed and undirected graph, so in above pic we have taken an undirected graph.
In above Figure, we have shown a graph and its one of DFS tree (There could be different DFS trees on same graph depending on order in which edges are traversed).
In DFS tree, continuous arrows are tree edges and dashed arrows are back edges (DFS Tree Edges
Disc and Low values are showin in Figure for every node as (Disc/Low).
Disc: This is the time when a node is visited 1st time while DFS traversal. For nodes A, B, C, .., J in DFS tree, Disc values are 1, 2, 3, .., 10.
Low: In DFS tree, Tree edges take us forward, from ancestor node to one of its descendants. For example, from node C, tree edges can take us to node node G, node I etc. Back edges take us backward, from a descendant node to one of its ancestors. For example, from node G, Back edges take us to E or C. If we look at both Tree and Back edge together, then we can see that if we start traversal from one node, we may go down the tree via Tree edges and then go up via back edges. For example, from node E, we can go down to G and then go up to C. Similarly from E, we can go down to I or J and then go up to F. “Low” value of a node tells the topmost reachable ancestor (with minimum possible Disc value) via the subtree of that node. So for any node, Low value equal to its Disc value anyway (A node is ancestor of itself). Then we look into its subtree and see if there is any node which can take us to any of its ancestor. If there are multiple back edges in subtree which take us to different ancestors, then we take the one with minimum Disc value (i.e. the topmost one). If we look at node F, it has two subtrees. Subtree with node G, takes us to E and C. The other subtree takes us back to F only. Here topmost ancestor is C where F can reach and so Low value of F is 3 (The Disc value of C).
Based on above discussion, it should be clear that Low values of B, C, and D are 1 (As A is the topmost node where B, C and D can reach). In same way, Low values of E, F, G are 3 and Low values of H, I, J are 6.
For any node u, when DFS starts, Low will be set to its Disc 1st.
Then later on DFS will be performed on each of its children v one by one, Low value of u can change it two case:
Case1 (Tree Edge): If node v is not visited already, then after DFS of v is complete, then minimum of low[u] and low[v] will be updated to low[u].
low[u] = min(low[u], low[v]);
Case 2 (Back Edge): When child v is already visited, then minimum of low[u] and Disc[v] will be updated to low[u].
low[u] = min(low[u], disc[v]);
In case two, can we take low[v] instead of disc[v] ?? . Answer is NO. If you can think why answer is NO, you probably understood the Low and Disc concept.

Same Low and Disc values help to solve other graph problems like articulation point, bridge and biconnected component.
To track the subtree rooted at head, we can use a stack (keep pushing node while visiting). When a head node found, pop all nodes from stack till you get head out of stack.
To make sure, we don’t consider cross edges, when we reach a node which is already visited, we should process the visited node only if it is present in stack, else ignore the node.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Graph Coloring | Set 1 (Introduction and Applications)


Graph coloring problem is to assign colors to certain elements of a graph subject to certain constraints. 
Vertex coloring is the most common graph coloring problem. The problem is, given m colors, find a way of coloring the vertices of a graph such that no two adjacent vertices are colored using same color. The other graph coloring problems like Edge Coloring (No vertex is incident to two edges of same color) and Face Coloring (Geographical Map Coloring) can be transformed into vertex coloring.
Chromatic Number: The smallest number of colors needed to color a graph G is called its chromatic number. For example, the following can be colored minimum 3 colors.







The problem to find chromatic number of a given graph is NP Complete.
Applications of Graph Coloring:
The graph coloring problem has huge number of applications.
1) Making Schedule or Time Table:  Suppose we want to make am exam schedule for a university. We have list different subjects and students enrolled in every subject. Many subjects would have common students (of same batch, some backlog students, etc).  How do we schedule the exam so that no two exams with a common student are scheduled at same time? How many minimum time slots are needed to schedule all exams? This problem can be represented as a graph where every vertex is a subject and an edge between two vertices mean there is a common student. So this is a graph coloring problem where minimum number of time slots is equal to the chromatic number of the graph.
2) Mobile Radio Frequency Assignment: When frequencies are assigned to towers, frequencies assigned to all towers at the same location must be different. How to assign frequencies with this constraint? What is the minimum number of frequencies needed? This problem is also an instance of graph coloring problem where every tower represents a vertex and an edge between two towers represents that they are in range of each other.
3) Sudoku:  Sudoku is also a variation of Graph coloring problem where every cell represents a vertex. There is an edge between two vertices if they are in same row or same column or same block.
4) Register Allocation:  In compiler optimization, register allocation is the process of assigning a large number of target program variables onto a small number of CPU registers. This problem is also a graph coloring problem.
5) Bipartite Graphs: We can check if a graph is Bipartite or not by coloring the graph using two colors. If a given graph is 2-colorable, then it is Bipartite, otherwise not. See this for more details.
6) Map Coloring: Geographical maps of countries or states where no two adjacent cities cannot be assigned same color. Four colors are sufficient to color any map (See Four Color Theorem)
There can be many more applications: For example the below reference video lecture has a case study at 1:18.
Akamai runs a network of thousands of servers and the servers are used to distribute content on Internet. They install a new software or update existing softwares pretty much every week. The update cannot be deployed on every server at the same time, because the server may have to be taken down for the install. Also, the update should not be done one at a time, because it will take a lot of time. There are sets of servers that cannot be taken down together, because they have certain critical functions. This is a typical scheduling application of graph coloring problem. It turned out that 8 colors were good enough to color the graph of 75000 nodes. So they could install updates in 8 passes.
We will soon be discussing different ways to solve the graph coloring problem.
References:
Lec 6 | MIT 6.042J Mathematics for Computer Science, Fall 2010 | Video Lecture
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Coloring a Cycle GraphEdge Coloring of a GraphGraph Coloring | Set 2 (Greedy Algorithm)Mathematics | Planar Graphs and Graph ColoringGraph Types and ApplicationsApplications of Graph Data Structurem Coloring Problem | Backtracking-5Convert the undirected graph into directed graph such that there is no path of length greater than 1Graph implementation using STL for competitive programming | Set 2 (Weighted graph)Detect cycle in the graph using degrees of nodes of graphApplications of Depth First SearchApplications of Breadth First TraversalKarger’s algorithm for Minimum Cut | Set 2 (Analysis and Applications)Applications of Minimum Spanning Tree ProblemBFS for Disconnected Graph

Article Tags : GraphGraph Coloring
Practice Tags : Graph 

thumb_up
14



To-do

Done



2.5


Based on 18 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Graph Coloring | Set 2 (Greedy Algorithm)


We introduced graph coloring and applications in previous post. As discussed in the previous post, graph coloring is widely used. Unfortunately, there is no efficient algorithm available for coloring a graph with minimum number of colors as the problem is a known NP Complete problem. There are approximate algorithms to solve the problem though. Following is the basic Greedy Algorithm to assign colors. It doesn’t guarantee to use minimum colors, but it guarantees an upper bound on the number of colors. The basic algorithm never uses more than d+1 colors where d is the maximum degree of a vertex in the given graph.
Basic Greedy Coloring Algorithm:

1. Color first vertex with first color.
2. Do following for remaining V-1 vertices.
….. a) Consider the currently picked vertex and color it with the
             lowest numbered color that has not been used on any previously
             colored vertices adjacent to it. If all previously used colors
             appear on vertices adjacent to v, assign a new color to it.






Following are C++ and Java implementations of the above Greedy Algorithm.

C++






filter_none

Travelling Salesman Problem | Set 1 (Naive and Dynamic Programming)



Travelling Salesman Problem (TSP): Given a set of cities and distance between every pair of cities, the problem is to find the shortest possible route that visits every city exactly once and returns to the starting point.
Note the difference between Hamiltonian Cycle and TSP. The Hamiltoninan cycle problem is to find if there exist a tour that visits every city exactly once. Here we know that Hamiltonian Tour exists (because the graph is complete) and in fact many such tours exist, the problem is to find a minimum weight Hamiltonian Cycle.

For example, consider the graph shown in figure on right side. A TSP tour in the graph is 1-2-4-3-1. The cost of the tour is 10+25+30+15 which is 80.
The problem is a famous NP hard problem. There is no polynomial time know solution for this problem.
Following are different solutions for the traveling salesman problem.
Naive Solution:
1) Consider city 1 as the starting and ending point.
2) Generate all (n-1)! Permutations of cities.
3) Calculate cost of every permutation and keep track of minimum cost permutation.
4) Return the permutation with minimum cost.
Time Complexity: Θ(n!)
Dynamic Programming:
Let the given set of vertices be {1, 2, 3, 4,….n}. Let us consider 1 as starting and ending point of output. For every other vertex i (other than 1), we find the minimum cost path with 1 as the starting point, i as the ending point and all vertices appearing exactly once. Let the cost of this path be cost(i), the cost of corresponding Cycle would be cost(i) + dist(i, 1) where dist(i, 1) is the distance from i to 1. Finally, we return the minimum of all [cost(i) + dist(i, 1)] values. This looks simple so far. Now the question is how to get cost(i)?
To calculate cost(i) using Dynamic Programming, we need to have some recursive relation in terms of sub-problems. Let us define a term C(S, i) be the cost of the minimum cost path visiting each vertex in set S exactly once, starting at 1 and ending at i.
We start with all subsets of size 2 and calculate C(S, i) for all subsets where S is the subset, then we calculate C(S, i) for all subsets S of size 3 and so on. Note that 1 must be present in every subset.
If size of S is 2, then S must be {1, i},
 C(S, i) = dist(1, i) 
Else if size of S is greater than 2.
 C(S, i) = min { C(S-{i}, j) + dis(j, i)} where j belongs to S, j != i and j != 1.

For a set of size n, we consider n-2 subsets each of size n-1 such that all subsets don’t have nth in them.
Using the above recurrence relation, we can write dynamic programming based solution. There are at most O(n*2n) subproblems, and each one takes linear time to solve. The total running time is therefore O(n2*2n). The time complexity is much less than O(n!), but still exponential. Space required is also exponential. So this approach is also infeasible even for slightly higher number of vertices.
We will soon be discussing approximate algorithms for travelling salesman problem.



Next Article: Traveling Salesman Problem | Set 2
References:
http://www.lsi.upc.edu/~mjserna/docencia/algofib/P07/dynprog.pdf
http://www.cs.berkeley.edu/~vazirani/algorithms/chap6.pdf
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Travelling Salesman Problem | Set 2 (Approximate using MST)Travelling Salesman Problem implementation using BackTrackingHow to solve a Dynamic Programming Problem ?Understanding The Coin Change Problem  With Dynamic ProgrammingVertex Cover Problem | Set 2  (Dynamic Programming Solution for Tree)Traveling Salesman Problem (TSP) ImplementationDynamic Programming | High-effort vs. Low-effort Tasks ProblemDynamic Programming on Trees | Set-1Dynamic Programming on Trees | Set 2Bitmasking and Dynamic Programming | Set-2 (TSP)Greedy approach vs Dynamic programmingDynamic Programming vs Divide-and-ConquerConvert N to M with given operations using dynamic programmingDynamic Programming | Building BridgesTop 20 Dynamic Programming Interview Questions

Article Tags : Bit MagicDynamic ProgrammingGraphGoogleMicrosoftNPHardOpera
Practice Tags :  MicrosoftGoogleOperaDynamic ProgrammingBit MagicGraph 

thumb_up
13



To-do

Done



4.2


Based on 84 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Travelling Salesman Problem | Set 2 (Approximate using MST)


We introduced Travelling Salesman Problem and discussed Naive and Dynamic Programming Solutions for the problem in the previous post,.  Both of the solutions are infeasible.  In fact, there is no polynomial time solution available for this problem as the problem is a known NP-Hard problem. There are approximate algorithms to solve the problem though. The approximate algorithms work only if the problem instance satisfies Triangle-Inequality.
Triangle-Inequality: The least distant path to reach a vertex j from i is always to reach j directly from i, rather than through some other vertex k (or vertices), i.e., dis(i, j) is always less than or equal to dis(i, k) + dist(k, j). The Triangle-Inequality holds in many practical situations.
When the cost function satisfies the triangle inequality, we can design an approximate algorithm for TSP that returns a tour whose cost is never more than twice the cost of an optimal tour.  The idea is to use Minimum Spanning Tree (MST).  Following is the MST based algorithm.
Algorithm:
1)    Let 1 be the starting and ending point for salesman.
2)    Construct MST from with 1 as root using Prim’s Algorithm.
3)    List vertices visited in preorder walk of the constructed MST and add 1 at the end.





Let us consider the following example.  The first diagram is the given graph. The second diagram shows MST constructed with 1 as root.  The preorder traversal of MST is 1-2-4-3.  Adding 1 at the end gives 1-2-4-3-1 which is the output of this algorithm.  
 


Hamiltonian Cycle | Backtracking-6


Hamiltonian Path in an undirected graph is a path that visits each vertex exactly once. A Hamiltonian cycle (or Hamiltonian circuit) is a Hamiltonian Path such that there is an edge (in the graph) from the last vertex to the first vertex of the Hamiltonian Path. Determine whether a given graph contains Hamiltonian Cycle or not. If it contains, then prints the path.  Following are the input and output of the required function.
Input:
A 2D array graph[V][V] where V is the number of vertices in graph and graph[V][V] is adjacency matrix representation of the graph. A value graph[i][j] is 1 if there is a direct edge from i to j, otherwise graph[i][j] is 0.
Output:
An array path[V] that should contain the Hamiltonian Path. path[i] should represent the ith vertex in the Hamiltonian Path. The code should also return false if there is no Hamiltonian Cycle in the graph.





For example, a Hamiltonian Cycle in the following graph is {0, 1, 2, 4, 3, 0}.
(0)--(1)--(2)
 |   / \   |
 |  /   \  | 
 | /     \ |
(3)-------(4)

And the following graph doesn’t contain any Hamiltonian Cycle.
(0)--(1)--(2)
 |   / \   |
 |  /   \  | 
 | /     \ |
(3)      (4) 


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

Naive Algorithm
Generate all possible configurations of vertices and print a configuration that satisfies the given constraints. There will be n! (n factorial) configurations.
while there are untried conflagrations
{
   generate the next configuration
   if ( there are edges between two consecutive vertices of this
      configuration and there is an edge from the last vertex to 
      the first ).
   {
      print this configuration;
      break;
   }
}

Backtracking Algorithm
Create an empty path array and add vertex 0 to it. Add other vertices, starting from the vertex 1. Before adding a vertex, check for whether it is adjacent to the previously added vertex and not already added. If we find such a vertex, we add the vertex as part of the solution. If we do not find a vertex then we return false.
Implementation of Backtracking solution
Following are implementations of the Backtracking solution.

C++







filter_none

Vertex Cover Problem | Set 1 (Introduction and Approximate Algorithm)


A vertex cover of an undirected graph is a subset of its vertices such that for every edge (u, v) of the graph, either ‘u’ or ‘v’ is in vertex cover.   Although the name is Vertex Cover, the set covers all edges of the given graph. Given an undirected graph, the vertex cover problem is to find minimum size vertex cover. 
Following are some examples.


K Centers Problem | Set 1 (Greedy Approximate Algorithm)


Given n cities and distances between every pair of cities, select k cities to place warehouses (or ATMs or Cloud Server) such that the maximum distance of a city to a warehouse (or ATM  or Cloud Server) is minimized. 
For example consider the following four cities, 0, 1, 2 and 3 and distances between them, how do place 2 ATMs among these 4 cities so that the maximum distance of a city to an ATM is minimized.






There is no polynomial time solution available for this problem as the problem is a known NP-Hard problem. There is a polynomial time Greedy approximate algorithm, the greedy algorithm provides a solution which is never worse that twice the optimal solution.  The greedy solution works only if the distances between cities follow Triangular Inequality (Distance between two points is always smaller than sum of distances through a third point). 
The 2-Approximate Greedy Algorithm:
1) Choose the first center arbitrarily.
2) Choose remaining k-1 centers using the following criteria.
            Let c1, c2, c3, … ci be the already chosen centers. Choose
            (i+1)’th center by picking the city which is farthest from already
            selected centers, i.e, the point p which has following value as maximum
                           Min[dist(p, c1), dist(p, c2), dist(p, c3), …. dist(p, ci)]

Example (k = 3 in the above shown Graph)
a) Let the first arbitrarily picked vertex be 0. 
b) The next vertex is 1 because 1 is the farthest vertex from 0. 
c) Remaining cities are 2 and 3. Calculate their distances from already selected centers (0 and 1).  The greedy algorithm basically calculates following values.
        Minimum of all distanced from 2 to already considered centers
        Min[dist(2, 0), dist(2, 1)] = Min[7, 8] = 7
        Minimum of all distanced from 3 to already considered centers
        Min[dist(3, 0), dist(3, 1)] = Min[6, 5] = 5
        After computing the above values, the city 2 is picked as the value corresponding to 2 is maximum.




Note that the greedy algorithm doesn’t give best solution for k = 2 as this is just an approximate algorithm with bound as twice of optimal.
Proof that the above greedy algorithm is 2 approximate.
Let OPT be the maximum distance of a city from a center in the Optimal solution.  We need to show that the maximum distance obtained from Greedy algorithm is 2*OPT.
The proof can be done using contradiction.
a) Assume that the distance from the furthest point to all centers is > 2·OPT.
b) This means that distances between all centers are also > 2·OPT.
c) We have k + 1 points with distances > 2·OPT between every pair.
d) Each point has a center of the optimal solution with distance <= OPT to it. 
e) There exists a pair of points with the same center X in the optimal solution (pigeonhole principle: k optimal centers, k+1 points)
f) The distance between them is at most 2·OPT (triangle inequality) which is a contradiction.
Source:
http://algo2.iti.kit.edu/vanstee/courses/kcenter.pdf
This article is contributed by Harshit. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Set Cover Problem | Set 1 (Greedy Approximate Algorithm)Vertex Cover Problem | Set 1 (Introduction and Approximate Algorithm)Travelling Salesman Problem | Set 2 (Approximate using MST)Activity Selection Problem | Greedy Algo-1Boruvka's algorithm | Greedy Algo-9Greedy Algorithm for Egyptian FractionGraph Coloring | Set 2 (Greedy Algorithm)Dijkstra's shortest path algorithm | Greedy Algo-7Greedy Algorithm to find Minimum number of CoinsDijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2Hungarian Algorithm for Assignment Problem | Set 1 (Introduction)Ford-Fulkerson Algorithm for Maximum Flow ProblemWidest Path Problem | Practical application of Dijkstra's AlgorithmCorrectness of Greedy Algorithms

Article Tags : GraphGreedy
Practice Tags : GreedyGraph 

thumb_up
1



To-do

Done



4.3


Based on 42 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Ford-Fulkerson Algorithm for Maximum Flow Problem



Given a graph which represents a flow network where every edge has a capacity. Also given two vertices source  ‘s’ and sink ‘t’ in the graph, find the maximum possible flow from s to t with following constraints:
a) Flow on an edge doesn’t exceed the given capacity of the edge.
b) Incoming flow is equal to outgoing flow for every vertex except s and t.
For example, consider the following graph from CLRS book.

The maximum possible flow in the above graph is 23.


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







Prerequisite : Max Flow Problem Introduction
Ford-Fulkerson Algorithm 
The following is simple idea of Ford-Fulkerson algorithm:
1) Start with initial flow as 0.
2) While there is a augmenting path from source to sink. 
           Add this path-flow to flow.
3) Return flow.
Time Complexity: Time complexity of the above algorithm is O(max_flow * E). We run a loop while there is an augmenting path. In worst case, we may add 1 unit flow in every iteration. Therefore the time complexity becomes O(max_flow * E).
How to implement the above simple algorithm? 
Let us first define the concept of Residual Graph which is needed for understanding the implementation.
Residual Graph of a flow network is a graph which indicates additional possible flow. If there is a path from source to sink in residual graph, then it is possible to add flow. Every edge of a residual graph has a value called residual capacity which is equal to original capacity of the edge minus current flow. Residual capacity is basically the current capacity of the edge.
Let us now talk about implementation details. Residual capacity is 0 if there is no edge between two vertices of residual graph. We can initialize the residual graph as original graph as there is no initial flow and initially residual capacity is equal to original capacity. To find an augmenting path, we can either do a BFS or DFS of the residual graph. We have used BFS in below implementation. Using BFS, we can find out if there is a path from source to sink. BFS also builds parent[] array. Using the parent[] array, we traverse through the found path and find possible flow through this path by finding minimum residual capacity along the path. We later add the found path flow to overall flow.
The important thing is, we need to update residual capacities in the residual graph. We subtract path flow from all edges along the path and we add path flow along the reverse edges We need to add path flow along reverse edges because may later need to send flow in reverse direction (See following link for example).
https://www.geeksforgeeks.org/max-flow-problem-introduction/
Below is the implementation of Ford-Fulkerson algorithm. To keep things simple, graph is represented as a 2D matrix.

C++






filter_none

Find maximum number of edge disjoint paths between two vertices


Given a directed graph and two vertices in it, source ‘s’ and destination ‘t’, find out the maximum number of edge disjoint paths from s to t. Two paths are said edge disjoint if they don’t share any edge.

There can be maximum two edge disjoint paths from source 0 to destination 7 in the above graph. Two edge disjoint paths are highlighted below in red and blue colors are 0-2-6-7 and 0-3-6-5-7. 






Note that the paths may be different, but the maximum number is same.  For example, in the above diagram, another possible set of paths is 0-1-2-6-7 and 0-3-6-5-7 respectively.
This problem can be solved by reducing it to maximum flow problem.  Following are steps.
1) Consider the given source and destination as source and sink in flow network. Assign unit capacity to each edge.
2) Run Ford-Fulkerson algorithm to find the maximum flow from source to sink.
3) The maximum flow is equal to the maximum number of edge-disjoint paths.
When we run Ford-Fulkerson, we reduce the capacity by a unit.  Therefore, the edge can not be used again. So the maximum flow is equal to the maximum number of edge-disjoint paths.
Following is the implementation of the above algorithm.  Most of the code is taken from  here.

C/C++







filter_none

Find minimum s-t cut in a flow network


In a flow network, an s-t cut is a cut that requires the source ‘s’ and the sink ‘t’ to be in different subsets, and it consists of edges going from the source’s side to the sink’s side. The capacity of an s-t cut is defined by the sum of the capacity of each edge in the cut-set. (Source: Wiki)
The problem discussed here is to find minimum capacity s-t cut of the given network. Expected output is all edges of the minimum cut.
For example, in the following flow network, example s-t cuts are {{0 ,1}, {0, 2}}, {{0, 2}, {1, 2}, {1, 3}}, etc.  The minimum s-t cut is {{1, 3}, {4, 3}, {4 5}} which has capacity as 12+7+4  = 23.

Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.







We strongly recommend to read the below post first.
Ford-Fulkerson Algorithm for Maximum Flow Problem
Minimum Cut and Maximum Flow
Like Maximum Bipartite Matching, this is another problem which can solved using Ford-Fulkerson Algorithm. This is based on max-flow min-cut theorem.
The max-flow min-cut theorem states that in a flow network, the amount of maximum flow is equal to capacity of the minimum cut.  See CLRS book for proof of this theorem.
From Ford-Fulkerson, we get capacity of minimum cut.  How to print all edges that form the minimum cut?  The idea is to use residual graph. 
Following are steps to print all edges of the minimum cut.
1) Run Ford-Fulkerson algorithm and consider the final residual graph.
2) Find the set of vertices that are reachable from the source in the residual graph. 
3) All edges which are from a reachable vertex to non-reachable vertex are minimum cut edges. Print all such edges.
Following is the implementation of the above approach.

C++







filter_none

Maximum Bipartite Matching


A matching in a Bipartite Graph is a set of the edges chosen in such a way that no two edges share an endpoint. A maximum matching is a matching of maximum size (maximum number of edges).  In a  maximum matching, if any edge is added to it, it is no longer a matching. There can be more than one maximum matchings for a given Bipartite Graph.  
Why do we care?
There are many real world problems that can be formed as Bipartite Matching. For example, consider the following problem:
There are M job applicants and N jobs. Each applicant has a subset of jobs that he/she is interested in. Each job opening can only accept one applicant and a job applicant can be appointed for only one job. Find an assignment of jobs to applicants in such that as many applicants as possible get jobs.






We strongly recommend to read the following post first.
Ford-Fulkerson Algorithm for Maximum Flow Problem
Maximum Bipartite Matching and Max Flow Problem
Maximum Bipartite Matching (MBP) problem can be solved by converting it into a flow network (See this video to know how did we arrive this conclusion).   Following are the steps.
1) Build a Flow Network
There must be a source and sink in a flow network.  So we add a source and add edges from source to all applicants.  Similarly, add edges from all jobs to sink. The capacity of every edge is marked as 1 unit.
 


Channel Assignment Problem


There are M transmitter and N receiver stations. Given a matrix that keeps track of the number of packets to be transmitted from a given transmitter to a receiver. If the (i; j)-th entry of the matrix is k, it means at that time the station i has k packets for transmission to station j.
During a time slot, a transmitter can send only one packet and a receiver can receive only one packet.  Find the channel assignments so that maximum number of packets are transferred from transmitters to receivers during the next time slot.
Example:
0 2 0
3 0 1
2 4 0
The above is the input format. We call the above matrix M. Each value M[i; j] represents the number of packets Transmitter ‘i’ has to send to Receiver ‘j’. The output should be:
The number of maximum packets sent in the time slot is 3
T1 -> R2
T2 -> R3
T3 -> R1 
Note that the maximum number of packets that can be transferred in any slot is min(M, N).





Algorithm:
The channel assignment problem between sender and receiver can be easily transformed into Maximum Bipartite Matching(MBP) problem that can be solved by converting it into a flow network.
Step 1: Build a Flow Network
There must be a source and sink in a flow network. So we add a dummy source and add edges from source to all senders. Similarly, add edges from all receivers to dummy sink. The capacity of all added edges is marked as 1 unit.
Step 2: Find the maximum flow.
We use Ford-Fulkerson algorithm to find the maximum flow in the flow network built in step 1. The maximum flow is actually the maximum number of packets that can be transmitted without bandwidth interference in a time slot.
Implementation:
Let us first define input and output forms. Input is in the form of Edmonds matrix which is a 2D array ‘table[M][N]‘ with M rows (for M senders) and N columns (for N receivers). The value table[i][j] is the number of packets that has to be sent from transmitter ‘i’ to receiver ‘j’. Output is the maximum number of packets that can be transmitted without bandwidth interference in a time slot.
A simple way to implement this is to create a matrix that represents adjacency matrix representation of a directed graph with M+N+2 vertices. Call the fordFulkerson() for the matrix. This implementation requires O((M+N)*(M+N)) extra space.
Extra space can be reduced and code can be simplified using the fact that the graph is bipartite. The idea is to use DFS traversal to find a receiver for a transmitter (similar to augmenting path in Ford-Fulkerson). We call bpm() for every applicant, bpm() is the DFS based function that tries all possibilities to assign a receiver to the sender. In bpm(), we one by one try all receivers that a sender ‘u’ is interested in until we find a receiver, or all receivers are tried without luck.
For every receiver we try, we do following:
If a receiver is not assigned to anybody, we simply assign it to the sender and return true. If a receiver is assigned to somebody else say x, then we recursively check whether x can be assigned some other receiver. To make sure that x doesn’t get the same receiver again, we mark the receiver ‘v’ as seen before we make recursive call for x. If x can get other receiver, we change the sender for receiver ‘v’ and return true. We use an array maxR[0..N-1] that stores the senders assigned to different receivers.
If bmp() returns true, then it means that there is an augmenting path in flow network and 1 unit of flow is added to the result in maxBPM().
Time and space complexity analysis:
In case of bipartite matching problem, F ? |V| since there can be only |V| possible edges coming out from source node. So the total running time is O(m’n) = O((m + n)n). The space complexity is also substantially reduces from O ((M+N)*(M+N)) to just a single dimensional array of size M thus storing the mapping between M and N.

C






filter_none

Find if an array of strings can be chained to form a circle | Set 1


Given an array of strings, find if the given strings can be chained to form a circle.  A string X can be put before another string Y in circle if the last character of X is same as first character of Y.
Examples:
Input: arr[] = {"geek", "king"}
Output: Yes, the given strings can be chained.
Note that the last character of first string is same
as first character of second string and vice versa is
also true.

Input: arr[] = {"for", "geek", "rig", "kaf"}
Output: Yes, the given strings can be chained.
The strings can be chained as "for", "rig", "geek" 
and "kaf"

Input: arr[] = {"aab", "bac", "aaa", "cda"}
Output: Yes, the given strings can be chained.
The strings can be chained as "aaa", "aab", "bac" 
and "cda"

Input: arr[] = {"aaa", "bbb", "baa", "aab"};
Output: Yes, the given strings can be chained.
The strings can be chained as "aaa", "aab", "bbb" 
and "baa"

Input: arr[] = {"aaa"};
Output: Yes

Input: arr[] = {"aaa", "bbb"};
Output: No

Input  : arr[] = ["abc", "efg", "cde", "ghi", "ija"]
Output : Yes
These strings can be reordered as, “abc”, “cde”, “efg”,
“ghi”, “ija”

Input : arr[] = [“ijk”, “kji”, “abc”, “cba”]
Output : No



Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Given a sorted dictionary of an alien language, find order of characters


Given a sorted dictionary (array of words) of an alien language, find order of characters in the language.
Examples:
Input:  words[] = {"baa", "abcd", "abca", "cab", "cad"}
Output: Order of characters is 'b', 'd', 'a', 'c'
Note that words are sorted and in the given language "baa" 
comes before "abcd", therefore 'b' is before 'a' in output.
Similarly we can find other orders.

Input:  words[] = {"caa", "aaa", "aab"}
Output: Order of characters is 'c', 'a', 'b'


Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.

The idea is to create a graph of characters and then find topological sorting of the created graph.  Following are the detailed steps.





1) Create a graph g with number of vertices equal to the size of alphabet in the given alien language. For example, if the alphabet size is 5, then there can be 5 characters in words.  Initially there are no edges in graph.
2) Do following for every pair of adjacent words in given sorted array.
…..a) Let the current pair of words be word1 and word2. One by one compare characters of both words and find the first mismatching characters.
…..b) Create an edge in g from mismatching character of word1 to that of word2.
3) Print topological sorting of the above created graph.
Following is the implementation of the above algorithm.

C++







filter_none

Karger’s algorithm for Minimum Cut | Set 1 (Introduction and Implementation)


Given an undirected and unweighted graph, find the smallest cut (smallest number of edges that disconnects the graph into two components).
The input graph may have parallel edges.
For example consider the following example, the smallest cut has 2 edges.

A Simple Solution use Max-Flow based s-t cut algorithm to find minimum cut. Consider every pair of vertices as source ‘s’ and sink ‘t’, and call minimum s-t cut algorithm to find the s-t cut.  Return minimum of all s-t cuts.   Best possible time complexity of this algorithm is O(V5) for a graph. [How? there are total possible V2 pairs and s-t cut algorithm for one pair takes O(V*E) time and  E = O(V2)].  





Below is simple Karger’s Algorithm for this purpose.  Below Karger’s algorithm can be implemented in O(E) = O(V2) time.
1)  Initialize contracted graph CG as copy of original graph
2)  While there are more than 2 vertices.
      a) Pick a random edge (u, v) in the contracted graph.
      b) Merge (or contract) u and v into a single vertex (update 
         the contracted graph).
      c) Remove self-loops
3) Return cut represented by two vertices.

Let us understand above algorithm through the example given.
Let the first randomly picked vertex be ‘a‘ which connects vertices 0 and 1.  We remove this edge and contract the graph (combine vertices 0 and 1).  We get the following graph.

Let the next randomly picked edge be ‘d’. We remove this edge and combine vertices (0,1) and 3.

We need to remove self-loops in the graph.  So we remove edge ‘c’

Now graph has two vertices, so we stop.  The number of edges in the resultant graph is the cut produced by Karger’s algorithm.
Karger’s algorithm is a Monte Carlo algorithm and cut produced by it may not be minimum.  For example, the following diagram shows that a different order of picking random edges produces a min-cut of size 3.

Below is C++ implementation of above algorithm. The input graph is represented as a collection of edges and union-find data structure is used to keep track of components. 





filter_none

Karger’s algorithm for Minimum Cut | Set 2 (Analysis and Applications)


We have introduced and discussed below Karger’s algorithm in set 1.
1)  Initialize contracted graph CG as copy of original graph
2)  While there are more than 2 vertices.
      a) Pick a random edge (u, v) in the contracted graph.
      b) Merge (or contract) u and v into a single vertex (update 
         the contracted graph).
      c) Remove self-loops
3) Return cut represented by two vertices.
As discussed in the previous post, Karger’s algorithm doesn’t always find min cut.  In this post, the probability of finding min-cut is discussed. 
 Probability that the cut produced by Karger’s Algorithm is Min-Cut is greater than or equal to 1/(n2)





Proof:
Let there be a unique Min-Cut of given graph and let there be C edges in the Min-Cut and the edges be {e1, e2, e3, .. ec}. The Karger’s algorithm would produce this Min-Cut if and only if none of the edges in set {e1, e2, e3, .. ec} is removed in iterations in the main while loop of above algorithm.

c is number of edges in min-cut
m is total number of edges
n is total number of vertices

S1 = Event that one of the edges in {e1, e2, 
     e3, .. ec} is chosen in 1st iteration.
S2 = Event that one of the edges in {e1, e2, 
     e3, .. ec} is chosen in 2nd iteration.
S3 = Event that one of the edges in {e1, e2, 
     e3, .. ec} is chosen in 3rd iteration.

..................
..................

The cut produced by Karger's algorithm would be a min-cut if none of the above
events happen.

So the required probability is P[S1' ∩ S2' ∩ S3' ∩  ............]
Probability that a min-cut edge is chosen in first iteration: 
Let us calculate  P[S1']
P[S1]  = c/m
P[S1'] = (1 - c/m)

Above value is in terms of m (or edges), let us convert 
it in terms of n (or vertices) using below 2 facts.. 

1) Since size of min-cut is c, degree of all vertices must be greater 
than or equal to c. 

2) As per Handshaking Lemma, sum of degrees of all vertices = 2m

From above two facts, we can conclude below.
  n*c <= 2m
    m >= nc/2

  P[S1] <= c / (cn/2)
        <= 2/n

  P[S1] <= c / (cn/2)
        <= 2/n

  P[S1'] >= (1-2/n) ------------(1)
Probability that a min-cut edge is chosen in second iteration:

P[S1' ∩  S2'] = P[S2' | S1' ] * P[S1']

In the above expression, we know value of P[S1'] >= (1-2/n)

P[S2' | S1'] is conditional probability that is, a min cut is 
not chosen in second iteration given that it is not chosen in first iteration

Since there are total (n-1) edges left now and number of cut edges is still c,
we can replace n by n-1 in inequality (1).  So we get.
  P[S2' | S1' ] >= (1 - 2/(n-1)) 

  P[S1' ∩  S2'] >= (1-2/n) x (1-2/(n-1))
Probability that a min-cut edge is chosen in all iterations: 

P[S1' ∩  S2' ∩ S3'  ∩.......... ∩ Sn-2']

>= [1 - 2/n] * [1 - 2/(n-1)] * [1 - 2/(n-2)] * [1 - 2/(n-3)] *...
                              ... * [1 - 2/(n - (n-4)] * [1 - 2/(n - (n-3)]

>= [(n-2)/n] * [(n-3)/(n-1)] * [(n-4)/(n-2)] * .... 2/4 * 2/3

>= 2/(n * (n-1))
>= 1/n2 
How to increase probability of success?
The above probability of success of basic algorithm is very less.  For example, for a graph with 10 nodes, the probability of finding the min-cut is greater than or equal to 1/100.   The probability can be increased by repeated runs of basic algorithm and return minimum of all cuts found.
Applications:
1) In war situation, a party would be interested in finding minimum number of links that break communication network of enemy.
2) The min-cut problem can be used to study reliability of a network (smallest number of edges that can fail).  
3) Study of network optimization (find a maximum flow).
4) Clustering problems (edges like associations rules) Matching problems (an NC algorithm for min-cut in directed graphs would result in an NC algorithm for maximum matching in bipartite graphs)
5) Matching problems (an NC algorithm for min-cut in directed graphs would result in an NC algorithm for maximum matching in bipartite graphs)
Sources: 
https://www.youtube.com/watch?v=-UuivvyHPas
 http://disi.unal.edu.co/~gjhernandezp/psc/lectures/02/MinCut.pdf
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Applications of Minimum Spanning Tree ProblemKarger's algorithm for Minimum Cut | Set 1 (Introduction and Implementation)Boruvka's algorithm for Minimum Spanning TreeKarp's minimum mean (or average) weight cycle algorithmReverse Delete Algorithm for Minimum Spanning TreeKruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2Graph Types and ApplicationsApplications of Breadth First TraversalApplications of Depth First SearchRandomized Algorithms | Set 2 (Classification and Applications)Graph Coloring | Set 1 (Introduction and Applications)Applications of Graph Data StructureRandomized Algorithms | Set 1 (Introduction and Analysis)Prim's algorithm using priority_queue in STLRelabel-to-front Algorithm

Article Tags : GraphRandomized
Practice Tags : Graph 

thumb_up
1



To-do

Done



3


Based on 2 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Hopcroft–Karp Algorithm for Maximum Matching | Set 1 (Introduction)


A matching in a Bipartite Graph is a set of the edges chosen in such a way that no two edges share an endpoint. A maximum matching is a matching of maximum size (maximum number of edges).  In a  maximum matching, if any edge is added to it, it is no longer a matching. There can be more than one maximum matching for a given Bipartite Graph.  
We have discussed importance of maximum matching and Ford Fulkerson Based approach for maximal Bipartite Matching in previous post.  Time complexity of the Ford Fulkerson based algorithm is O(V x E). 
Hopcroft Karp algorithm is an improvement that runs in O(√V x E) time. Let us define few terms before we discuss the algorithm





Free Node or Vertex: Given a matching M, a node that is not part of matching is called free node.  Initially all vertices as free (See first graph of below diagram). In second graph, u2 and v2 are free.  In third graph, no vertex is free.
Matching and Not-Matching edges: Given a matching M, edges that are part of matching are called Matching edges and edges that are not part of M (or connect free nodes) are called Not-Matching edges.  In first graph, all edges are non-matching.  In second graph, (u0, v1), (u1, v0) and (u3, v3) are matching and others not-matching.
Alternating Paths: Given a matching M, an alternating path is a path in which the edges belong alternatively to the matching and not matching.  All single edges paths are alternating paths. Examples of alternating paths in middle graph are u0-v1-u2 and u2-v1-u0-v2.
Augmenting path: Given a matching M, an augmenting path is an alternating path that starts from and ends on free vertices.  All single edge paths that start and end with free vertices are augmenting paths.  In below diagram, augmenting paths are highlighted with blue color.  Note that the augmenting path always has one extra matching edge.
The Hopcroft Karp algorithm is based on below concept.
A matching M is not maximum if there exists an augmenting path. It is also true other way, i.e, a matching is maximum if no augmenting path exists
So the idea is to one by one look for augmenting paths. And add the found paths to current matching. 
Hopcroft Karp Algorithm 
1) Initialize Maximal Matching M as empty.
2) While there exists an Augmenting Path p
     Remove matching edges of p from M and add not-matching edges of p to M
     (This increases size of M by 1 as p starts and ends with a free vertex)
3) Return M. 
Below diagram shows working of the algorithm.





In the initial graph all single edges are augmenting paths and we can pick in any order.  In the middle stage, there is only one augmenting path. We remove matching edges of this path from M and add not-matching edges.  In final matching, there are no augmenting paths so the matching is maximum.
Implementation of Hopcroft Karp algorithm is discussed in set 2.
Hopcroft–Karp Algorithm for Maximum Matching | Set 2 (Implementation)

References:
https://en.wikipedia.org/wiki/Hopcroft%E2%80%93Karp_algorithm
http://www.dis.uniroma1.it/~leon/tcs/lecture2.pdf
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Boruvka's algorithm for Minimum Spanning TreePush Relabel Algorithm | Set 1 (Introduction and Illustration)Floyd Warshall Algorithm | DP-16Union-Find Algorithm | Set 2 (Union By Rank and Path Compression)Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2Dijkstra's shortest path algorithm | Greedy Algo-7Dijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8Bellman–Ford Algorithm | DP-23Ford-Fulkerson Algorithm for Maximum Flow ProblemMaximum Bipartite MatchingFleury's Algorithm for printing Eulerian Path or CircuitFind maximum number of edge disjoint paths between two verticesJohnson's algorithm for All-pairs shortest pathsGraph Coloring | Set 1 (Introduction and Applications)Graph Coloring | Set 2 (Greedy Algorithm)

Article Tags : Graph
Practice Tags : Graph 

thumb_up
Be the First to upvote.



To-do

Done



3.5


Based on 10 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Hopcroft–Karp Algorithm for Maximum Matching | Set 1 (Introduction)


A matching in a Bipartite Graph is a set of the edges chosen in such a way that no two edges share an endpoint. A maximum matching is a matching of maximum size (maximum number of edges).  In a  maximum matching, if any edge is added to it, it is no longer a matching. There can be more than one maximum matching for a given Bipartite Graph.  
We have discussed importance of maximum matching and Ford Fulkerson Based approach for maximal Bipartite Matching in previous post.  Time complexity of the Ford Fulkerson based algorithm is O(V x E). 
Hopcroft Karp algorithm is an improvement that runs in O(√V x E) time. Let us define few terms before we discuss the algorithm





Free Node or Vertex: Given a matching M, a node that is not part of matching is called free node.  Initially all vertices as free (See first graph of below diagram). In second graph, u2 and v2 are free.  In third graph, no vertex is free.
Matching and Not-Matching edges: Given a matching M, edges that are part of matching are called Matching edges and edges that are not part of M (or connect free nodes) are called Not-Matching edges.  In first graph, all edges are non-matching.  In second graph, (u0, v1), (u1, v0) and (u3, v3) are matching and others not-matching.
Alternating Paths: Given a matching M, an alternating path is a path in which the edges belong alternatively to the matching and not matching.  All single edges paths are alternating paths. Examples of alternating paths in middle graph are u0-v1-u2 and u2-v1-u0-v2.
Augmenting path: Given a matching M, an augmenting path is an alternating path that starts from and ends on free vertices.  All single edge paths that start and end with free vertices are augmenting paths.  In below diagram, augmenting paths are highlighted with blue color.  Note that the augmenting path always has one extra matching edge.
The Hopcroft Karp algorithm is based on below concept.
A matching M is not maximum if there exists an augmenting path. It is also true other way, i.e, a matching is maximum if no augmenting path exists
So the idea is to one by one look for augmenting paths. And add the found paths to current matching. 
Hopcroft Karp Algorithm 
1) Initialize Maximal Matching M as empty.
2) While there exists an Augmenting Path p
     Remove matching edges of p from M and add not-matching edges of p to M
     (This increases size of M by 1 as p starts and ends with a free vertex)
3) Return M. 
Below diagram shows working of the algorithm.





In the initial graph all single edges are augmenting paths and we can pick in any order.  In the middle stage, there is only one augmenting path. We remove matching edges of this path from M and add not-matching edges.  In final matching, there are no augmenting paths so the matching is maximum.
Implementation of Hopcroft Karp algorithm is discussed in set 2.
Hopcroft–Karp Algorithm for Maximum Matching | Set 2 (Implementation)

References:
https://en.wikipedia.org/wiki/Hopcroft%E2%80%93Karp_algorithm
http://www.dis.uniroma1.it/~leon/tcs/lecture2.pdf
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Boruvka's algorithm for Minimum Spanning TreePush Relabel Algorithm | Set 1 (Introduction and Illustration)Floyd Warshall Algorithm | DP-16Union-Find Algorithm | Set 2 (Union By Rank and Path Compression)Kruskal’s Minimum Spanning Tree Algorithm | Greedy Algo-2Dijkstra's shortest path algorithm | Greedy Algo-7Dijkstra’s Algorithm for Adjacency List Representation | Greedy Algo-8Bellman–Ford Algorithm | DP-23Ford-Fulkerson Algorithm for Maximum Flow ProblemMaximum Bipartite MatchingFleury's Algorithm for printing Eulerian Path or CircuitFind maximum number of edge disjoint paths between two verticesJohnson's algorithm for All-pairs shortest pathsGraph Coloring | Set 1 (Introduction and Applications)Graph Coloring | Set 2 (Greedy Algorithm)

Article Tags : Graph
Practice Tags : Graph 

thumb_up
Be the First to upvote.



To-do

Done



3.5


Based on 10 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Word Ladder (Length of shortest chain to reach a target word)


Given a dictionary, and two words ‘start’ and ‘target’ (both of same length). Find length of the smallest chain from ‘start’ to ‘target’ if it exists, such that adjacent words in the chain only differ by one character and each word in the chain is a valid word i.e., it exists in the dictionary. It may be assumed that the ‘target’ word exists in dictionary and length of all dictionary words is same.
Example:
Input:  Dictionary = {POON, PLEE, SAME, POIE, PLEA, PLIE, POIN}
             start = TOON
             target = PLEA
Output: 7
Explanation: TOON - POON - POIN - POIE - PLIE - PLEE - PLEA

Recommended: Please try your approach on {IDE} first, before moving on to the solution.

The idea is to use BFS. We start from the given start word, traverse all words that adjacent (differ by one character) to it and keep doing so until we find the target word or we have traversed all words.





Below is C++ implementation of above idea.

C++






filter_none

Find same contacts in a list of contacts


Given a list of contacts containing username, email and phone number in any order. Identify the same contacts (i.e., same person having many different contacts) and output the same contacts together. 
Notes:
1) A contact can store its three fields in any order, i.e., phone number can appear before username or username can appear before phone number.
2) Two contacts are same if they have either same username or email or phone number.   





Example:
Input: contact[] = 
     { {"Gaurav", "gaurav@gmail.com", "gaurav@gfgQA.com"},
       { "Lucky", "lucky@gmail.com", "+1234567"},
       { "gaurav123", "+5412312", "gaurav123@skype.com"}.
       { "gaurav1993", "+5412312", "gaurav@gfgQA.com"}
     }
Output:
   0 2 3
   1 
contact[2] is same as contact[3] because they both have same
contact number.
contact[0] is same as contact[3] because they both have same
e-mail address.
Therefore, contact[0] and contact[2] are also same.

We strongly recommend you to minimize your browser and try this yourself first.
Input is basically an array of structures.  A structure contains three fields such that any field can represent any detail about a contact.
The idea is to first create a graph of contacts using given array.  In the graph, there is an edge between vertex i to vertex j if they both have either same username or same email or same phone number.   Once the graph is constructed, the task reduces to finding connected components in an undirected graph.  We can find connected components either by doing DFS or BFS starting from every unvisited vertex.  In below code, DFS is used.
Below is implementation of this idea.

C++







filter_none

Linearity of Expectation


Prerequisite : Random Variable
This post is about mathematical concepts like expectation, linearity of expectation. It covers one of the required topics to understand Randomized Algorithms.
Let us consider the following simple problem.





Given a fair dice with 6 faces, the dice is thrown n times, find expected value of sum of all results.
For example, if n = 2, there are total 36 possible outcomes. 

(1, 1), (1, 2), .... (1, 6)
(2, 1), (2, 2), .... (2, 6)
................
................
(6, 1), (6, 2), ..... (6, 6) 

Expected value of a discrete random variable is R defined as following. Suppose R can take value r1 with probability p1, value r2 with probability p2, and so on, up to value rk with probability pk. Then the expectation of this random variable R is defined as 

    E[R] = r1*p1 + r2*p2 + ... rk*pk
Let us calculate expected value for the above example. 
Expected Value of sum = 2*1/36 + 3*1/6 + .... + 7*1/36 + 
of two dice throws      3*1/36 + 4*1/6 + .... + 8*1/36 + 
                        ........................
                        .........................
                        7*1/36 + 8*1/6 + .... + 12*1/36     
                  
                      =  7  
The above way to solve the problem becomes difficult when there are more dice throws.
If we know about linearity of expectation, then we can quickly solve the above problem for any number of throws.
Linearity of Expectation: Let R1 and R2  be two discrete random variables on some probability space, then 
     E[R1 + R2] = E[R1] + E[R2] 
Using the above formula, we can quickly solve the dice problem.
Expected Value of sum of 2 dice throws = 2*(Expected value of one dice throw)
                                       = 2*(1/6 + 2/6 + .... 6/6)
                                       = 2*7/2
                                       = 7 

Expected value of sum for n dice throws is = n * 7/2 = 3.5 * n 
Some interesting facts about Linearly of Expectation:
1) Linearity of expectation holds for both dependent and independent events.  On the other hand the rule E[R1R2] = E[R1]*E[R2] is true only for independent events.
2) Linearity of expectation holds for any number of random variables on some probability space.  Let R1, R2, R3, … Rk be k random variables, then
E[R1 + R2 + R3 + … + Rk] = E[R1] + E[R2] + E[R3] + … + E[Rk]




Another example that can be easily solved with linearity of expectation:
Hat-Check Problem: Let there be group of n men where every man has one hat.  The hats are redistributed and every man gets a random hat back.  What is the expected number of men that get their original hat back.
Solution: Let Ri be a random variable, the value of random variable is 1 if i’th man gets the same hat back, otherwise 0.
So the expected number of men to get the right hat back is
  = E[R1] + E[R2]  +  .. + E[Rn] 
  = P(R1 = 1) + P(R2 = 1) + .... + P(Rn = 1) 
  [Here P(Ri = 1)  indicates probability that Ri is 1]
  = 1/n + 1/n + ... + 1/n 
  = 1

So on average 1 person gets the right hat back.
Exercise:
1) Given a fair coin, what is the expected number of heads when coin is tossed n times.
2) Balls and Bins: Suppose  we  have m balls, labeled i = 1, … , m and n bins, labeled j = 1, .. ,n.  Each ball is thrown into one of the bin independently and uniformly at random.
     a) What is the expected number of balls in every bin
     b) What is the expected number of empty bins.
3) Coupon Collector: Suppose there are n types of coupons in a lottery and each lot contains one coupon (with probability 1 = n each).  How many lots have to be bought (in expectation) until we have at least one coupon of each type.  
See following for solution of Coupon Collector.
Expected Number of Trials until Success
Linearity of expectation is useful in algorithms. For example, expected time complexity of random algorithms like randomized quick sort is evaluated using linearity of expectation (See this for reference).
References:
http://www.cse.iitd.ac.in/~mohanty/col106/Resources/linearity_expectation.pdf
http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/video-lectures/lecture-22-expectation-i/
This article is contributed by Shubham Gupta. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Expectation or expected value of an arrayNumber of subsequences with positive productCount the total number of triangles after Nth operationMinimum operations to make two numbers equalFermat's Factorization MethodAppend two elements to make the array satisfy the given conditionNumber of pairs in an array having sum equal to productMaximize the sum of differences of consecutive elements after removing exactly K elementsCount of numbers from range [L, R] that end with any of the given digitsFind the number obtained after concatenation of binary representation of M and NInvert the Kth most significant bit of NOptimal strategy for a Game with modificationsNumber of sub-strings  in a given binary string divisible by 2Satisfy the parabola when point (A, B) and the equation is given

Article Tags : MathematicalRandomized
Practice Tags : Mathematical 

thumb_up
Be the First to upvote.



To-do

Done



3.7


Based on 11 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Expected Number of Trials until Success


Consider the following famous puzzle.
In a country, all families want a boy. They keep having babies till a boy is born. What is the expected ratio of boys and girls in the country?
This puzzle can be easily solved if we know following interesting result in probability and expectation.





If probability of success is p in every trial, then expected number of trials until success is 1/p
Proof: Let R be a random variable that indicates number of trials until success.
The expected value of R is sum of following infinite series
E[R] = 1*p + 2*(1-p)*p + 3*(1-p)2*p + 4*(1-p)3*p + ........ 

Taking 'p' out
E[R] = p[1 + 2*(1-p) + 3*(1-p)2 + 4*(1-p)3 + .......] ---->(1)

Multiplying both sides with '(1-p)' and subtracting 
(1-p)*E[R] = p[1*(1-p) + 2*(1-p)2 + 3*(1-p)3 + .......] --->(2)

Subtracting (2) from (1), we get

p*E[R] = p[1 + (1-p) + (1-p)2 + (1-p)3 + ........] 

Canceling p from both sides
E[R] = [1 + (1-p) + (1-p)2 + (1-p)3 + ........] 

Above is an  infinite geometric  progression with ratio (1-p). 
Since (1-p) is less than, we can apply sum formula.
  E[R] = 1/[1 - (1-p)]
       = 1/p

Solution of Boys/Girls ratio puzzle:
Let us use the above result to solve the puzzle.  In the given puzzle, probability of success in every trial is 1/2 (assuming that girls and boys are equally likely).  
Let p be probability of having a baby boy.
Number of kids until a baby boy is born = 1/p 
                                        = 1/(1/2)
                                        = 2 
Since expected number of kids in a family is 2,
ratio of boys and girls is 50:50. 
Let us discuss another problem that uses above result.
Coupon Collector Problem:
Suppose there are n types of coupons in a lottery and each lot contains one coupon (with probability 1 = n each). How many lots have to be bought (in expectation) until we have at least one coupon of each type.
The solution of this problem is also based on above result.
Let Xi be the number of lots bought before i’th new coupon is collected.
Note that X1 is 1 as the first coupon is always a new coupon (not collected before).
Let ‘p’ be probability that 2nd coupon is collected in next buy. The value of p is (n-1)/n.  So the number of trials needed before 2nd new coupon is picked is 1/p which means n/(n-1).  [This is where we use above result]
Similarly, the number of trials needed before 3rd new coupon is collected is n/(n-2)




Using Linearity of expectation, 
we can say that the total number of expected trials = 
                  1 + n/(n-1) + n/(n-2) + n/(n-3) + .... + n/2 + n/1
               = n[1/n + 1/(n-1) + 1/(n-2) + 1/(n-3) + ....+ 1/2 + 1/1]
               = n * Hn
Here Hn is n-th Harmonic number

Since Logn <= Hn <= Logn + 1, we need to buy around 
nLogn lots to collect all n coupons. 
Exercise:
1) A 6 faced fair dice is thrown until a '5' is seen as result of dice throw. What is the expected number of throws?
2) What is the ratio of boys and girls in above puzzle if probability of a baby boy is 1/3?
Reference:
http://www.cse.iitd.ac.in/~mohanty/col106/Resources/linearity_expectation.pdf
http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/video-lectures/lecture-22-expectation-i/
Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above.







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Expected number of coin flips to get two heads in a row?Expected number of moves to reach the end of a board | Matrix ExponentiationExpected number of moves to reach the end of a board | Dynamic programmingExpectation or expected value of an arrayK'th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time)Count number of triplets with product equal to given number with duplicates allowedCount number of trailing zeros in Binary representation of a number using BitsetFind minimum number to be divided to make a number a perfect squareNumber of possible permutations when absolute difference between number of elements to the right and left are givenNumber of ways to split a binary number such that every part is divisible by 2Number of times the largest perfect square number can be subtracted from NGiven number of matches played, find number of teams in tournamentSmallest number dividing minimum number of elements in the array | Set 2Smallest number dividing minimum number of elements in the ArrayFind the number of positive integers less than or equal to N that have an odd number of digits

Article Tags : MathematicalRandomizedharmonic progression
Practice Tags : Mathematical 

thumb_up
3



To-do

Done



3


Based on 5 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Randomized Algorithms | Set 0 (Mathematical Background)


Conditional Probability Conditional probability P(A | B) indicates the probability of even ‘A’ happening given that the even B happened. 

We can easily understand above formula using below diagram. Since B has already happened, the sample space reduces to B.  So the probability of A happening becomes P(A ∩ B) divided by P(B)






Below is Bayes’s formula for conditional probability.

The formula provides relationship between P(A|B) and P(B|A). It is mainly derived form conditional probability formula discussed in the previous post. 
Consider the below forrmulas for conditional probabilities P(A|B) and P(B|A)


Since P(B ∩ A) = P(A ∩ B), we can replace P(A ∩ B) in first formula with P(B|A)P(A)
After replacing, we get the given formula.  Refer this for examples of Bayes’s formula. 
 
Random Variables: 
A random variable is actually a function that maps outcome of a random event (like coin toss) to a real value.  




Example : 
Coin tossing game : 
A player pays 50 bucks if result of coin
toss is "Head" 

The person gets 50 bucks if the result is
Tail. 

A random variable profit for person can 
be defined as below : 

Profit = +50 if Head
         -50 if Tail  

Generally gambling games are not fair for players, 
the organizer takes a share of profit for all 
arrangements. So expected profit is negative for 
a player in gambling and positive for the organizer. 
That is how organizers make money.

 
Expected Value of Random Variable : 
Expected value of a random variable R can be defined as following
    E[R] = r1*p1 + r2*p2 + ... rk*pk 
    
    ri ==> Value of R with probability pi
Expected value is basically sum of product of following two terms (for all possible events)
a) Probability of an event.
b) Value of R at that even
Example 1:
In above example of coin toss,
Expected value of profit = 50 * (1/2) + 
                          (-50) * (1/2)
                         = 0

Example 2:
Expected value of six faced dice throw is 
  = 1*(1/6) + 2*(1/6) + .... + 6*(1/6)
  = 3.5

 
Linearity of Expectation:
Let R1 and R2  be two discrete random variables on some probability space, then 
     E[R1 + R2] = E[R1] + E[R2] 
For example, expected value of sum for 3 dice throws is = 3 * 7/2 = 7
Refer this for more detailed explanation and examples.  
 
Expected Number of Trials until Success
If probability of success is p in every trial, then expected number of trials until success is 1/p.  For example, consider 6 faced fair dice is thrown until a ‘5’ is seen as result of dice throw. The expected number of throws before seeing a 5 is 6.  Note that 1/6 is probability of getting a 5 in every trial.  So number of trials is 1/(1/6) = 6.
As another example, consider a QuickSort version that keeps on looking for pivots until one of the middle n/2 elements is picked.  The expected time number of trials for finding middle pivot would be 2 as probability of picking one of the middle n/2 elements is 1/2. This example is discussed in more detail in Set 1.
Refer this for more detailed explanation and examples.  
 
More on Randomized Algorithms:

Randomized Algorithms | Set 1 (Introduction and Analysis) 
Randomized Algorithms | Set 2 (Classification and Applications)
Randomized Algorithms | Set 3 (1/2 Approximate Median)
All Randomized Algorithm Topics
This article is contributed by Shivam Gupta. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Randomized Algorithms | Set 3 (1/2 Approximate Median)Randomized Algorithms | Set 2 (Classification and Applications)Randomized Algorithms | Set 1 (Introduction and Analysis)Randomized Binary Search AlgorithmLoad Balancing on Servers (Randomized Algorithm)Maximum String PartitionMaximum length sub-array which satisfies the given conditionsGenerating Random String Using PHPGenerating OTP (One time Password) in PHPShuffle or Randomize a list in JavaMid-Square hashingStrong Password Suggester ProgramFreivald’s Algorithm to check if a matrix is product of twoImplement random-0-6-Generator using the given random-0-1-GeneratorImproved By :  ChandanKumar9

Article Tags : Randomized
 

thumb_up
Be the First to upvote.



To-do

Done



2.3


Based on 3 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Randomized Algorithms | Set 1 (Introduction and Analysis)


What is a Randomized Algorithm?
An algorithm that uses random numbers to decide what to do next anywhere in its logic is called Randomized Algorithm..  For example, in Randomized Quick Sort, we use random number to pick the next pivot (or we randomly shuffle the array). And in Karger’s algorithm, we randomly pick an edge.
How to analyse Randomized Algorithms?
Some randomized algorithms have deterministic time complexity.  For example, this implementation of Karger’s algorithm has time complexity as O(E). Such algorithms are called Monte Carlo Algorithms and are easier to analyse for worst case.
On the other hand, time complexity of other randomized algorithms (other than Las Vegas) is dependent on value of random variable. Such Randomized algorithms are called Las Vegas Algorithms. These algorithms are typically analysed for expected worst case. To compute expected time taken in worst case, all possible values of the used random variable needs to be considered in worst case and time taken by every possible value needs to be evaluated. Average of all evaluated times is the expected worst case time complexity. Below facts are generally helpful in analysis os such algorithms.
Linearity of Expectation
Expected Number of Trials until Success.
For example consider below a randomized version of QuickSort. 





A Central Pivot is a pivot that divides the array in such a way that one side has at-least 1/4 elements.
// Sorts an array arr[low..high]
randQuickSort(arr[], low, high)

1. If low >= high, then EXIT.

2. While pivot 'x' is not a Central Pivot.
  (i)   Choose uniformly at random a number from [low..high]. 
        Let the randomly picked number number be x.
  (ii)  Count elements in arr[low..high] that are smaller 
        than arr[x]. Let this count be sc.
  (iii) Count elements in arr[low..high] that are greater 
        than arr[x]. Let this count be gc.
  (iv)  Let n = (high-low+1). If sc >= n/4 and
        gc >= n/4, then x is a central pivot.

3. Partition arr[low..high] around the pivot x.

4. // Recur for smaller elements
   randQuickSort(arr, low, sc-1) 

5. // Recur for greater elements
   randQuickSort(arr, high-gc+1, high) 
The important thing in our analysis is, time taken by step 2 is O(n). 
How many times while loop  runs before finding a central pivot?
The probability that the randomly chosen element is central pivot is 1/2.
Therefore, expected number of times the while loop runs is 2 (See this for details)
Thus, the expected time complexity of step 2 is O(n).
What is overall Time Complexity in Worst Case?
In worst case, each partition divides array such that one side has n/4 elements and other side has 3n/4 elements.  The worst case height of recursion tree is Log 3/4 n which is O(Log n).  

T(n) < T(n/4) + T(3n/4) + O(n)
T(n) < 2T(3n/4) + O(n)

Solution of above recurrence is O(n Log n) 
Note that the above randomized algorithm is not the best way to implement randomized Quick Sort.  The idea here is to simplify the analysis as it is simple to analyse.
Typically, randomized Quick Sort is implemented by randomly picking a pivot (no loop).  Or by shuffling array elements.  Expected worst case time complexity of this algorithm is also O(n Log n), but analysis is complex, the MIT prof himself mentions same in his lecture here.  
Randomized Algorithms | Set 2 (Classification and Applications)

References:
http://www.tcs.tifr.res.in/~workshop/nitrkl_igga/randomized-lecture.pdf
This article is contributed by Ashish Sharma. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Randomized Algorithms | Set 0 (Mathematical Background)Randomized Algorithms | Set 3 (1/2 Approximate Median)Randomized Algorithms | Set 2 (Classification and Applications)Randomized Binary Search AlgorithmLoad Balancing on Servers (Randomized Algorithm)Karger’s algorithm for Minimum Cut | Set 2 (Analysis and Applications)Karger's algorithm for Minimum Cut | Set 1 (Introduction and Implementation)Maximum String PartitionMaximum length sub-array which satisfies the given conditionsGenerate a random permutation of 1 to NGenerating Random String Using PHPGenerating OTP (One time Password) in PHPShuffle or Randomize a list in JavaMid-Square hashing

Article Tags : Randomized
 

thumb_up
2



To-do

Done



3.5


Based on 7 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Randomized Algorithms | Set 2 (Classification and Applications)


We strongly recommend to refer below post as a prerequisite of this.
Randomized Algorithms | Set 1 (Introduction and Analysis)
Classification
Randomized algorithms are classified in two categories.





Las Vegas: These algorithms always produce correct or optimum result.   Time complexity of these algorithms is based on a random value and time complexity is evaluated as expected value.  For example, Randomized QuickSort always sorts an input array and expected worst case time complexity of QuickSort is O(nLogn). 
Monte Carlo: Produce correct or optimum result with some probability.  These algorithms have deterministic running time and it is generally easier to find out worst case time complexity. For example this implementation of Karger’s Algorithm produces minimum cut with probability greater than or equal to 1/n2 (n is number of vertices) and has worst case time complexity as O(E).  Another example is Fermet Method for Primality Testing.
Example to Understand Classification: 
Consider a binary array where exactly half elements are 0
and half are 1. The task is to find index of any 1.  
A Las Vegas algorithm for this task is to keep picking a random element until we find a 1.  A Monte Carlo algorithm for the same is to keep picking a random element until we either find 1 or we have tried maximum allowed times say k.
The Las Vegas algorithm always finds an index of 1, but time complexity is determined as expect value. The expected number of trials before success is 2, therefore expected time complexity is O(1).
The Monte Carlo Algorithm finds a 1 with probability [1 – (1/2)k].  Time complexity of Monte Carlo is O(k) which is deterministic
Applications and Scope:

 Consider a tool that basically does sorting.  Let the tool be used by many users and there are few users who always use tool for already sorted array.  If the tool uses simple (not randomized) QuickSort, then those few users are always going to face worst case situation. On the other hand if the tool uses Randomized  QuickSort, then there is no user that always gets worst case.  Everybody gets expected O(n Log n) time.
 Randomized algorithms have huge applications in Cryptography.  
 Load Balancing.  
 Number-Theoretic Applications: Primality Testing 
 Data Structures: Hashing, Sorting, Searching, Order Statistics and Computational Geometry. 
 Algebraic identities: Polynomial and matrix identity verification. Interactive proof systems.
 Mathematical programming: Faster algorithms for linear programming, Rounding linear program solutions to integer program solutions
 Graph algorithms: Minimum spanning trees, shortest paths, minimum cuts.
 Counting and enumeration: Matrix permanent Counting combinatorial structures.
 Parallel and distributed computing: Deadlock avoidance distributed consensus.
 Probabilistic existence proofs: Show that a combinatorial object arises with non-zero probability among  objects drawn from a suitable probability space.
 Derandomization: First devise a randomized algorithm then argue that it can be derandomized to yield a deterministic algorithm.

Sources:
http://theory.stanford.edu/people/pragh/amstalk.pdf
https://en.wikipedia.org/wiki/Randomized_algorithm
This article is contributed by Ashish Sharma. Please write comments if you find anything incorrect, or you want to share more information about the topic discussed above







My Personal Notes
arrow_drop_up





Save


Recommended Posts:Randomized Algorithms | Set 3 (1/2 Approximate Median)Randomized Algorithms | Set 0 (Mathematical Background)Randomized Algorithms | Set 1 (Introduction and Analysis)Randomized Binary Search AlgorithmLoad Balancing on Servers (Randomized Algorithm)Karger’s algorithm for Minimum Cut | Set 2 (Analysis and Applications)Maximum String PartitionMaximum length sub-array which satisfies the given conditionsGenerate a random permutation of 1 to NGenerating Random String Using PHPGenerating OTP (One time Password) in PHPShuffle or Randomize a list in JavaMid-Square hashingStrong Password Suggester Program

Article Tags : Randomized
 

thumb_up
2



To-do

Done



3.5


Based on 2 vote(s)















Please write to us at contribute@geeksforgeeks.org to report any issue with the above content.



Randomized Algorithms | Set 3 (1/2 Approximate Median)


We strongly recommend to refer below articles as a prerequisite of this.
Randomized Algorithms | Set 1 (Introduction and Analysis)
Randomized Algorithms | Set 2 (Classification and Applications)
In this post, a Monte Carlo algorithm is discussed.





Problem Statement :  Given an unsorted array A[] of n numbers and ε > 0, compute an element whose rank (position in sorted A[]) is in the range [(1 – ε)n/2, (1 +  ε)n/2].
For ½ Approximate Median Algorithm &epsilom; is 1/2 => rank should be in the range [n/4, 3n/4]
We can find k’th smallest element in O(n) expected time and O(n) worst case time.
What if we want in less than O(n) time with low probable error allowed?
Following steps represent an algorithm that is O((Log n) x (Log Log n)) time and produces incorrect result with probability less than or equal to 2/n2.

 Randomly choose k elements from the array where k=c log n (c is some constant) 
 Insert then into a set.  
 Sort elements of the set. 
 Return median of the set i.e. (k/2)th element from the set 


Karger’s algorithm for Minimum Cut | Set 1 (Introduction and Implementation)


Given an undirected and unweighted graph, find the smallest cut (smallest number of edges that disconnects the graph into two components).
The input graph may have parallel edges.
For example consider the following example, the smallest cut has 2 edges.

A Simple Solution use Max-Flow based s-t cut algorithm to find minimum cut. Consider every pair of vertices as source ‘s’ and sink ‘t’, and call minimum s-t cut algorithm to find the s-t cut.  Return minimum of all s-t cuts.   Best possible time complexity of this algorithm is O(V5) for a graph. [How? there are total possible V2 pairs and s-t cut algorithm for one pair takes O(V*E) time and  E = O(V2)].  





Below is simple Karger’s Algorithm for this purpose.  Below Karger’s algorithm can be implemented in O(E) = O(V2) time.
1)  Initialize contracted graph CG as copy of original graph
2)  While there are more than 2 vertices.
      a) Pick a random edge (u, v) in the contracted graph.
      b) Merge (or contract) u and v into a single vertex (update 
         the contracted graph).
      c) Remove self-loops
3) Return cut represented by two vertices.

Let us understand above algorithm through the example given.
Let the first randomly picked vertex be ‘a‘ which connects vertices 0 and 1.  We remove this edge and contract the graph (combine vertices 0 and 1).  We get the following graph.

Let the next randomly picked edge be ‘d’. We remove this edge and combine vertices (0,1) and 3.

We need to remove self-loops in the graph.  So we remove edge ‘c’

Now graph has two vertices, so we stop.  The number of edges in the resultant graph is the cut produced by Karger’s algorithm.
Karger’s algorithm is a Monte Carlo algorithm and cut produced by it may not be minimum.  For example, the following diagram shows that a different order of picking random edges produces a min-cut of size 3.

Below is C++ implementation of above algorithm. The input graph is represented as a collection of edges and union-find data structure is used to keep track of components. 





filter_none

K’th Smallest/Largest Element in Unsorted Array | Set 2 (Expected Linear Time)


We recommend reading the following post as a prerequisite of this post.
K’th Smallest/Largest Element in Unsorted Array | Set 1
Given an array and a number k where k is smaller than the size of the array, we need to find the k’th smallest element in the given array. It is given that all array elements are distinct.





Examples:
Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 3
Output: 7

Input: arr[] = {7, 10, 4, 3, 20, 15}
       k = 4
Output: 10
We have discussed three different solutions here.


Recommended: Please solve it on “PRACTICE ” first, before moving on to the solution.



Reservoir Sampling


Reservoir sampling is a family of randomized algorithms for randomly choosing k samples from a list of n items, where n is either a very large or unknown number. Typically n is large enough that the list doesn’t fit into main memory.  For example, a list of search queries in Google and Facebook.
So we are given a big array (or stream) of numbers (to simplify), and we need to write an efficient function to randomly select k numbers where 1 <= k <= n.  Let the input array be stream[]. 
A simple solution is to create an array reservoir[] of maximum size k.  One by one randomly select an item from stream[0..n-1]. If the selected item is not previously selected, then put it in reservoir[].   To check if an item is previously selected or not, we need to search the item in reservoir[].   The time complexity of this algorithm will be O(k^2).  This can be costly if k is big.  Also, this is not efficient if the input is in the form of a stream.  





It can be solved in O(n) time.  The solution also suits well for input in the form of stream. The idea is similar to this post.  Following are the steps.
1) Create an array reservoir[0..k-1] and copy first k items of stream[] to it.
2) Now one by one consider all items from (k+1)th item to nth item.
…a) Generate a random number from 0 to i where i is index of current item in stream[]. Let the generated random number is j.
…b) If j is in range 0 to k-1, replace reservoir[j] with arr[i]
Following is implementation of the above algorithm.

C++







filter_none

Shuffle a given array using Fisher–Yates shuffle Algorithm


Given an array, write a program to generate a random permutation of array elements. This question is also asked as “shuffle a deck of cards” or “randomize a given array”. Here shuffle means that every permutation of array element should equally likely.

Let the given array be arr[]. A simple solution is to create an auxiliary array temp[] which is initially a copy of arr[].  Randomly select an element from temp[], copy the randomly selected element to arr[0] and remove the selected element from temp[].  Repeat the same process n times and keep copying elements to arr[1], arr[2], … .  The time complexity of this solution will be O(n^2).
 Fisher–Yates shuffle Algorithm works in O(n) time complexity.  The assumption here is, we are given a function rand() that generates random number in O(1) time.
The idea is to start from the last element, swap it with a randomly selected element from the whole array (including last). Now consider the array from 0 to n-2 (size reduced by 1), and repeat the process till we hit the first element. 





Following is the detailed algorithm
To shuffle an array a of n elements (indices 0..n-1):
  for i from n - 1 downto 1 do
       j = random integer with 0 <= j <= i
       exchange a[j] and a[i]

Following is implementation of this algorithm.

C++






filter_none

Select a Random Node from a Singly Linked List


Given a singly linked list, select a random node from linked list (the probability of picking a node should be 1/N if there are N nodes in list).  You are given a random number generator.
Below is a Simple Solution
1) Count number of nodes by traversing the list.
2) Traverse the list again and select every node with probability 1/N.  The selection can be done by generating a random number from 0 to N-i for i’th node, and selecting the i’th node node only if generated number is equal to 0 (or any other fixed number from 0 to N-i).  
We get uniform probabilities with above schemes. 





i = 1, probability of selecting first node = 1/N
i = 2, probability of selecting second node =
                   [probability that first node is not selected] * 
                   [probability that second node is selected]
                  = ((N-1)/N)* 1/(N-1)
                  = 1/N  
Similarly, probabilities of other selecting other nodes is 1/N
The above solution requires two traversals of linked list.  
How to select a random node with only one traversal allowed?
The idea is to use Reservoir Sampling. Following are the steps.  This is a simpler version of Reservoir Sampling as we need to select only one key instead of k keys.
(1) Initialize result as first node
   result = head->key 
(2) Initialize n = 2
(3) Now one by one consider all nodes from 2nd node onward.
    (3.a) Generate a random number from 0 to n-1. 
         Let the generated random number is j.
    (3.b) If j is equal to 0 (we could choose other fixed number 
          between 0 to n-1), then replace result with current node.
    (3.c) n = n+1
    (3.d) current = current->next
Below is the implementation of above algorithm.

C







filter_none

0/1 Knapsack using Branch and Bound


Branch and bound is an algorithm design paradigm which is generally used for solving combinatorial optimization problems. These problems typically exponential in terms of time complexity and may require exploring all possible permutations in worst case. Branch and Bound solve these problems relatively quickly.
Let us consider below 0/1 Knapsack problem to understand Branch and Bound.
Given two integer arrays val[0..n-1] and wt[0..n-1] that represent values and weights associated with n items respectively. Find out the maximum value subset of val[] such that sum of the weights of this subset is smaller than or equal to Knapsack capacity W. 





Let us explore all approaches for this problem.

A Greedy approach is to pick the items in decreasing order of value per unit weight. The Greedy approach works only for fractional knapsack problem and may not produce correct result for 0/1 knapsack.
We can use Dynamic Programming (DP) for 0/1 Knapsack problem. In DP, we use a 2D table of size n x W. The DP Solution doesn’t work if item weights are not integers.
Since DP solution doesn’t alway work, a solution is to use Brute Force. With n items, there are 2n solutions to be generated, check each to see if they satisfy the constraint, save maximum solution that satisfies constraint. This solution can be expressed as tree.


Implementation of 0/1 Knapsack using Branch and Bound


We strongly recommend to refer below post as a prerequisite for this.
Branch and Bound | Set 1 (Introduction with 0/1 Knapsack)
We discussed different approaches to solve above problem and saw that the Branch and Bound solution is the best suited method when item weights are not integers.





In this post implementation of Branch and Bound method for 0/1 knapsack problem is discussed. 
How to find bound for every node for 0/1 Knapsack? 
The idea is to use the fact that the Greedy approach provides the best solution for Fractional Knapsack problem.
To check if a particular node can give us a better solution or not, we compute the optimal solution (through the node) using Greedy approach.  If the solution computed by Greedy approach itself is more than the best so far, then we can’t get a better solution through the node. 
Complete Algorithm:

 Sort all items in decreasing order of ratio of value per unit weight so that an upper bound can be computed using Greedy Approach.
 Initialize maximum profit, maxProfit = 0
 Create an empty queue, Q.
 Create a dummy node of decision tree and enqueue it to Q. Profit and weight of dummy node are 0.
 Do following while Q is not empty.

 Extract an item from Q. Let the extracted item be u.
 Compute profit of next level node. If the profit is more than maxProfit, then update maxProfit.
Compute bound of next level node. If bound is more than maxProfit, then add next level node to Q.
 Consider the case when next level node is not considered as part of solution and add a node to queue with level as next, but weight and profit without considering next level nodes.



Illustration: 
Input:
// First thing in every pair is weight of item
// and second thing is value of item
Item arr[] = {{2, 40}, {3.14, 50}, {1.98, 100},
              {5, 95}, {3, 30}};
Knapsack Capacity W = 10

Output:
The maximum possible profit = 235

Below diagram shows illustration. Items are 
considered sorted by value/weight.



8 puzzle Problem using Branch And Bound


We have introduced Branch and Bound and discussed 0/1 Knapsack problem in below posts.

Branch and Bound | Set 1 (Introduction with 0/1 Knapsack)
Branch and Bound | Set 2 (Implementation of 0/1 Knapsack)

In this puzzle solution of 8 puzzle problem is discussed.
Given a 3×3 board with 8 tiles (every tile has one number from 1 to 8) and one empty space. The objective is to place the numbers on tiles to match final configuration using the empty space. We can slide four adjacent (left, right, above and below) tiles into the empty space.

For example,

1. DFS (Brute-Force)
We can perform a depth-first search on state space (Set of all configurations of a given problem i.e. all states that can be reached from the initial state) tree. 





 
State Space Tree for 8 Puzzle
In this solution, successive moves can take us away from the goal rather than bringing closer. The search of state space tree follows the leftmost path from the root regardless of the initial state. An answer node may never be found in this approach.
2. BFS (Brute-Force)
We can perform a Breadth-first search on the state space tree. This always finds a goal state nearest to the root. But no matter what the initial state is, the algorithm attempts the same sequence of moves like DFS.
3. Branch and Bound
The search for an answer node can often be speeded by using an “intelligent” ranking function, also called an approximate cost function to avoid searching in sub-trees that do not contain an answer node. It is similar to the backtracking technique but uses BFS-like search.
There are basically three types of nodes involved in Branch and Bound
1. Live node is a node that has been generated but whose children have not yet been generated.
2. E-node is a live node whose children are currently being explored. In other words, an E-node is a node currently being expanded.
3. Dead node is a generated node that is not to be expanded or explored any further. All children of a dead node have already been expanded.
Cost function:
Each node X in the search tree is associated with a cost. The cost function is useful for determining the next E-node. The next E-node is the one with the least cost. The cost function is defined as 
   C(X) = g(X) + h(X) where
   g(X) = cost of reaching the current node 
          from the root
   h(X) = cost of reaching an answer node from X.
Ideal Cost function for 8-puzzle Algorithm : 
We assume that moving one tile in any direction will have 1 unit cost. Keeping that in mind, we define a cost function for the 8-puzzle algorithm as below: 
   c(x) = f(x) + h(x) where
   f(x) is the length of the path from root to x 
        (the number of moves so far) and
   h(x) is the number of non-blank tiles not in 
        their goal position (the number of mis-
        -placed tiles). There are at least h(x) 
        moves to transform state x to a goal state 
An algorithm is available for getting an approximation of h(x) which is an unknown value.
Complete Algorithm:
/* Algorithm LCSearch uses c(x) to find an answer node
 * LCSearch uses Least() and Add() to maintain the list 
   of live nodes
 * Least() finds a live node with least c(x), deletes
   it from the list and returns it
 * Add(x) adds x to the list of live nodes
 * Implement list of live nodes as a min-heap */

struct list_node
{
   list_node *next;

   // Helps in tracing path when answer is found
   list_node *parent; 
   float cost;
} 

algorithm LCSearch(list_node *t)
{
   // Search t for an answer node
   // Input: Root node of tree t
   // Output: Path from answer node to root
   if (*t is an answer node)
   {
       print(*t);
       return;
   }
   
   E = t; // E-node

   Initialize the list of live nodes to be empty;
   while (true)
   {
      for each child x of E
      {
          if x is an answer node
          {
             print the path from x to t;
             return;
          }
          Add (x); // Add x to list of live nodes;
          x->parent = E; // Pointer for path to root
      }

      if there are no more live nodes
      {
         print ("No answer node");
         return;
      }
       
      // Find a live node with least estimated cost
      E = Least(); 

      // The found node is deleted from the list of 
      // live nodes
   }
}

Below diagram shows the path followed by the above algorithm to reach final configuration from the given initial configuration of 8-Puzzle. Note that only nodes having the least value of cost function are expanded.










filter_none

Job Assignment Problem using Branch And Bound


Let there be N workers and N jobs. Any worker can be assigned to perform any job, incurring some cost that may vary depending on the work-job assignment. It is required to perform all jobs by assigning exactly one worker to each job and exactly one job to each agent in such a way that the total cost of the assignment is minimized.

Let us explore all approaches for this problem.





Solution 1: Brute Force
We generate n! possible job assignments and for each such assignment, we compute its total cost and return the less expensive assignment. Since the solution is a permutation of the n jobs, its complexity is O(n!).
Solution 2: Hungarian Algorithm
The optimal assignment can be found using the Hungarian algorithm. The Hungarian algorithm has worst case run-time complexity of O(n^3).
Solution 3: DFS/BFS on state space tree
A state space tree is a N-ary tree with property that any path from root to leaf node holds one of many solutions to given problem. We can perform depth-first search on state space tree and but successive moves can take us away from the goal rather than bringing closer. The search of state space tree follows leftmost path from the root regardless of initial state. An answer node may never be found in this approach. We can also perform a Breadth-first search on state space tree. But no matter what the initial state is, the algorithm attempts the same sequence of moves like DFS.
 Solution 4: Finding Optimal Solution using Branch and Bound
The selection rule for the next node in BFS and DFS is “blind”. i.e. the selection rule does not give any preference to a node that has a very good chance of getting the search to an answer node quickly. The search for an optimal solution can often be speeded by using an “intelligent” ranking function, also called an approximate cost function to avoid searching in sub-trees that do not contain an optimal solution. It is similar to BFS-like search but with one major optimization. Instead of following FIFO order, we choose a live node with least cost. We may not get optimal solution by following node with least promising cost, but it will provide very good chance of getting the search to an answer node quickly.
There are two approaches to calculate the cost function:

For each worker, we choose job with minimum cost from list of unassigned jobs (take minimum entry from each row). 
For each job, we choose a worker with lowest cost for that job from list of unassigned workers (take minimum entry from each column).

In this article, the first approach is followed.
Let’s take below example and try to calculate promising cost when Job 2 is assigned to worker A.

Since Job 2 is assigned to worker A (marked in green), cost becomes 2 and Job 2 and worker A becomes unavailable (marked in red).

Now we assign job 3 to worker B as it has minimum cost from list of unassigned jobs. Cost becomes 2 + 3 = 5 and Job 3 and worker B also becomes unavailable.

Finally, job 1 gets assigned to worker C as it has minimum cost among unassigned jobs and job 4 gets assigned to worker C as it is only Job left. Total cost becomes 2 + 3 + 5 + 4 = 14.

Below diagram shows complete search space diagram showing optimal solution path in green.

Complete Algorithm: 
/* findMinCost uses Least() and Add() to maintain the
   list of live nodes

   Least() finds a live node with least cost, deletes
   it from the list and returns it

   Add(x) calculates cost of x and adds it to the list
   of live nodes

   Implements list of live nodes as a min heap */


// Search Space Tree Node
node
{
   int job_number;
   int worker_number;
   node parent;
   int cost;
}

// Input: Cost Matrix of Job Assignment problem
// Output: Optimal cost and Assignment of Jobs
algorithm findMinCost (costMatrix mat[][])
{
   // Initialize list of live nodes(min-Heap)
   // with root of search tree i.e. a Dummy node
   while (true)
   {
      // Find a live node with least estimated cost
      E = Least();

      // The found node is deleted from the list
      // of live nodes
      if (E is a leaf node)
      {
         printSolution();
         return;
      }

     for each child x of E
     {
         Add(x); // Add x to list of live nodes;
         x->parent = E; // Pointer for path to root
     }
   }
} 
Below is its C++ implementation.





filter_none

N Queen Problem using Branch And Bound


The N queens puzzle is the problem of placing N chess queens on an N×N chessboard so that no two queens threaten each other. Thus, a solution requires that no two queens share the same row, column, or diagonal.
Backtracking Algorithm for N-Queen is already discussed here.  In backtracking solution we backtrack when we hit a dead end.  In Branch and Bound solution, after building a partial solution, we figure out that there is no point going any deeper as we are going to hit a dead end.  
Let’s begin by describing backtracking solution.  “The idea is to place queens one by one in different columns, starting from the leftmost column. When we place a queen in a column, we check for clashes with already placed queens. In the current column, if we find a row for which there is no clash, we mark this row and column as part of the solution. If we do not find such a row due to clashes, then we backtrack and return false.”








For the 1st Queen, there are total 8 possibilities as we can place 1st Queen in any row of first column. Let’s place Queen 1 on row 3.
After placing 1st Queen, there are 7 possibilities left for the 2nd Queen. But wait, we don’t really have 7 possibilities. We cannot place Queen 2 on rows 2, 3 or 4 as those cells are under attack from Queen 1. So, Queen 2 has only 8 – 3 = 5 valid positions left.
After picking a position for Queen 2, Queen 3 has even fewer options as most of the cells in its column are under attack from the first 2 Queens.

We need to figure out an efficient way of keeping track of which cells are under attack. In previous solution we kept an 8­-by­-8 Boolean matrix and update it each time we placed a queen, but that required linear time to update as we need to check for safe cells.
Basically, we have to ensure 4 things:
1. No two queens share a column.
2. No two queens share a row.
3. No two queens share a top-right to left-bottom diagonal.
4. No two queens share a top-left to bottom-right diagonal.
Number 1 is automatic because of the way we store the solution. For number 2, 3 and 4, we can perform updates in O(1) time. The idea is to keep three Boolean arrays that tell us which rows and which diagonals are occupied.
Lets do some pre-processing first. Let’s create two N x N matrix one for / diagonal and other one for \ diagonal. Let’s call them slashCode and backslashCode respectively. The trick is to fill them in such a way that two queens sharing a same /­diagonal will have the same value in matrix slashCode, and if they share same \­diagonal, they will have the same value in backslashCode matrix.
For an N x N matrix, fill slashCode and backslashCode matrix using below formula –
slashCode[row][col] = row + col
backslashCode[row][col] = row – col + (N-1)
Using above formula will result in below matrices






The ‘N – 1’ in the backslash code is there to ensure that the codes are never negative because we will be using the codes as indices in an array.
Now before we place queen i on row j, we first check whether row j is used (use an array to store row info). Then we check whether slash code ( j + i ) or backslash code ( j – i + 7 ) are used (keep two arrays that will tell us which diagonals are occupied). If yes, then we have to try a different location for queen i. If not, then we mark the row and the two diagonals as used and recurse on queen i + 1. After the recursive call returns and before we try another position for queen i, we need to reset the row, slash code and backslash code as unused again, like in the code from the previous notes.
Below is the implementation of above idea – 

C++






filter_none

Traveling Salesman Problem using Branch And Bound


Given a set of cities and distance between every pair of cities, the problem is to find the shortest possible tour that visits every city exactly once and returns to the starting point.

For example, consider the graph shown in figure on right side. A TSP tour in the graph is 0-1-3-2-0. The cost of the tour is 10+25+30+15 which is 80.





We  have discussed following solutions
1) Naive and Dynamic Programming
2) Approximate solution using MST
 
 
Branch and Bound Solution
As seen in the previous articles, in Branch and Bound method, for current node in tree, we compute a bound on best possible solution that we can get if we down this node.  If the bound on best possible solution itself is worse than current best (best computed so far), then we ignore the subtree rooted with the node.  
Note that the cost through a node includes two costs.
1) Cost of reaching the node from the root (When we reach a node, we have this cost computed)
2) Cost of reaching an answer from current node to a leaf (We compute a bound on this cost to decide whether to ignore subtree with this node or not).

In cases of a maximization problem, an upper bound tells us the maximum possible solution if we follow the given node. For example in 0/1 knapsack we used Greedy approach to find an upper bound. 
In cases of a minimization problem, a lower bound tells us the minimum possible solution if we follow the  given node. For example, in Job Assignment Problem, we get a lower bound by assigning least cost job to a worker.

In branch and bound, the challenging part is figuring out a way to compute a bound on best possible solution.  Below is an idea used to compute bounds for Traveling salesman problem.
Cost of any tour can be written as below.
Cost of a tour T = (1/2) * &Sum; (Sum of cost of two edges
                              adjacent to u and in the
                              tour T) 
                   where u ∈ V
For every vertex u, if we consider two edges through it in T,
and sum their costs.  The overall sum for all vertices would
be twice of cost of tour T (We have considered every edge 
twice.)

(Sum of two tour edges adjacent to u) >= (sum of minimum weight
                                          two edges adjacent to
                                          u)

Cost of any tour >=  1/2) * &Sum; (Sum of cost of two minimum
                              weight edges adjacent to u) 
                   where u ∈ V


For example, consider the above shown graph. Below are minimum cost two edges adjacent to every node.
Node     Least cost edges   Total cost            
0     (0, 1), (0, 2)            25
1     (0, 1), (1, 3)         35
2    (0, 2), (2, 3)            45
3     (0, 3), (1, 3)            45

Thus a lower bound on the cost of any tour = 
         1/2(25 + 35 + 45 + 45)
       = 75
Refer this for one more example.

Now we have an idea about computation of lower bound.  Let us see how to how to apply it state space search tree.  We start enumerating all possible nodes (preferably in lexicographical order)
1. The Root Node: Without loss of generality, we assume we start at vertex “0” for which the lower bound has been calculated above.
Dealing with Level 2: The next level enumerates all possible vertices we can go to (keeping in mind that in any path a vertex has to occur only once) which are, 1, 2, 3… n (Note that the graph is complete). Consider we are calculating for vertex 1, Since we moved from 0 to 1, our tour has now included the edge 0-1. This allows us to make necessary changes in the lower bound of the root.





Lower Bound for vertex 1 = 
   Old lower bound - ((minimum edge cost of 0 + 
                    minimum edge cost of 1) / 2) 
                  + (edge cost 0-1)
How does it work? To include edge 0-1, we add the edge cost of 0-1, and subtract an edge weight such that the lower bound remains as tight as possible which would be the sum of the minimum edges of 0 and 1 divided by 2. Clearly, the edge subtracted can’t be smaller than this.
Dealing with other levels: As we move on to the next level, we again enumerate all possible vertices. For the above case going further after 1, we check out for 2, 3, 4, …n.
Consider lower bound for 2 as we moved from 1 to 1, we include the edge 1-2 to the tour and alter the new lower bound for this node.
Lower bound(2) = 
     Old lower bound - ((second minimum edge cost of 1 + 
                         minimum edge cost of 2)/2)
                     + edge cost 1-2)
Note: The only change in the formula is that this time we have included second minimum edge cost for 1, because the minimum edge cost has already been subtracted in previous level.

C++







filter_none