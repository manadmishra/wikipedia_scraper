***Semaphore (programming)***
In computer science, a  semaphore  is a variable or abstract data type used to control access to a common resource by multiple processes in a concurrent system such as a multitasking operating system. A semaphore is simply a variable. This variable is used to solve critical section problems and to achieve process synchronization in the multi processing environment. A trivial semaphore is a plain variable that is changed (for example, incremented or decremented, or toggled) depending on programmer-defined conditions.
 A useful way to think of a semaphore as used in the real-world system is as a record of how many units of a particular resource are available, coupled with operations to adjust that record  safely  (i.e., to avoid race conditions) as units are required or become free, and, if necessary, wait until a unit of the resource becomes available. 
 Semaphores are a useful tool in the prevention of race conditions; however, their use is by no means a guarantee that a program is free from these problems. Semaphores which allow an arbitrary resource count are called  counting semaphores , while semaphores which are restricted to the values 0 and 1 (or locked/unlocked, unavailable/available) are called  binary semaphores  and are used to implement locks.
 The semaphore concept was invented by Dutch computer scientist Edsger Dijkstra in 1962 or 1963, when Dijkstra and his team were developing an operating system for the  Electrologica X8. That system eventually became known as THE multiprogramming system.
 

 **Semantics and implementation**

 Counting semaphores are equipped with two operations, historically denoted as P and V (see § Operation names for alternative names). Operation V increments the semaphore  S , and operation P decrements it.
 The value of the semaphore  S  is the number of units of the resource that are currently available. The P operation wastes time or sleeps until a resource protected by the semaphore becomes available, at which time the resource is immediately claimed. The V operation is the inverse: it makes a resource available again after the process has finished using it.
One important property of semaphore  S  is that its value cannot be changed except by using the V and P operations.
 A simple way to understand  wait  (P) and  signal  (V) operations is:
 
 wait : Decrements the value of semaphore variable by 1. If the new value of the semaphore variable is negative, the process executing  wait  is blocked (i.e., added to the semaphore's queue). Otherwise, the process continues execution, having used a unit of the resource. 
 signal : Increments the value of semaphore variable by 1. After the increment, if the pre-increment value was negative (meaning there are processes waiting for a resource), it transfers a blocked process from the semaphore's waiting queue to the ready queue. Many operating systems provide efficient semaphore primitives that unblock a waiting process when the semaphore is incremented. This means that processes do not waste time checking the semaphore value unnecessarily.
 The counting semaphore concept can be extended with the ability to claim or return more than one "unit" from the semaphore, a technique implemented in Unix. The modified V and P operations are as follows, using square brackets to indicate atomic operations, i.e., operations which appear indivisible from the perspective of other processes:
 
 function  V(semaphore S, integer I):
    [S ← S + I]

 function  P(semaphore S, integer I):
     repeat: 
        [ if  S ≥ I:
        S ← S − I
         break ]
 
 However, the remainder of this section refers to semaphores with unary V and P operations, unless otherwise specified.
 To avoid starvation, a semaphore has an associated queue of processes (usually with FIFO semantics). If a process performs a P operation on a semaphore that has the value zero, the process is added to the semaphore's queue and its execution is suspended. When another process increments the semaphore by performing a V operation, and there are processes on the queue, one of them is removed from the queue and resumes execution. When processes have different priorities the queue may be ordered by priority, so that the highest priority process is taken from the queue first.
 If the implementation does not ensure atomicity of the increment, decrement and comparison operations, then there is a risk of increments or decrements being forgotten, or of the semaphore value becoming negative. Atomicity may be achieved by using a machine instruction that is able to read, modify and write the semaphore in a single operation. In the absence of such a hardware instruction, an atomic operation may be synthesized through the use of a software mutual exclusion algorithm. On uniprocessor systems, atomic operations can be ensured by temporarily suspending preemption or disabling hardware interrupts. This approach does not work on multiprocessor systems where it is possible for two programs sharing a semaphore to run on different processors at the same time. To solve this problem in a multiprocessor system a locking variable can be used to control access to the semaphore. The locking variable is manipulated using a test-and-set-lock command.
 

 **Examples**

 **Trivial example**

 Consider a variable  A  and a boolean variable  S .  A  is only accessed when  S  is marked true. Thus,  S  is a semaphore for  A .
 One can imagine a stoplight signal ( S ) just before a train station ( A ). In this case, if the signal is green, then one can enter the train station. If it is yellow or red (or any other color), the train station cannot be accessed.
 

 **Login queue**

 Consider a system that can only support ten users (S=10). Whenever a user logs in, P is called, decrementing the semaphore  S  by 1. Whenever a user logs out, V is called, incrementing  S  by 1 representing a login slot that has become available. When  S  is 0, any users wishing to log in must wait until  S  > 0  and the login request is enqueued onto a FIFO queue; mutual exclusion is used to ensure that requests are enqueued in order. Whenever  S  becomes greater than 0 (login slots available), a login request is dequeued, and the user owning the request is allowed to log in.
 

 **Producer–consumer problem**

 In the producer–consumer problem, one process (the producer) generates data items and another process (the consumer) receives and uses them. They communicate using a queue of maximum size  N  and are subject to the following conditions:
 
 the consumer must wait for the producer to produce something if the queue is empty; 
 the producer must wait for the consumer to consume something if the queue is full. The semaphore solution to the producer–consumer problem tracks the state of the queue with two semaphores:  emptyCount , the number of empty places in the queue, and  fullCount , the number of elements in the queue. To maintain integrity,  emptyCount  may be lower (but never higher) than the actual number of empty places in the queue, and  fullCount  may be lower (but never higher) than the actual number of items in the queue. Empty places and items represent two kinds of resources, empty boxes and full boxes, and the semaphores  emptyCount  and  fullCount  maintain control over these resources.
 The binary semaphore  useQueue  ensures that the integrity of the state of the queue itself is not compromised, for example by two producers attempting to add items to an empty queue simultaneously, thereby corrupting its internal state. Alternatively a mutex could be used in place of the binary semaphore.
 The  emptyCount  is initially  N ,  fullCount  is initially 0, and  useQueue  is initially 1.
 The producer does the following repeatedly:
 
 produce: 
    P(emptyCount)
    P(useQueue)
    putItemIntoQueue(item)
    V(useQueue)
    V(fullCount)
 
 The consumer does the following repeatedly
 
 consume: 
    P(fullCount)
    P(useQueue)
    item ← getItemFromQueue()
    V(useQueue)
    V(emptyCount)
 
 Below is a substantive example:
 
 A single consumer enters its critical section. Since  fullCount  is 0, the consumer blocks. 
 Several producers enter the producer critical section. No more than  N  producers may enter their critical section due to  emptyCount  constraining their entry. 
 The producers, one at a time, gain access to the queue through  useQueue  and deposit items in the queue. 
 Once the first producer exits its critical section,  fullCount  is incremented, allowing one consumer to enter its critical section. Note that  emptyCount  may be much lower than the actual number of empty places in the queue, for example in the case where many producers have decremented it but are waiting their turn on  useQueue  before filling empty places. Note that  emptyCount + fullCount ≤  N    always holds, with equality if and only if no producers or consumers are executing their critical sections.
 

 **Operation names**

 The canonical names V and P come from the initials of Dutch words. V is generally explained as  verhogen  ("increase"). Several explanations have been offered for P, including  proberen  ("to test" or "to try"),  passeren  ("pass"), and  pakken  ("grab"). Dijkstra's earliest paper on the subject gives  passering  ("passing") as the meaning for  P , and  vrijgave  ("release") as the meaning for V. It also mentions that the terminology is taken from that used in railroad signals. Dijkstra subsequently wrote that he intended  P  to stand for the portmanteau  prolaag , short for  probeer te verlagen , literally "try to reduce", or to parallel the terms used in the other case, "try to decrease". In ALGOL 68, the Linux kernel, and in some English textbooks, the  V  and  P  operations are called, respectively,  up  and  down . In software engineering practice, they are often called  signal  and  wait ,  release  and  acquire  (which the standard Java library uses), or  post  and  pend . Some texts call them  vacate  and  procure  to match the original Dutch initials.
 

 **Semaphores vs. mutexes**

 A mutex is a locking mechanism that sometimes uses the same basic implementation as the binary semaphore. The differences between them are in how they are used. While a binary semaphore may be colloquially referred to as a mutex, a true mutex has a more specific use-case and definition, in that only the task that locked the mutex is supposed to unlock it. This constraint aims to handle some potential problems of using semaphores:
 
 Priority inversion: If the mutex knows who locked it and is supposed to unlock it, it is possible to promote the priority of that task whenever a higher-priority task starts waiting on the mutex. 
 Premature task termination: Mutexes may also provide deletion safety, where the task holding the mutex cannot be accidentally deleted. 
 Termination deadlock: If a mutex-holding task terminates for any reason, the OS can release the mutex and signal waiting tasks of this condition. 
 Recursion deadlock: a task is allowed to lock a reentrant mutex multiple times as it unlocks it an equal number of times. 
 Accidental release: An error is raised on the release of the mutex if the releasing task is not its owner. 

 